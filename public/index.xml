<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ことえりブログ</title>
    <link>/</link>
    <description>Recent content on ことえりブログ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 Jun 2019 12:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>DockerコンテナにホストのAWSアクセスキーを渡す方法</title>
      <link>/post/2019-06-08-Docker%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%81%AB%E3%83%9B%E3%82%B9%E3%83%88%E3%81%AEAWS%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E3%82%AD%E3%83%BC%E3%82%92%E6%B8%A1%E3%81%99%E6%96%B9%E6%B3%95/</link>
      <pubDate>Sat, 08 Jun 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-06-08-Docker%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%81%AB%E3%83%9B%E3%82%B9%E3%83%88%E3%81%AEAWS%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E3%82%AD%E3%83%BC%E3%82%92%E6%B8%A1%E3%81%99%E6%96%B9%E6%B3%95/</guid>
      <description>課題 DockerコンテナからAWSのAPIにアクセスしたい場合、ホストがEC2ならIAMロールが使える。 しかしホストがローカルのMacの場合は、アクセスキーとシークレットアクセスキーを、どうにかしてコンテナに渡す必要がある。
結論 aws cliのconfigure getサブコマンドを使う。 具体的には下記のようにする。
#!/usr/bin/env sh AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id) AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key) docker run --rm \  -e AWS_REGION=ap-northeast-1 \  -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \  -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \  (略) このようにすればコンテナ内のAWC CLI指定の環境変数にアクセスキー等が格納されるので、そのままaws cliコマンドなどが使える。 プロファイルが複数ある場合は下記のようにして切り替えることもできる。
AWS_ACCESS_KEY_ID=$(aws --profile (プロファイル名) configure get aws_access_key_id) AWS_SECRET_ACCESS_KEY=$(aws --profile (プロファイル名) configure get aws_secret_access_key) 参考 get — AWS CLI 1.16.174 Command Reference
AWS CLI の設定 - AWS Command Line Interface</description>
    </item>
    
    <item>
      <title>UseKeychainが設定されているMacのssh configをLinuxで使い回す</title>
      <link>/post/2019-06-08-UseKeychain%E3%81%8C%E8%A8%AD%E5%AE%9A%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8BMac%E3%81%AEssh-config%E3%82%92Linux%E3%81%A7%E4%BD%BF%E3%81%84%E5%9B%9E%E3%81%99/</link>
      <pubDate>Sat, 08 Jun 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-06-08-UseKeychain%E3%81%8C%E8%A8%AD%E5%AE%9A%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8BMac%E3%81%AEssh-config%E3%82%92Linux%E3%81%A7%E4%BD%BF%E3%81%84%E5%9B%9E%E3%81%99/</guid>
      <description>課題 Dockerコンテナ内でMacのSSH設定を引き継ごうと思い、ボリュームマウントで対応したものの、Macでしか使えないUseKeychainが邪魔をしてエラーとなってしまう。
結論 IgnoreUnknownオプションを使う。 具体的には下記のようにする。
IgnoreUnknown UseKeychain UseKeychain yes 参考 Technical Note TN2449: OpenSSH updates in macOS 10.12.2</description>
    </item>
    
    <item>
      <title>jQueryのajaxデバッグ方法</title>
      <link>/post/2019-04-23-jQuery%E3%81%AEajax%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E6%96%B9%E6%B3%95/</link>
      <pubDate>Tue, 23 Apr 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-23-jQuery%E3%81%AEajax%E3%83%87%E3%83%90%E3%83%83%E3%82%B0%E6%96%B9%E6%B3%95/</guid>
      <description>表題の通り、jQueryのajaxをデバッグするには、コールバックを登録すればいいらしい。 ついでにキャッシュも無効化しよう。
$.ajax({ type: &amp;#39;GET&amp;#39;, url: &amp;#39;/api.php&amp;#39;, dataType: &amp;#39;json&amp;#39;, data: { hoge: &amp;#39;hage&amp;#39; }, async: false }) .done(function(response) { result = response; }) .fail(function () { console.log(&amp;#39;error&amp;#39;); }); $.ajax({ type: &amp;#39;GET&amp;#39;, url: &amp;#39;/api.php&amp;#39;, dataType: &amp;#39;json&amp;#39;, data: { hoge: &amp;#39;hage&amp;#39; }, async: false, cache: false, success: function(result){ console.debug(&amp;#34;result&amp;#34; + result); }, error: function(jqxhr, status, exception) { console.debug(&amp;#39;jqxhr&amp;#39;, jqxhr); console.debug(&amp;#39;status&amp;#39;, status); console.debug(&amp;#39;exception&amp;#39;, exception); } }) .done(function(response) { result = response; }) .fail(function () { console.</description>
    </item>
    
    <item>
      <title>Macのログイン画面に管理者(Admin)のアカウントしか出てこないとき</title>
      <link>/post/2019-04-18-Mac%E3%81%AE%E3%83%AD%E3%82%B0%E3%82%A4%E3%83%B3%E7%94%BB%E9%9D%A2%E3%81%AB%E7%AE%A1%E7%90%86%E8%80%85Admin%E3%81%AE%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%81%97%E3%81%8B%E5%87%BA%E3%81%A6%E3%81%93%E3%81%AA%E3%81%84%E3%81%A8%E3%81%8D/</link>
      <pubDate>Thu, 18 Apr 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-18-Mac%E3%81%AE%E3%83%AD%E3%82%B0%E3%82%A4%E3%83%B3%E7%94%BB%E9%9D%A2%E3%81%AB%E7%AE%A1%E7%90%86%E8%80%85Admin%E3%81%AE%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E3%81%97%E3%81%8B%E5%87%BA%E3%81%A6%E3%81%93%E3%81%AA%E3%81%84%E3%81%A8%E3%81%8D/</guid>
      <description>表題の通り、Macのログイン画面に管理者(Admin)のアカウントしか出てこないときの対応です。
FileVaultの許可ユーザーを設定 (99%これで解決)  システム環境設定 -&amp;gt; セキュリティ -&amp;gt; FileVaultのタブにアクセス 左下の鍵マークを選択し、管理者パスワードを入力 許可されていないユーザーがあります的なボタンが出てくるので、それを押してそのユーザーのパスワードを入力  IsHidden要素を設定 ユーザーに設定されているIsHidden要素が1だとログイン画面に出てこないらしい。
  Terminal.appで下記コマンドを実行。
sudo dscl . create /Users/(ユーザー名) IsHidden 0   （変更確認方法） Terminal.appで下記コマンドを実行
dscl . -read /Users/_(ユーザー名)   参考 macOS でユーザアカウントを非表示にする - Apple サポート
適当なユーザーを作って削除 よく分からんが自分の場合はこれで解決
 適当なユーザーを作成する 再起動してログイン画面に表示したいユーザーと作成したユーザーが出ることを確認 作成したユーザーを削除  </description>
    </item>
    
    <item>
      <title>KarabinerでCtrl &#43; [をEscの代わりにする設定</title>
      <link>/post/2019-04-12-Karabiner%E3%81%A7Ctrl-&#43;-%E3%82%92Esc%E3%81%AE%E4%BB%A3%E3%82%8F%E3%82%8A%E3%81%AB%E3%81%99%E3%82%8B%E8%A8%AD%E5%AE%9A/</link>
      <pubDate>Fri, 12 Apr 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-12-Karabiner%E3%81%A7Ctrl-&#43;-%E3%82%92Esc%E3%81%AE%E4%BB%A3%E3%82%8F%E3%82%8A%E3%81%AB%E3%81%99%E3%82%8B%E8%A8%AD%E5%AE%9A/</guid>
      <description>表題の通りKarabinerでCtrl + [をEscの代わりにする設定です。
VSCodeでVimのキーバインドを導入した際、EscがCtrl+]に割り当てられており、キーバインドを変更してみたのですが、効果がなかったのでOSレベルでキーバインドを変更してしまいます。
{ &amp;#34;title&amp;#34;: &amp;#34;Change ctrl+[ to ESC&amp;#34;, &amp;#34;rules&amp;#34;: [{ &amp;#34;description&amp;#34;: &amp;#34;Change ctrl+[ key to Escape key&amp;#34;, &amp;#34;manipulators&amp;#34;: [{ &amp;#34;type&amp;#34;: &amp;#34;basic&amp;#34;, &amp;#34;from&amp;#34;: { &amp;#34;key_code&amp;#34;: &amp;#34;open_bracket&amp;#34;, &amp;#34;modifiers&amp;#34;: { &amp;#34;mandatory&amp;#34;: [&amp;#34;control&amp;#34;] } }, &amp;#34;to&amp;#34;: [{ &amp;#34;key_code&amp;#34;: &amp;#34;escape&amp;#34; }] }] }] } 上記ファイルを作成すれば自動的にComplex ModificationsのAdd Rule内に項目が出てくるのでEnableをクリックするだけです。
ちなみに環境はMac (JIS配列) + 外付けUS配列キーボードでした。</description>
    </item>
    
    <item>
      <title>Laravel入門 -Laradock導入-</title>
      <link>/post/2019-04-07-Laravel%E5%85%A5%E9%96%80-Laradock%E5%B0%8E%E5%85%A5-/</link>
      <pubDate>Sun, 07 Apr 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-04-07-Laravel%E5%85%A5%E9%96%80-Laradock%E5%B0%8E%E5%85%A5-/</guid>
      <description>はじめに Laradockについて PHPを開発するのに必要なアプリが全部セットになったDocker環境。 今回はMySQL + PHP-FPM + NGINX + Laravelでいきますが、データベースにPostgreSQLを選んだり、WebサーバにApacheを選んだりかなり自由度は高いです。
ディレクトリ構成 . ├── laradock-dakoku ←Laradockのコード (docker-composeコマンドはここで実行) └── src ←Laravelのコード (コンテナに入らずエディタで編集できる) コンテナを動かすための初期設定 PROJECT=(プロジェクト名) mkdir $PROJECT cd !$ # イメージを他プロジェクトと共用しないよう名前を変える git clone https://github.com/Laradock/laradock.git laradock-$PROJECT cd laradock-$PROJECT cp env-example .env DB_HOST=mysql APP_CODE_PATH_HOST=../src # MySQL8の認証方式caching_sha2_passwordにPHPのMySQLライブラリが対応していないため MYSQL_VERSION=5.7.25 コンテナを動かす docker-compose up -d nginx mysql workspace Laravelをインストール docker-compose exec workspace bash # バージョンは好きなものを指定する。ここでは5.2系 composer create-project laravel/laravel . &amp;#34;5.2.*&amp;#34; DB migrate実行 DB_HOST=mysql DB_PORT=3306 DB_DATABASE=default DB_USERNAME=default DB_PASSWORD=secret php artisan migrate NGINX設定 cp nginx/sites/laravel.</description>
    </item>
    
    <item>
      <title>terraform importを試してみたので手順とか個人的ハマりポイントとか</title>
      <link>/post/2019-03-24-terraform-import%E3%82%92%E8%A9%A6%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F%E3%81%AE%E3%81%A7%E6%89%8B%E9%A0%86%E3%81%A8%E3%81%8B%E5%80%8B%E4%BA%BA%E7%9A%84%E3%83%8F%E3%83%9E%E3%82%8A%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%81%A8%E3%81%8B/</link>
      <pubDate>Sun, 24 Mar 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-03-24-terraform-import%E3%82%92%E8%A9%A6%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F%E3%81%AE%E3%81%A7%E6%89%8B%E9%A0%86%E3%81%A8%E3%81%8B%E5%80%8B%E4%BA%BA%E7%9A%84%E3%83%8F%E3%83%9E%E3%82%8A%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88%E3%81%A8%E3%81%8B/</guid>
      <description>terraform import手順 簡単な例でS3バケットのimportをしてみる。 先に書いておくと、terraform importは現状のAWSリソースの情報をいい感じにterraformのtfファイルに書き起こしてくれるわけではなく、tfstateファイルにリソース情報を記録してくれるだけ。 あとはterraformのドキュメントとtfstateファイルを参考にtfファイルを手書きする感じとなる。
1. importしたいリソースをmain.tfに記載 resource (リソースタイプ) (リソース名) の形式で記載する。 ※リソース名はterraform内の識別名
resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;test&amp;#34; { } 2. terraform importコマンドでterraform.tfstateファイルに状態を保存 terraform import (リソースタイプ).(リソース名) (importするリソースID)の形式でコマンドを実行する。 ※S3バケットの場合importするリソースIDはバケット名
terraform import aws_s3_bucket.test tomohiko.io ※もしエラーが出たらterraform initを実行してAWSプラグインをインストールする
3. terraform.tfstateファイルからmain.tfファイルに必要なパラメータを抜き出しmain.tfファイルに記載 terraform.tfstateファイルにimportしたリソースの状態が記録されるので、その情報とterraformのドキュメントを参考にmain.tfファイルを完成させる。
※デフォルト設定のS3を作成するだけならbucketの指定だけで大丈夫です。
resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;test&amp;#34; { bucket = &amp;#34;tomohiko.io&amp;#34; } 個人的ハマりポイント IAM Role IAM Roleを定義するためには下記3つのresourceと1つのdataを定義する必要がある。
policy
 aws_iam_role aws_iam_policy_document aws_iam_role_policy  data
 aws_iam_policy_document  自分の書いたコードの一部を抜粋するとこんな感じ。
resource &amp;quot;aws_iam_role&amp;quot; &amp;quot;IAMロール名&amp;quot; { name = &amp;quot;IAMロール名&amp;quot; assume_role_policy = &amp;quot;${data.aws_iam_policy_document.IAMロール名.json}&amp;quot; } data &amp;quot;aws_iam_policy_document&amp;quot; &amp;quot;IAMロール名&amp;quot; { statement { actions = [&amp;quot;sts:AssumeRole&amp;quot;] principals { type = &amp;quot;Service&amp;quot; identifiers = [&amp;quot;ecs-tasks.</description>
    </item>
    
    <item>
      <title>最速でLet&#39;s Encryptの証明書をGETする方法</title>
      <link>/post/2019-03-18-%E6%9C%80%E9%80%9F%E3%81%A7Lets-Encrypt%E3%81%AE%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%82%92GET%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 18 Mar 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-03-18-%E6%9C%80%E9%80%9F%E3%81%A7Lets-Encrypt%E3%81%AE%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%82%92GET%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>前提  更新したいドメインがRoute53で管理されている Route53の操作権を持つIAMロールを割り当てたEC2で作業する EC2でDockerが使える  手順 下記コマンドを実行するだけ。
sudo docker run -it --rm -e AWS_HOSTED_ZONE_ID=(対象ドメインのHosted Zone ID) -v $PWD:/app xenolf/lego --path=/app --email=&amp;#34;(メールアドレス)&amp;#34; --domains=&amp;#34;(対象のドメイン)&amp;#34; --dns route53 run 証明書がカレントディレクトリのcertificatesディレクトリ以下に保存される。</description>
    </item>
    
    <item>
      <title>New Relic {FUTURE} STACK スーパー書き殴りメモ</title>
      <link>/post/2019-03-14-New-Relic-FUTURE-STACK-%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E6%9B%B8%E3%81%8D%E6%AE%B4%E3%82%8A%E3%83%A1%E3%83%A2/</link>
      <pubDate>Thu, 14 Mar 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-03-14-New-Relic-FUTURE-STACK-%E3%82%B9%E3%83%BC%E3%83%91%E3%83%BC%E6%9B%B8%E3%81%8D%E6%AE%B4%E3%82%8A%E3%83%A1%E3%83%A2/</guid>
      <description>New Relic {Future} STACK 2019年3月14日 https://futurestack19-lp.eventcloudmix.com/
ハンズオン はじめに アプリケーション監視が特別である理由  影響を受ける要素が多い 外部サービス・DB・ユーザー入力・出力・ほかプロセス ただ動いているだけでは十分ではない マネタイズしているか  データ収集の仕組み  トランザクション（リクエスト窓口）の自動検出とパフォーマンス計測 外部プロセスとの通信の自動検出とパフォーマンス計測  やるべきこと  ビジネス目標を達成したか  Insightsで確認できる   全体のパフォーマンスを確認  ヒストグラムでデータの分布区分ごとの件数（1秒台が10件…など）を確認 パーセンタイルでデータを小さい順に並べたときの、全体の割合とその値を時系列で確認 Apdexスコア (満足の件数 + やや満足の件数の半分) / 総数   個別のトラブルシューティングもしくは全体の最適化  Trancactionsで消費時間・処理時間が遅い順でソートできる。そこから処理ごとの詳細サマリが見られる    重要なこと  トランザクションがどんな処理なのかを理解すること  Key Transactionを考慮してみる   ビジネス目標を意識すること トランザクション全体のパフォーマンスを意識する 個別事象の対応なのか、全体の最適化なのかを意識すること  個別の事象の確認: トランザクショントレース、エラーアナライティクス 全体の最適化    Insights データを分析しダッシュボードを作成
  一番簡単なダッシュボードの作成は、既存のチャートを貼り付ける。
  APMの各チャートをマウスホバーするとメニューが出る。</description>
    </item>
    
    <item>
      <title>DynamoDBのオートスケールしきい値設定をAWS CLIから行う</title>
      <link>/post/2019-02-14-DynamoDB%E3%81%AE%E3%82%AA%E3%83%BC%E3%83%88%E3%82%B9%E3%82%B1%E3%83%BC%E3%83%AB%E3%81%97%E3%81%8D%E3%81%84%E5%80%A4%E8%A8%AD%E5%AE%9A%E3%82%92AWS-CLI%E3%81%8B%E3%82%89%E8%A1%8C%E3%81%86/</link>
      <pubDate>Thu, 14 Feb 2019 12:00:00 +0000</pubDate>
      
      <guid>/post/2019-02-14-DynamoDB%E3%81%AE%E3%82%AA%E3%83%BC%E3%83%88%E3%82%B9%E3%82%B1%E3%83%BC%E3%83%AB%E3%81%97%E3%81%8D%E3%81%84%E5%80%A4%E8%A8%AD%E5%AE%9A%E3%82%92AWS-CLI%E3%81%8B%E3%82%89%E8%A1%8C%E3%81%86/</guid>
      <description>DynamoDBのオートスケール設定をAWS CLIから行う
今までブラウザのAWSコンソールからポチポチやっていましたが、必要になったので調べました。 オートスケール設定はDynamoDBではなくapplication-autoscaling経由で行うようです。
DynamoDBテーブルの確認
aws application-autoscaling describe-scaling-policies --service-namespace dynamodb --resource-id &amp;#34;table/テーブル名&amp;#34; オートスケールしきい値設定
aws application-autoscaling put-scaling-policy --service-namespace dynamodb --policy-name &amp;#34;DynamoDBReadCapacityUtilization:table/テーブル名&amp;#34; --resource-id &amp;#34;table/テーブル名&amp;#34; --scalable-dimension dynamodb:table:ReadCapacityUnits --policy-type TargetTrackingScaling --target-tracking-scaling-policy-configuration &amp;#39;{ &amp;#34;TargetValue&amp;#34;: リードの値, &amp;#34;PredefinedMetricSpecification&amp;#34;: { &amp;#34;PredefinedMetricType&amp;#34;: &amp;#34;DynamoDBReadCapacityUtilization&amp;#34; } }&amp;#39; aws application-autoscaling put-scaling-policy --service-namespace dynamodb --policy-name &amp;#34;DynamoDBWriteCapacityUtilization:table/テーブル名&amp;#34; --resource-id &amp;#34;table/テーブル名&amp;#34; --scalable-dimension dynamodb:table:WriteCapacityUnits --policy-type TargetTrackingScaling --target-tracking-scaling-policy-configuration &amp;#39;{ &amp;#34;TargetValue&amp;#34;: ライトの値, &amp;#34;PredefinedMetricSpecification&amp;#34;: { &amp;#34;PredefinedMetricType&amp;#34;: &amp;#34;DynamoDBWriteCapacityUtilization&amp;#34; } }&amp;#39; </description>
    </item>
    
    <item>
      <title>gem omniauth-google-oauth2を使ってGoogle認証を使う (Rails5版)</title>
      <link>/post/2018-12-29-gem-omniauth-google-oauth2%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6Google%E8%AA%8D%E8%A8%BC%E3%82%92%E4%BD%BF%E3%81%86-Rails5%E7%89%88/</link>
      <pubDate>Sat, 29 Dec 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-12-29-gem-omniauth-google-oauth2%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6Google%E8%AA%8D%E8%A8%BC%E3%82%92%E4%BD%BF%E3%81%86-Rails5%E7%89%88/</guid>
      <description>先日こちらの記事を参考に、omniauth-google-oauth2を使ってGoogle認証を試しました。
大体はそのままで動いたものの、記事が書かれてから２年以上立っており、動かない部分もあったため、備忘録として構築手順を残したいと思います。
リポジトリはこちら。 https://github.com/kter/qiita-omniauth-google-oauth2-test
Google側の設定 Google側の設定は参考にさせていただいた記事通りにやればほぼほぼ大丈夫です。
準備 ファイルの設置 RailsとDB(MySQL)はdocker-composeで動かすので、その設定を行います。
Dockerfile
FROM ruby:2.5.1 RUN apt-get update -qq &amp;amp;&amp;amp; apt-get install -y build-essential libpq-dev nodejs RUN mkdir /myapp WORKDIR /myapp COPY Gemfile /myapp/Gemfile COPY Gemfile.lock /myapp/Gemfile.lock RUN bundle install COPY . /myapp docker-compose.yml
version: &amp;#39;3&amp;#39; services: db: image: mysql:5.7.23 env_file: .env volumes: - ./mysql-data:/var/lib/mysql web: build: . command: bundle exec rails s -p 80 -b &amp;#39;0.0.0.0&amp;#39; volumes: - .:/myapp ports: - &amp;#34;80:80&amp;#34; depends_on: - db env_file: .</description>
    </item>
    
    <item>
      <title>AWSマネージドサービスのみでリダイレクトさせる</title>
      <link>/post/2018-11-27-AWS%E3%83%9E%E3%83%8D%E3%83%BC%E3%82%B8%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E3%81%BF%E3%81%A7%E3%83%AA%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%E3%81%95%E3%81%9B%E3%82%8B/</link>
      <pubDate>Tue, 27 Nov 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-27-AWS%E3%83%9E%E3%83%8D%E3%83%BC%E3%82%B8%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%AE%E3%81%BF%E3%81%A7%E3%83%AA%E3%83%80%E3%82%A4%E3%83%AC%E3%82%AF%E3%83%88%E3%81%95%E3%81%9B%E3%82%8B/</guid>
      <description>http通信をhttpsにリダイレクトしたり、またゾーンアペックスからサブドメインへのリダイレクト (google.com -&amp;gt; www.google.com のような)は一般だとNGINXやApacheで設定…となりますが、AWSのサービスを駆使すれば必要ありません。 それぞれ説明します。
http通信をhttpsにリダイレクト ALBを使います。 80番のターゲットグループでリダイレクトの設定を行えばOK.
ゾーンアペックスからサブドメインへのリダイレクト Route53とS3を使います。もしhttpsもリダイレクトしたい場合はCloudFrontも使います。
S3 ゾーンアペックス名でバケットを作った後、Static website hostingでリダイレクトの設定を行います。 ※バケットポリシー等の設定は不要です。
CloudFront (httpsも使う場合） S3をオリジンとしたCloudFrontを用意します。わざわざCloudFrontを利用する理由は、S3だとカスタムのhttps証明書が入らないからです。 なのでCloudFrontではhttps証明書も設定します。 ※オリジンの設定にはリストで出てくるS3ではなく、Static website hostingで出てくるエンドポイントのドメイン部分をコピペして設定します。
Route53 ゾーンアペックスのAレコードのエイリアスとしてCloudFront　(CloudFrontを使用しない場合はS3)　を指定します。</description>
    </item>
    
    <item>
      <title>Wordpressのhttps化をDB直接変更で強引に行う</title>
      <link>/post/2018-11-27-Wordpress%E3%81%AEhttps%E5%8C%96%E3%82%92DB%E7%9B%B4%E6%8E%A5%E5%A4%89%E6%9B%B4%E3%81%A7%E5%BC%B7%E5%BC%95%E3%81%AB%E8%A1%8C%E3%81%86/</link>
      <pubDate>Tue, 27 Nov 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-27-Wordpress%E3%81%AEhttps%E5%8C%96%E3%82%92DB%E7%9B%B4%E6%8E%A5%E5%A4%89%E6%9B%B4%E3%81%A7%E5%BC%B7%E5%BC%95%E3%81%AB%E8%A1%8C%E3%81%86/</guid>
      <description>Wordpressをhttps化したものの、一部ページ内の画像がhttpのままのため、ブラウザのアドレスバーに警告が出ていました。
1ページずつ修正するのは論外だし、プラグインを使うのも後々トラブルになりそうだったので、DBを直接弄って解決しました。
UPDATE wp_options SET option_value = replace(option_value, &amp;#39;http://ドメイン&amp;#39;, &amp;#39;https://ドメイン&amp;#39;) WHERE option_name = &amp;#39;home&amp;#39; OR option_name = &amp;#39;siteurl&amp;#39;; UPDATE wp_posts SET post_content = replace(post_content, &amp;#39;http://ドメイン&amp;#39;, &amp;#39;https://ドメイン&amp;#39;); UPDATE wp_postmeta SET meta_value = replace(meta_value,&amp;#39;http://ドメイン&amp;#39;,&amp;#39;https://ドメイン&amp;#39;); UPDATE wp_usermeta SET meta_value = replace(meta_value, &amp;#39;http://ドメイン&amp;#39;,&amp;#39;https://ドメイン&amp;#39;); UPDATE wp_links SET link_url = replace(link_url, &amp;#39;http://ドメイン&amp;#39;,&amp;#39;https://ドメイン&amp;#39;); UPDATE wp_comments SET comment_content = replace(comment_content , &amp;#39;http://ドメイン&amp;#39;,&amp;#39;https://ドメイン&amp;#39;); UPDATE wp_posts SET post_content = replace(post_content, &amp;#39;http://ドメイン&amp;#39;, &amp;#39;https://ドメイン&amp;#39;); UPDATE wp_links SET link_image = replace(link_image, &amp;#39;http://ドメイン&amp;#39;,&amp;#39;https://ドメイン&amp;#39;); UPDATE wp_posts SET guid = replace(guid, &amp;#39;http://ドメイン&amp;#39;,&amp;#39;https://ドメイン&amp;#39;); </description>
    </item>
    
    <item>
      <title>Amazon Redshiftのカラム属性を変更する場合の手順</title>
      <link>/post/2018-11-21-Amazon-Redshift%E3%81%AE%E3%82%AB%E3%83%A9%E3%83%A0%E5%B1%9E%E6%80%A7%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E6%89%8B%E9%A0%86/</link>
      <pubDate>Wed, 21 Nov 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-21-Amazon-Redshift%E3%81%AE%E3%82%AB%E3%83%A9%E3%83%A0%E5%B1%9E%E6%80%A7%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E6%89%8B%E9%A0%86/</guid>
      <description>Redshiftでカラムの属性を変更する場合、一旦別名で変更後の属性でカラムを作った後、リネームして既存カラムと置き換える必要があります。
下記の例ではtable_nameというテーブルに対して、column_nameというカラムのデフォルト値を変更していますが、デフォルト値以外の変更も基本同じような対応で可能です。
column_name_tmpというカラム名で新しいカラムデフォルト値を設定する。 ALTER TABLE table_name ADD COLUMN column_name_tmp VARCHAR(20) DEFAULT &amp;#39;new_default_value&amp;#39;; 既存カラム (column_name) の値を先ほど作成したcolumn_name_tmpにコピーする。 UPDATE table_name SET column_name_tmp = column_name; 既存カラムを削除する。 ALTER TABLE table_name DROP COLUMN column_name CASCADE; 新しく作成したカラムを既存カラム名にリネームする。 ALTER TABLE table_name RENAME COLUMN column_name_tmp TO column_name; 旧のデフォルト値で入っていたデータの更新 UPDATE table_name SET column_name = &amp;#39;new_default_value&amp;#39; WHERE column_name = &amp;#39;old_default_value&amp;#39;; 権限がリセットされてしまった場合はつけ直す -- user_nameに対してtable_nameテーブルの全操作を許可 grant all privileges on table_name TO user_name; -- 確認 \z </description>
    </item>
    
    <item>
      <title>AWS CLIのS3でワイルドカードを使う方法</title>
      <link>/post/2018-11-13-AWS-CLI%E3%81%AES3%E3%81%A7%E3%83%AF%E3%82%A4%E3%83%AB%E3%83%89%E3%82%AB%E3%83%BC%E3%83%89%E3%82%92%E4%BD%BF%E3%81%86%E6%96%B9%E6%B3%95/</link>
      <pubDate>Tue, 13 Nov 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-11-13-AWS-CLI%E3%81%AES3%E3%81%A7%E3%83%AF%E3%82%A4%E3%83%AB%E3%83%89%E3%82%AB%E3%83%BC%E3%83%89%E3%82%92%E4%BD%BF%E3%81%86%E6%96%B9%E6%B3%95/</guid>
      <description>AWS CLIのS3ではワイルドカードが使えないと思っていましたが、実はオプションを駆使することで使えることがわかったのでメモ。
aws s3 cp --recursive \  --exclude &amp;#39;*&amp;#39; \  --include &amp;#39;ワイルドカード入り検索文字列&amp;#39; \  s3://bucket_name/path/ . S3とかCloudFrontだとログファイルがディレクトリ掘らずに置かれてしまうのでこれでやると便利ですね。</description>
    </item>
    
    <item>
      <title>CloudFormationでSecurityGroupを作るときにYou may not define rules between a VPC group and a non-VPC groupとエラーが出るときの対応</title>
      <link>/post/2018-10-25-CloudFormation%E3%81%A7SecurityGroup%E3%82%92%E4%BD%9C%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%ABYou-may-not-define-rules-between-a-VPC-group-and-a-non-VPC-group%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%BF%9C/</link>
      <pubDate>Thu, 25 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-10-25-CloudFormation%E3%81%A7SecurityGroup%E3%82%92%E4%BD%9C%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%ABYou-may-not-define-rules-between-a-VPC-group-and-a-non-VPC-group%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%BF%9C/</guid>
      <description>CloudFormationでSecurityGroupを作るときにYou may not define rules between a VPC group and a non-VPC groupとエラーが出るときの対応
解決まで地味に30分程度掛かったのでメモ。
CloudFormationで次のような感じでSecurityGroupを作ろうとすると、You may not define rules between a VPC group and a non-VPC groupとエラーが出てSecurityGroupが作れない。
DBEC2SecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: &amp;#34;Allow access from specific SecurityGroup&amp;#34; SecurityGroupIngress: - IpProtocol: tcp FromPort: &amp;#39;3306&amp;#39; ToPort: &amp;#39;3306&amp;#39; SourceSecurityGroupId: !Ref &amp;#39;EC2SecurityGroup&amp;#39; これはSourceSecurityGroupにVPCのSecurityGroupが指定されているのに、（VpcIdが指定されていないため）EC2 Classic環境にSecurityGroupが作られようとしているため出たエラーである（言葉にするとややこしい）。
ドキュメントにもあるが正しくはこんな感じ。
DBEC2SecurityGroup: Type: AWS::EC2::SecurityGroup Properties: VpcId: !Ref VPC GroupDescription: &amp;#34;Allow access from specific SecurityGroup&amp;#34; SecurityGroupIngress: - IpProtocol: tcp FromPort: &amp;#39;3306&amp;#39; ToPort: &amp;#39;3306&amp;#39; SourceSecurityGroupId: !</description>
    </item>
    
    <item>
      <title>SlackにWebHookを送るときに&#43;記号がスペースに置き換えられる問題の対応</title>
      <link>/post/2018-10-24-Slack%E3%81%ABWebHook%E3%82%92%E9%80%81%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB&#43;%E8%A8%98%E5%8F%B7%E3%81%8C%E3%82%B9%E3%83%9A%E3%83%BC%E3%82%B9%E3%81%AB%E7%BD%AE%E3%81%8D%E6%8F%9B%E3%81%88%E3%82%89%E3%82%8C%E3%82%8B%E5%95%8F%E9%A1%8C%E3%81%AE%E5%AF%BE%E5%BF%9C/</link>
      <pubDate>Wed, 24 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-10-24-Slack%E3%81%ABWebHook%E3%82%92%E9%80%81%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AB&#43;%E8%A8%98%E5%8F%B7%E3%81%8C%E3%82%B9%E3%83%9A%E3%83%BC%E3%82%B9%E3%81%AB%E7%BD%AE%E3%81%8D%E6%8F%9B%E3%81%88%E3%82%89%E3%82%8C%E3%82%8B%E5%95%8F%E9%A1%8C%E3%81%AE%E5%AF%BE%E5%BF%9C/</guid>
      <description>SlackにWebHookを送るときに+記号がスペースに置き換えられる問題の対応です。 この問題の解決に1,2時間掛かったのでメモしておきます…。
こんな感じでSlackにWebHookを送ろうと思っていたのですが、この例では+の部分がスペースに置き換わってしまいす。
$params = [ &amp;#39;title&amp;#39; =&amp;gt; &amp;#34;タイトル&amp;#34;, &amp;#39;text&amp;#39; =&amp;gt; &amp;#34;プラス記号がスペースに置き換わる→+←&amp;#34;, &amp;#39;channel&amp;#39; =&amp;gt; $channel, &amp;#39;username&amp;#39; =&amp;gt; $username, &amp;#39;icon_emoji&amp;#39; =&amp;gt; $icon_emoji, &amp;#39;mrkdwn&amp;#39; =&amp;gt; true, &amp;#39;attachments&amp;#39; =&amp;gt; [$attachments] ]; $payload = &amp;#39;payload=&amp;#39; . json_encode($params); $ch = curl_init($webhook_url); curl_setopt($ch, CURLOPT_POST, true); curl_setopt($ch, CURLOPT_POSTFIELDS, $payload); curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, true); curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 2); curl_setopt($ch, CURLOPT_RETURNTRANSFER, true); $result = curl_exec($ch); バッククォートやダブルクォーテーションで括っても結果は同じ。 いろいろ試したり検索したりしていくうちにURLエンコードをすれば良いことに気が付きました。
ということでこのようにして解決。
&amp;#39;text&amp;#39; =&amp;gt; urlencode(&amp;#34;プラス記号がスペースに置き換わる→+←&amp;#34;), 後からよくよく調べてみるとドキュメントにちゃんとURLエンコードしろと書いてありました… https://api.slack.com/docs/message-formatting</description>
    </item>
    
    <item>
      <title>Analytics Architecture Night - Tokyo 201810自分用メモ</title>
      <link>/post/2018-10-05-Analytics-Architecture-Night-Tokyo-201810%E8%87%AA%E5%88%86%E7%94%A8%E3%83%A1%E3%83%A2/</link>
      <pubDate>Fri, 05 Oct 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-10-05-Analytics-Architecture-Night-Tokyo-201810%E8%87%AA%E5%88%86%E7%94%A8%E3%83%A1%E3%83%A2/</guid>
      <description>Serverless Analytics on AWS アマゾン ウェブ サービス ジャパン株式会社 Analytics Specialist SA 志村 誠
サーバレスはセキュアでもある  パッチが適用されていないサーバーは存在しない SSHもできない  サーバーレスな分析 下回りを気にせず、やりたいことに集中
 データ収集: 設定だけで後は自動でデータを収集 データ管理: データのスキーマを自動で登録・更新 ETL: 処理を記述したスクリプトだけで前処理を実行 クエリ: SQLだけで自由に分析 可視化: ブラウザから簡単にGUIで可視化  AWSの分析サービス 複数あるが、最近のサービスであればサーバーレスに近い
Amazon Kinesis Data フルマネージド型リアルタイム大規模ストリーミング処理 KDS: ストリームデータを収集し、公団で各種分析やデータ保存を実施 KDF: ストリームを収集し、S3/Redshift/ES/Splunkに簡単に配信 KDA: 上記2つからストリームを取得しSQLを実施
AWS Glue 完全マネージド型ETLサービス Spark/PythonジョブによるETLを実行
Amazon Athena インタラクティブなクエリサービス クエリエンジンとしてPrestoを用いS3上のデータに直接クエリを実行 実行した分だけ課金
Amazon QuickSight 高速なSPICEエンジンと直感的な操作、専門家不要のBI 最大5ドル 1セッション30分で$0.3
GlueベースのS3データレイク 各種データソースのカタログをGlueで一元的に管理 S3上のデータをAthena/Redshift Spectrum/EMRで分析
CSV/TSV/JSONをParquetに変換すると効率が良い。 -&amp;gt; S3ファイル追加のイベントトリガーでLambdaを起動してGlueジョブを実行するとよい -&amp;gt; Kinesis FirehoseはParquetで出力できる
 ジョブワークフローの構築はStep Functionsで  使い分けのポイント Glue/Athenaはあえて選択肢を絞ったり、チューニングの要素を絞ったりすることで、運用の負荷を下げ、本来の目的(ETL/分析)に集中できるようにしている。 まずはサーバーレス分析サービスでやりたいことが実現可能かどうか？ それでもだめならRedshift等使う</description>
    </item>
    
    <item>
      <title>CloudFormationで作るCodePipelineで継続的デリバリされるECSクラスタを考えてみた</title>
      <link>/post/2018-09-30-CloudFormation%E3%81%A7%E4%BD%9C%E3%82%8BCodePipeline%E3%81%A7%E7%B6%99%E7%B6%9A%E7%9A%84%E3%83%87%E3%83%AA%E3%83%90%E3%83%AA%E3%81%95%E3%82%8C%E3%82%8BECS%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E8%80%83%E3%81%88%E3%81%A6%E3%81%BF%E3%81%9F/</link>
      <pubDate>Sun, 30 Sep 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-09-30-CloudFormation%E3%81%A7%E4%BD%9C%E3%82%8BCodePipeline%E3%81%A7%E7%B6%99%E7%B6%9A%E7%9A%84%E3%83%87%E3%83%AA%E3%83%90%E3%83%AA%E3%81%95%E3%82%8C%E3%82%8BECS%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E8%80%83%E3%81%88%E3%81%A6%E3%81%BF%E3%81%9F/</guid>
      <description>CloudFormationで作るCodePipelineで継続的デリバリされるECSクラスタを考えてみました。
前提  リポジトリにはGitHubを使う CloudFormationで環境一式が作成される ECSは単一タスク定義にコンテナ2つ  WebとAppコンテナ   CodepipelineはWeb, Appコンテナ用それぞれ用意  コンポーネント GitHub リポジトリを分けます。分ける理由はファイル更新時のデリバリー範囲を狭めるためです (Webコンテナの設定変更だけならAppコンテナは反映しない)。
 learning_of_codepipeline_ecs  CloudFormation設定ファイル   learning_of_codepipeline_ecs_app  Appコンテナ用 Dockerfile Appコンテナ用 Codebuild設定ファイル   learning_of_codepipeline_ecs_web  Webコンテナ用 Dockerfile Webコンテナ用 Codebuild設定ファイル    CloudFormation 下記リソースの作成を行います。
 CodePipeline CodeBuild  App, WebコンテナイメージをビルドしてECRにPush   ECSクラスタ  App, Webコンテナを動かす    CodePipeline 単一PipelineでApp, WebコンテナのビルドとECSへのデプロイをやろうと思ったのですが、下記問題があったのでWebとAppで別のPipelineにしました。
 Web, Appどちらかの更新で両方のビルドが始まってしまう ECSへのデプロイ時に片方が常に失敗する  成果物 CodePipeline https://github.com/kter/learning_of_codepipeline_ecs Webコンテナ用 https://github.com/kter/learning_of_codepipeline_ecs_web Appコンテナ用 https://github.</description>
    </item>
    
    <item>
      <title>Kibana&#43;ElasticSearchで検索した時Courier Fetch: X of Y shards failedとエラーが出てしまったときの対処</title>
      <link>/post/2018-09-26-Kibana&#43;ElasticSearch%E3%81%A7%E6%A4%9C%E7%B4%A2%E3%81%97%E3%81%9F%E6%99%82Courier-Fetch-X-of-Y-shards-failed%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%81%A6%E3%81%97%E3%81%BE%E3%81%A3%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%87%A6/</link>
      <pubDate>Wed, 26 Sep 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-09-26-Kibana&#43;ElasticSearch%E3%81%A7%E6%A4%9C%E7%B4%A2%E3%81%97%E3%81%9F%E6%99%82Courier-Fetch-X-of-Y-shards-failed%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%81%A6%E3%81%97%E3%81%BE%E3%81%A3%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%87%A6/</guid>
      <description>Kibana+ElasticSearchで検索した時、Courier Fetch: X of Y shards failedとエラーが出てしまったときの対処
結論から言うとおかしなインデックスを削除したら直りました。
1. インデックスを確認 curl localhost:9200/_cat/shards?v | awk &#39;{ print $1 }&#39; | sort | uniq index .kibana logstash-2018.09.12 logstash-2018.09.13 logstash-2018.09.14 logstash-2018.09.15 logstash-2018.09.16 logstash-2018.09.17 logstash-2018.09.18 logstash-2018.09.19 logstash-2018.09.20 logstash-2018.09.21 logstash-2018.09.22 logstash-2018.09.23 logstash-2018.09.24 logstash-2018.09.25 logstash-2018.09.26 logstash-503830.12.31 # こんな感じの変なインデックスがある 2. インデックスの削除 curl -XDELETE localhost:9200/logstash-503830.12.31?pretty 3. 再起動 service elasticsearch restart こうなった原因ははっきりとはしませんが、直近で大量のドキュメントがElasticSearchに流れ込み、負荷が高い状態が続いた時があったので、そのときにインデックスが変になってしまったのかもしれません。</description>
    </item>
    
    <item>
      <title>ElasticSearchコマンドメモ</title>
      <link>/post/2018-09-21-ElasticSearch%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A1%E3%83%A2/</link>
      <pubDate>Fri, 21 Sep 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-09-21-ElasticSearch%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A1%E3%83%A2/</guid>
      <description>絶対忘れるので使ったコマンドを書いておく。
ElasticSearch 5.5で確認
インデックスを確認
curl -XGET localhost:9200/_cat/indices 指定したフィールドを取得
curl -XGET &#39;http://localhost:9200/(インデックス名)/_search?pretty&#39; -d &#39; { &amp;quot;_source&amp;quot;: [ &amp;quot;(取得するフィールド名1)&amp;quot;, &amp;quot;(取得するフィールド名2)&amp;quot;] }&#39; 指定フィールドから指定文字列を検索
curl -XGET &#39;http://localhost:9200/(インデックス名)/_search?pretty&#39; -d &#39; { &amp;quot;_source&amp;quot;: [ &amp;quot;(取得するフィールド名1)&amp;quot;, &amp;quot;(取得するフィールド名2)&amp;quot;], &amp;quot;query&amp;quot;:{ &amp;quot;match&amp;quot;:{ &amp;quot;(検索フィールド名)&amp;quot;: { &amp;quot;query&amp;quot;: &amp;quot;(検索文字列)&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;phrase&amp;quot; } } } }&#39; 指定フィールドから指定文字列を検索 (AND検索)
curl -XGET &#39;http://localhost:9200/(インデックス名)/_search?pretty&#39; -d &#39; { &amp;quot;_source&amp;quot;: [ &amp;quot;(取得するフィールド名1)&amp;quot;, &amp;quot;(取得するフィールド名2)&amp;quot;], &amp;quot;query&amp;quot;:{ &amp;quot;bool&amp;quot;:{ &amp;quot;must&amp;quot;: [ { &amp;quot;match&amp;quot;:{ &amp;quot;(検索フィールド名)&amp;quot;: { &amp;quot;query&amp;quot;: &amp;quot;(検索文字列)&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;phrase&amp;quot; } } }, { &amp;quot;match&amp;quot;:{ &amp;quot;(検索フィールド名)&amp;quot;: { &amp;quot;query&amp;quot;: &amp;quot;(検索文字列)&amp;quot;, &amp;quot;type&amp;quot;: &amp;quot;phrase&amp;quot; } } } ] } } }&#39; 指定フィールドから指定文字列を検索 (OR検索)</description>
    </item>
    
    <item>
      <title>Debian Jessie以降でDockerをインストールする</title>
      <link>/post/2018-09-17-Debian-Jessie%E4%BB%A5%E9%99%8D%E3%81%A7Docker%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B/</link>
      <pubDate>Mon, 17 Sep 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-09-17-Debian-Jessie%E4%BB%A5%E9%99%8D%E3%81%A7Docker%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B/</guid>
      <description>Debian Jessie以降で下記コマンドを順に実行するとDockerがインストールできます。
詳細はこちらの公式サイトを参照してください。
sudo apt-get update sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - # 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88で終わることを確認 sudo apt-key fingerprint 0EBFCD88 sudo add-apt-repository &amp;quot;deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable&amp;quot; sudo apt-get update sudo apt-get install docker-ce # 動作確認 sudo docker run hello-world </description>
    </item>
    
    <item>
      <title>AWS SAMのLambda (Python)で環境変数で設定した値を配列で受け取る</title>
      <link>/post/2018-09-08-AWS-SAM%E3%81%AELambda-Python%E3%81%A7%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%81%A7%E8%A8%AD%E5%AE%9A%E3%81%97%E3%81%9F%E5%80%A4%E3%82%92%E9%85%8D%E5%88%97%E3%81%A7%E5%8F%97%E3%81%91%E5%8F%96%E3%82%8B/</link>
      <pubDate>Sat, 08 Sep 2018 16:28:02 +0000</pubDate>
      
      <guid>/post/2018-09-08-AWS-SAM%E3%81%AELambda-Python%E3%81%A7%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%81%A7%E8%A8%AD%E5%AE%9A%E3%81%97%E3%81%9F%E5%80%A4%E3%82%92%E9%85%8D%E5%88%97%E3%81%A7%E5%8F%97%E3%81%91%E5%8F%96%E3%82%8B/</guid>
      <description>環境変数に設定された値は文字列としてしか取得できません。
なのでos.getenv()で値を取得したあとsplit()で配列化します。 ついでにstrip()も呼んでスペースも除去します。コードはこんな感じです。
array = [x.strip() for x in str(os.getenv(&amp;#39;(環境変数名)&amp;#39;)).split(&amp;#39;,&amp;#39;)] yamlファイルはこんな感じです。
Resources: Lambda: Type: &amp;#39;AWS::Serverless::Function&amp;#39; Properties: Handler: lambda_function.lambda_handler Runtime: python3.6 CodeUri: . MemorySize: 128 Role: Fn::GetAtt: - LambdaRole - Arn Timeout: 3 Environment: Variables: (環境変数名): &amp;#39;val1, val2, val3&amp;#39; </description>
    </item>
    
    <item>
      <title>AWS S3 Glacierからリストアしてファイルをダウンロードする</title>
      <link>/post/2018-09-06-AWS-S3-Glacier%E3%81%8B%E3%82%89%E3%83%AA%E3%82%B9%E3%83%88%E3%82%A2%E3%81%97%E3%81%A6%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 06 Sep 2018 22:31:02 +0000</pubDate>
      
      <guid>/post/2018-09-06-AWS-S3-Glacier%E3%81%8B%E3%82%89%E3%83%AA%E3%82%B9%E3%83%88%E3%82%A2%E3%81%97%E3%81%A6%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/</guid>
      <description>まとめ Glacier状態のS3オブジェクトを取り出す際には、リストア期間を指定した上でrestore-objectを実行する必要があります。
手順 リストア recursiveオプションが無いため、list-objectsしてオブジェクトパスを取得してからrestore-objectを実行します。
for key in `aws s3api list-objects --bucket (バケット名) --prefix (ディレクトリ名) --output json | jq -r &amp;#39;.Contents[].Key&amp;#39;`; do echo $key; aws s3api restore-object --bucket (バケット名) --key $key --restore-request &amp;#39;{&amp;#34;Days&amp;#34;: 3}&amp;#39;;done ダウンロード リストア済みのオブジェクトをダウンロードするときもresursiveが使えないため、list-objectsしてオブジェクトパスを取得してからダウンロードします。
for key in `aws s3api list-objects --bucket (バケット名) --prefix (ディレクトリ名) --output json | jq -r &amp;#39;.Contents[].Key&amp;#39;`; do echo $key; aws s3 cp s3://(バケット名)/$key .;done </description>
    </item>
    
    <item>
      <title>自分用AWS クラウドサービス活用資料集メモ AWS Lambda編</title>
      <link>/post/2018-09-06-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-AWS-Lamda%E7%B7%A8/</link>
      <pubDate>Thu, 06 Sep 2018 12:00:00 +0000</pubDate>
      
      <guid>/post/2018-09-06-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-AWS-Lamda%E7%B7%A8/</guid>
      <description>AWS Lambdaとは  インフラを一切期にすることなくアプリケーションコードを実行できるコンピュートサービス  実行基盤はすべてAWSが管理 AWSサービスと連携し、イベントドリブンなアプリケーションを作れる コード実行時間に対して課金    →やりたいことだけに集中できる
ユースケース  S3のバケットに画像が保存されたらサムネイルイメージを用意 DynamoDBに保存されるアドレスが全て正しい形式化チェックしたい  詳細  対応言語  JavaScript Java Python Go   メモリ容量に応じてCPU能力が変動 隔離されたコンテナ内で実行される 対応起動トリガー  API Gateway AWS IoT Alexa Skills Kit Alexa Smarat Home CloudFront CloudWatch Events CloudWatch Logs CodeCommit Cognito Sync Trigger DynamoDB Kinesis S3 SNS SQS   モバイル・WebアプリからSDKを利用して呼び出すこともできる  モバイルSDK経由の実行だとデバイス、アプリ、アイデンティティ情報にアクセス可能   同期実行と非同期実行が選べる  非同期実行の場合レスポンスはリクエストが正常に受け付けられたかどうかのみ   DynamoDBとKinesisのイベントはLambdaが自動的に取得しに行く（PULLモデル)  Lambdaが取得しに行くのでその権限が必要    </description>
    </item>
    
    <item>
      <title>July Tech Festa 2018メモ</title>
      <link>/post/2018-08-25-July-Tech-Festa-2018%E3%83%A1%E3%83%A2/</link>
      <pubDate>Sat, 25 Aug 2018 15:01:02 +0000</pubDate>
      
      <guid>/post/2018-08-25-July-Tech-Festa-2018%E3%83%A1%E3%83%A2/</guid>
      <description>自分用のメモですので悪しからず…
Ansible with AWX ~ Move to the next step of IT automation ~ 斉藤秀喜さん (twitter: saito_hideki)
 AWX(自動化プラットフォームでAnsible Towerのアップストリーム版)  Ansibleコマンドのラッパーとして動作する ドキュメントはAnsible Towerの物を見れば良い（日本語版もある）   下記機能がある  WebUI / Restful API / Callback URL機能 ユーザ管理機能（Active Directory, Google OAuth2など） ターゲットホストの認証情報を一点管理 AWS / GCP / Azure / OpenStackなどと連携可能 GitHub / Gitlabなどの外部SCM上のPlaybookを取得 複数のジョブ（Playbook)をワークフローとして実行  失敗したらこのジョブを動かすなどといった動作ができる   ジョブやワークフローを指定の日時で実行 ジョブの結果をIRCやSlackなどに送信 ログをlogstashやsplunkなど外部システムに転送 AWXサービスをクラスタ化（HAではなくマルチノード構成）   dockerとpython-docker-pyが必要（Ansible Towerと違ってコンテナ上で動く） AWX自体のインストールもAnsible Playbookで行う  副業で収益化をめざす ~月数百円から始めるWebサービス立ち上げから運営まで~ 高宮安仁さん
  有給消化中でLingomineという英語学習サービスを開発。</description>
    </item>
    
    <item>
      <title>JMeterでHTTPプロキシサーバーを使いHTTPSサイトでもシナリオの自動作成を行う</title>
      <link>/post/2018-08-20-JMeter%E3%81%A7HTTP%E3%83%97%E3%83%AD%E3%82%AD%E3%82%B7%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%82%92%E4%BD%BF%E3%81%84HTTPS%E3%82%B5%E3%82%A4%E3%83%88%E3%81%A7%E3%82%82%E3%82%B7%E3%83%8A%E3%83%AA%E3%82%AA%E3%81%AE%E8%87%AA%E5%8B%95%E4%BD%9C%E6%88%90%E3%82%92%E8%A1%8C%E3%81%86/</link>
      <pubDate>Mon, 20 Aug 2018 10:46:02 +0000</pubDate>
      
      <guid>/post/2018-08-20-JMeter%E3%81%A7HTTP%E3%83%97%E3%83%AD%E3%82%AD%E3%82%B7%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC%E3%82%92%E4%BD%BF%E3%81%84HTTPS%E3%82%B5%E3%82%A4%E3%83%88%E3%81%A7%E3%82%82%E3%82%B7%E3%83%8A%E3%83%AA%E3%82%AA%E3%81%AE%E8%87%AA%E5%8B%95%E4%BD%9C%E6%88%90%E3%82%92%E8%A1%8C%E3%81%86/</guid>
      <description>JMeterにはプロキシを使ったシナリオの自動作成機能があります。
プロキシの使い方を紹介しているサイトによってはHTTPSはJMeter単体ではできないと書いてあるのですが、単体でできたので手順をメモします。
手順 1. 記録するHTTPSリクエストを置く空のスレッドグループを作成 2. 記録用のプロキシサーバを作成 3. プロキシサーバの設定 &amp;ldquo;対象となるコントローラ&amp;quot;に、先の手順で作成したスレッドグループを指定します。
その後&amp;quot;開始&amp;quot;ボタンを押下します。
プロキシ用のダミー証明書についての説明が書かれています。OKボタンを押下します。
4. ダミー証明書をインストール JMeterのbinディレクトリ内に生成されたApacheJMeterTemporaryRootCA.crtファイルをダブルクリックで開きます。
キーチェーンが開きますので、選択されている_ DO NOT INSTALLで始まる証明書ファイルを右クリックして&amp;quot;情報を見る&amp;quot;を押下します。
5. 証明書を信頼 開いたウインドウの&amp;quot;信頼&amp;quot;タブの&amp;quot;この証明書を使用する時&amp;quot;のプルダウンで&amp;quot;常に信頼&amp;quot;を選択します。
ウインドウを閉じるときにパスワードが求められるので入力します。
6. プロキシ設定 システム環境設定のネットワークを押下します。
詳細ボタンを押下します。
&amp;ldquo;プロキシ&amp;quot;タブを開き、&amp;ldquo;保護されたWebプロキシ (HTTPS)&amp;ldquo;を選択し、&amp;ldquo;保護されたWebプロキシサーバ&amp;quot;にlocalhostを入力し、OKを押下する。
7. プロキシを通じてページにアクセスする プロキシの設定ができたのでWebページにアクセスします。
するとスレッドグループの配下にHTTPリクエストが追加されます。
8. 最後に プロキシの利用が終わったら環境設定の&amp;quot;保護されたWebプロキシ (HTTPS)&amp;ldquo;のチェックを外します。</description>
    </item>
    
    <item>
      <title>AWS Lambda (Python) からCloudFormationのスタック作成・削除を行う</title>
      <link>/post/2018-08-18-AWS-Lambda-Python-%E3%81%8B%E3%82%89CloudFormation%E3%81%AE%E3%82%B9%E3%82%BF%E3%83%83%E3%82%AF%E4%BD%9C%E6%88%90%E5%89%8A%E9%99%A4%E3%82%92%E8%A1%8C%E3%81%86/</link>
      <pubDate>Sat, 18 Aug 2018 15:08:02 +0000</pubDate>
      
      <guid>/post/2018-08-18-AWS-Lambda-Python-%E3%81%8B%E3%82%89CloudFormation%E3%81%AE%E3%82%B9%E3%82%BF%E3%83%83%E3%82%AF%E4%BD%9C%E6%88%90%E5%89%8A%E9%99%A4%E3%82%92%E8%A1%8C%E3%81%86/</guid>
      <description>業務時間だけ使うAWSリソースがあり、それをCloudFormationを使って管理しているという場合、Lambdaからスタックの作製・削除ができると便利です。
削除するのは簡単なのですが、作成するときは少し手こずったのでそれを書いておきます。
作成 TemplateURLにS3バケット内のファイルを指定する場合は次のようにします。 ※httpsとスキームが付きますが、Webホスティングの設定は必要ありません。
https://s3-ap-northeast-1.amazonaws.com/(S3バケット名)/ファイル名 ということで作成するときはこんな感じになります。
cf = boto3.client(&amp;#39;cloudformation&amp;#39;) res = cf.create_stack( StackName=(スタック名), TemplateURL=&amp;#39;https://s3-ap-northeast-1.amazonaws.com/(S3バケット名)/ファイル名&amp;#39;, Parameters=[ { &amp;#39;ParameterKey&amp;#39;: &amp;#39;パラメータ名1&amp;#39;, &amp;#39;ParameterValue&amp;#39;: &amp;#39;設定値1&amp;#39; }, { &amp;#39;ParameterKey&amp;#39;: &amp;#39;パラメータ名2&amp;#39;, &amp;#39;ParameterValue&amp;#39;: &amp;#39;設定値2&amp;#39; }, ], Capabilities=[ &amp;#39;CAPABILITY_NAMED_IAM&amp;#39;, ], ) 削除 削除はスタック名を指定するだけなのでとても簡単。
cf = boto3.client(&amp;#39;cloudformation&amp;#39;) res = cf.delete_stack( StackName=(スタック名) ) </description>
    </item>
    
    <item>
      <title>AWS CLIでMFAを使う</title>
      <link>/post/2018-07-28-AWS-CLI%E3%81%A7MFA%E3%82%92%E4%BD%BF%E3%81%86/</link>
      <pubDate>Sat, 28 Jul 2018 15:15:00 +0000</pubDate>
      
      <guid>/post/2018-07-28-AWS-CLI%E3%81%A7MFA%E3%82%92%E4%BD%BF%E3%81%86/</guid>
      <description>MFA設定後、AWS CLIからMFAを使うためには一時的なクレデンシャルを発行する必要があります。
前提 IAMポリシーにこんな感じでConditionを設定するとMFAが有効になっていない時の設定を行うことができます。
ここで例えばEffectをDenyに、Actionをiam:DeleteUserとすると、MFA認証なしではDeleteUserができなくなります。
&amp;#34;Condition&amp;#34;: { &amp;#34;Bool&amp;#34;: { &amp;#34;aws:MultiFactorAuthPresent&amp;#34;: &amp;#34;false&amp;#34; } } MFAを設定しておけば、AWSマネジメントコンソールにログインしようとするとMFAのコード入力画面が勝手に出てきますが、AWS CLIの場合は出てきません。
本題 どうするのかというと次のコマンドを実行し、一時的なクレデンシャルを発行します。
aws sts get-session-token --serial-number (登録MFAのARN 例：arn:aws:iam::500000000:mfa/kter) --token-code (MFAコード) 環境変数にクレデンシャルを突っ込むワンライナーはこちら。
eval `aws sts get-session-token --serial-number (登録MFAのARN) --token-code (MFAコード) | awk &amp;#39; $1 == &amp;#34;\&amp;#34;AccessKeyId\&amp;#34;:&amp;#34; { gsub(/\&amp;#34;/,&amp;#34;&amp;#34;); gsub(/,/,&amp;#34;&amp;#34;); print &amp;#34;export AWS_ACCESS_KEY_ID=&amp;#34;$2 } $1 == &amp;#34;\&amp;#34;SecretAccessKey\&amp;#34;:&amp;#34; { gsub(/\&amp;#34;/,&amp;#34;&amp;#34;); gsub(/,/,&amp;#34;&amp;#34;); print &amp;#34;export AWS_SECRET_ACCESS_KEY=&amp;#34;$2 } $1 == &amp;#34;\&amp;#34;SessionToken\&amp;#34;:&amp;#34; { gsub(/\&amp;#34;/,&amp;#34;&amp;#34;); gsub(/,/,&amp;#34;&amp;#34;); print &amp;#34;export AWS_SESSION_TOKEN=&amp;#34;$2 } &amp;#39;` 参考にさせていただいたページ https://www.slideshare.net/tetsunorinishizawa/aws-cliassume-role</description>
    </item>
    
    <item>
      <title>機密情報をLambdaで使いたいとき</title>
      <link>/post/2018-07-26-%E6%A9%9F%E5%AF%86%E6%83%85%E5%A0%B1%E3%82%92Lambda%E3%81%A7%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%84%E3%81%A8%E3%81%8D/</link>
      <pubDate>Thu, 26 Jul 2018 00:48:00 +0000</pubDate>
      
      <guid>/post/2018-07-26-%E6%A9%9F%E5%AF%86%E6%83%85%E5%A0%B1%E3%82%92Lambda%E3%81%A7%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%84%E3%81%A8%E3%81%8D/</guid>
      <description>AWS Systems Manager パラメータストアを使いましょう。
ソースコードに書きたくない、環境変数にも残したくない。そういったときにパラメータストアが役に立ちます。
パラメータストアでは暗号化もサポートしているので、機密情報はこれを使って保存します。
パラメータストア自体の使い方はGUIからできるので省略しますが、Lambda(Python)では次のような感じでサクッと利用することができます。
ssm = boto3.client(&#39;ssm&#39;) ssm_response = ssm.get_parameters( Names = [ (パラメータストアキー名), ], WithDecryption=True ) print(ssm_response[&#39;Parameters&#39;][0][&#39;Value&#39;]) IAMポリシーはこんな感じです。
{ &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Action&amp;quot;: [ &amp;quot;ssm:GetParameters&amp;quot; ], &amp;quot;Resource&amp;quot;: [ &amp;quot;arn:aws:ssm:*:*:parameter/(パラメータストアキー名)&amp;quot; ], &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot; } ] } </description>
    </item>
    
    <item>
      <title>Lambda (Python) から特定のログストリームにログを書こうとして苦戦した2つのポイント</title>
      <link>/post/2018-07-17-Lambda-Python-%E3%81%8B%E3%82%89%E7%89%B9%E5%AE%9A%E3%81%AE%E3%83%AD%E3%82%B0%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC%E3%83%A0%E3%81%AB%E3%83%AD%E3%82%B0%E3%82%92%E6%9B%B8%E3%81%93%E3%81%86%E3%81%A8%E3%81%97%E3%81%A6%E8%8B%A6%E6%88%A6%E3%81%97%E3%81%9F2%E3%81%A4%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88/</link>
      <pubDate>Tue, 17 Jul 2018 22:48:00 +0000</pubDate>
      
      <guid>/post/2018-07-17-Lambda-Python-%E3%81%8B%E3%82%89%E7%89%B9%E5%AE%9A%E3%81%AE%E3%83%AD%E3%82%B0%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC%E3%83%A0%E3%81%AB%E3%83%AD%E3%82%B0%E3%82%92%E6%9B%B8%E3%81%93%E3%81%86%E3%81%A8%E3%81%97%E3%81%A6%E8%8B%A6%E6%88%A6%E3%81%97%E3%81%9F2%E3%81%A4%E3%81%AE%E3%83%9D%E3%82%A4%E3%83%B3%E3%83%88/</guid>
      <description>Lambda (Python) から指定のログストリームにログを書こうとして苦戦したのでメモ。
今日使い始めたばかりなので間違ってる点があるかもしれません。もし間違っていたら教えてくださいm(_ _)m
苦戦ポイント1 -put_log_events()の使い方- 結論から言って次のようにする必要があります。
logs_client = boto3.client(&amp;#39;logs&amp;#39;) res = logs_client.describe_log_streams( logGroupName=&amp;#39;(ロググループ名)&amp;#39;, logStreamNamePrefix=&amp;#39;(ログストリーム名)&amp;#39;, ) seq_token = res[&amp;#39;logStreams&amp;#39;][0][&amp;#39;uploadSequenceToken&amp;#39;] res = logs_client.put_log_events( logGroupName=&amp;#39;(ロググループ名)&amp;#39;, logStreamName=&amp;#39;(ログストリーム名)&amp;#39;, logEvents=[ { &amp;#39;timestamp&amp;#39;: int(time.time()) * 1000, &amp;#39;message&amp;#39;: &amp;#39;%sbacked up successfully&amp;#39; % (message) }, ], sequenceToken=seq_token ) 注意する点が2点ほどあります。
timestampの指定 まず1点目、timestampはUNIX時間に1000を掛けたものを整数で指定しましょう。つまり単位がミリ秒です。
sequenceToken 2点目、ログを書き出すput_log_events()にはsequenceTokenというパラメータが必要になります。 ログストリームへの初回の書き込みなら（多分）いらないのですが、2回目以降は必要になります。
上記コードではsequenceTokenをdescribe_log_streams()から取得していますが、put_log_events()のレスポンスの中にもありますのでそれを使ってもいいです。
苦戦ポイント2 -IAM ポリシー- 結論から言って次のようにする必要があります。
{ &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Action&amp;#34;: [ &amp;#34;logs:CreateLogGroup&amp;#34;, &amp;#34;logs:CreateLogStream&amp;#34;, &amp;#34;logs:PutLogEvents&amp;#34;, ], &amp;#34;Resource&amp;#34;: [ &amp;#34;arn:aws:logs:*:*:/aws/lambda/(Lambda関数名☆ワイルドカード可☆)&amp;#34;, &amp;#34;arn:aws:logs:*:*:log-group:(ロググループ名):log-stream:(ログストリーム名)&amp;#34; ], &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34; }, { &amp;#34;Action&amp;#34;: [ &amp;#34;logs:DescribeLogStreams&amp;#34; ], &amp;#34;Resource&amp;#34;: [ &amp;#34;arn:aws:logs:*:*:*&amp;#34; ], &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34; } ] } ポリシーについて先に説明させていただきますと、最初のCreateLogGroup, CreateLogStream, PutLogEventsはCloudWatch Logsにログを書き出す（ログストリームの作成も）時に必要です。</description>
    </item>
    
    <item>
      <title>Smart Forfourに乗ったので感想</title>
      <link>/post/2018-07-02-Smart-Forfour%E3%81%AB%E4%B9%97%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E3%81%AE%E3%81%A7%E6%84%9F%E6%83%B3/</link>
      <pubDate>Mon, 02 Jul 2018 15:19:00 +0000</pubDate>
      
      <guid>/post/2018-07-02-Smart-Forfour%E3%81%AB%E4%B9%97%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E3%81%AE%E3%81%A7%E6%84%9F%E6%83%B3/</guid>
      <description>Smart Forfour BRABUS sportsに乗ったので感想をメモ。
市街地40kmほど走りましたが、エアコンの重度使用と渋滞のため燃費は8Lほどだったと思います。
BRABUSという名を冠するだけあってかなりスポーティーな印象でした。
高速走行はできなかったものの、エンジンのポテンシャルは十分感じられました。
パドルシフトがついているため、マニュアルモードにすると気持ちのいい走りができます。
一方でユーザビリティや乗り心地はスポイルされてしまって、日常使いにはあまり向かないかなとも思いました。
しかし、このコンパクトなサイズでこれまでのスポーティな車はなかなかないのでそういった意味では貴重な車かと思います。
Pros  車体のサイズが小さくて取り回しがしやすい。小回りも効く (最小回転半径4.1m) エクステリアが個性的 排気量900ccながら元気のいい走り  Cons  ハイオクのため給油代が高い 燃費がかなり悪い エンジンがトランクの下にあるため、音は小さい サスペンションがかなり高めで、路面の凹凸をよく拾う アクセルペダルとブレーキペダルの間隔がかなり狭く、ブレーキが踏みづらい 20km/h付近のアクセルコントロールが鋭敏  MTで1速のまま半クラッチにせずにアクセルオン・オフしたときのような感じ    </description>
    </item>
    
    <item>
      <title>Audi A1に乗ったので感想</title>
      <link>/post/2018-07-01-Audi-A1%E3%81%AB%E4%B9%97%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E3%81%AE%E3%81%A7%E6%84%9F%E6%83%B3/</link>
      <pubDate>Sun, 01 Jul 2018 15:19:00 +0000</pubDate>
      
      <guid>/post/2018-07-01-Audi-A1%E3%81%AB%E4%B9%97%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E3%81%AE%E3%81%A7%E6%84%9F%E6%83%B3/</guid>
      <description>Audi A1 Sportback 1.0 TFSIに乗ったので感想をメモ。
一般・高速道路含め300kmほど走りましたが、燃費は18km/lほどでした。
同じくらいの大きさのデミオと比べると、乗り心地は勝っていますが燃費も悪いし100万近い価格差があります。
ドイツ車ならではのプレミアムで質実剛健さを求めるか、国産車のような収納スペースや安全装備充実の実用さを求めるかで見方が変わるかなと思います。
ただ新型A1がすでに発表されているのでそちらの方はどうなっているか期待ですね。
Pros  車体のサイズが小さくて取り回しがしやすい 排気量が1Lながら高速道路を走っている限りパワーは十分 車体剛性は十分 アクセル・ブレーキフィールはリニアで良い 足回りは固くもなく、柔らかくもなく 乗り心地は国産コンパクトカーよりは上かなという感じ テレスコピック機構がついていて、適切なドライビングポジションが取りやすい ペダル周りのスペースも十分  Cons  ハイオクのため給油代が高い 後部座席はそこそこ狭く、特に座面の傾斜がキツイ (背もたれと座面の角度が鋭角) (個体差かもしれないが)サイドミラー展開・格納時の音が大きい  </description>
    </item>
    
    <item>
      <title>自身のインスタンス名を取得するワンライナー</title>
      <link>/post/2018-06-27-%E8%87%AA%E8%BA%AB%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%82%BF%E3%83%B3%E3%82%B9%E5%90%8D%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B%E3%83%AF%E3%83%B3%E3%83%A9%E3%82%A4%E3%83%8A%E3%83%BC/</link>
      <pubDate>Wed, 27 Jun 2018 01:13:00 +0000</pubDate>
      
      <guid>/post/2018-06-27-%E8%87%AA%E8%BA%AB%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%82%BF%E3%83%B3%E3%82%B9%E5%90%8D%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B%E3%83%AF%E3%83%B3%E3%83%A9%E3%82%A4%E3%83%8A%E3%83%BC/</guid>
      <description>急にインスタンス名を取得したくなった時などにどうぞ。 ※EC2のDescribeInstances権限が必要です。
aws ec2 describe-instances \  --instance-ids `/usr/bin/curl -s http://169.254.169.254/latest/meta-data/instance-id` \  --query &amp;#39;Reservations[].Instances[].[Tags[?Key==`Name`].Value]&amp;#39; \  --output text 変数に入れる時はこんな感じで
INSTANCE_NAME=$(aws ec2 describe-instances \  --instance-ids `/usr/bin/curl -s http://169.254.169.254/latest/meta-data/instance-id` \  --query &amp;#39;Reservations[].Instances[].[Tags[?Key==`Name`].Value]&amp;#39; \  --output text) コピペ用
aws ec2 describe-instances --instance-ids `/usr/bin/curl -s http://169.254.169.254/latest/meta-data/instance-id` --query &amp;#39;Reservations[].Instances[].[Tags[?Key==`Name`].Value]&amp;#39; --output text </description>
    </item>
    
    <item>
      <title>自分用AWS クラウドサービス活用資料集メモ Auto Scaling編</title>
      <link>/post/2018-05-26-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-Auto-Scaling%E7%B7%A8/</link>
      <pubDate>Sat, 26 May 2018 11:34:00 +0000</pubDate>
      
      <guid>/post/2018-05-26-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-Auto-Scaling%E7%B7%A8/</guid>
      <description>Auto Scaling 情報元: AWS Black Belt Online Seminar 2017 Auto Scaling
 動的スケーリング3種  ChangeInCapacity  指定したインスタンス数だけ容量を増減 ex. アラームが起きたら2台増やす   ExactCapacity  指定したインスタンス数に容量を変更 アラームが起きたら2台にする   PercentChangeInCapacity  指定したインスタンス数に容量を変更 現在のサイズから20%増やす     負荷が予想できるなら: スケジュールベース 予定された負荷の対策: 手動スケーリング 予測できない緩やかな負荷: 動的スケーリング ヘルスチェック  EC2: ステータスがrunning以外の状態を以上と判断 ELB: ELBのヘルスチェックを利用   クールダウン: スケーリングアクション実行後、指定した時間ないは次のスケーリングアクションを実行しない仕組み  シンプルスケーリングポリシーのみ対応   ターミネーションポリシー: スケールイン時どのインスタンスから終了するか定義  OldestInstance / NewestInstance OldestLaunchConfiguration ClosestToNextInstanceHour (次の課金が始まるタイミングが最も近いインスタンス) Default (OldestLaunchConfigurationとClosestToNextInstanceHourを順に適用し、複数インスタンスが残ればランダム) インスタンス保護対象は除外   インスタンスのアタッチ・デタッチ  インスタンスのアタッチ: Auto Scaling Groupに追加できる。Desired Capacityが自動で追加される インスタンスのデタッチ: Auto Scaling Groupから取り除ける。Desired Capacityは変更されないため、新規インスタンスが追加される どちらもELBとは連動する。   スタンバイ: ELBからデタッチされ、トラフィックが流れないようになる  Desired Capasityも自動で変更される   ライフサイクルフック: Auto Scalingによるインスタンス起動・終了を待機させ、起動時または終了時にカスタムアクションを実行できる仕組み  インスタンス起動・終了処理を待機させ、メッセージを通知。SNS、SQS、CloudWatchイベントに送られる 待機時間にカスタムアクションを(初期化・終了処理）を実行 ライフサイクルの終了または待機時間延長コマンドを実行   突発的なスパイクには向いていない  CloudFrontにオフロード API Gatewayでスロットリング サイトを静的ページに切り替える   アーキテクチャとしてはSQSやECS、Blue Green(ASGをCloudFormationで自動作成)等が挙げられる。 Application Auto Scaling: Auto Scalingと似たUXでAWSリソースの自動スケールを実現  ECS Spot Fleet EMR    </description>
    </item>
    
    <item>
      <title>自分用AWS クラウドサービス活用資料集メモ Elastic Load Balancing編</title>
      <link>/post/2018-05-23-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-Elastic-Load-Balancing%E7%B7%A8/</link>
      <pubDate>Wed, 23 May 2018 21:48:00 +0000</pubDate>
      
      <guid>/post/2018-05-23-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-Elastic-Load-Balancing%E7%B7%A8/</guid>
      <description>AWS クラウドサービス活用資料集メモ サービス別資料 コンピューティング Elastic Load Balancing (ELB) 情報元: AWS Black Belt Online Seminar 2016 Elastic Load Balancing
 Application Load Balancer  L7のコンテントベースのロードバランサー ターゲットグループに対してルーティング コンテナベースのアプリケーションのサポート WebSocketとHTTP/2のサポート 複数のAZで耐障害性が高い 価格はALBの起動時間とLoad Balancer Capacity Units(LCU)の使用量で決まる   Elastic Load Balancing (ELB)  Application Load BalancerとClassic Load Balancerの二種類がある。  Application Load BalancerはL7のコンテントベースのロードバランサー Classic Load BalancerはL4および一部L7機能を提供するロードバランサー     ELBは複数AZに設定できる。DNSラウンドロビンで各AZのELBにアクセスが分散される。その後負荷が均等になるようバックエンドのEC2に振り分けられる クロスゾーン負荷分散を使うことで、AZ間のキャパシティ（インスタンス数、サイズ）が異なる場合やクライアントがDNSをキャッシュする環境でも負荷を均等にできる。 無通信状態が続くとそのコネクションを自動で切断する。デフォルトでは60秒、最低1秒最高3600秒 ELBは自動でスケールするが、瞬間的に急増すると503を返す。  Pre-Warming（暖機運転）の申請を行うあ負荷を段階的にかける ただしPre-WarmingはBusiness/Enterpriseサポートが必要   サブネットは最小/27、空きIPは8以上 ICMP Echo Request/Replyを許可すれば、ELBがpingにも応答する Perfect Forward Secrecyのサポート Server Order Preference対応 スティッキーセッション  同じユーザから来たリクエストをすべて同じEC2インスタンスに送信 ELBで生成するCookieかアプリケーションで生成するCookieか選べる   Connection Draining  ELBから登録解除したりヘルスチェックが失敗したときに、新規割り振りは中止して処理中のリクエストが終わるまで一定期間末   CLBはTCP/SSLによる負荷分散が可能 CLBはバックエンドインスタンスのサーバ証明書認証ができる CLBのコンテントベースルーティングはサブドメインかNGINXで行う。 Load Balancer Capacity Unitsは新規接続数、アクティブ接続数、帯域幅のうち、最も使用量が高いディメンションのみ請求  新規接続数: 1秒あたりの新規接続数 アクティブ接続数: 1分あたりのアクティブ接続数 トラフィック量（Mbps)   1 LCUには1秒あたり最大25の新規接続数 (4KB証明書の場合は最大5), 1分あたり最大3000個のアクティブ接続, 最大2.</description>
    </item>
    
    <item>
      <title>自分用AWS クラウドサービス活用資料集メモ Amazon EC2編</title>
      <link>/post/2018-05-23-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-Amazon-EC2%E7%B7%A8/</link>
      <pubDate>Wed, 23 May 2018 00:13:00 +0000</pubDate>
      
      <guid>/post/2018-05-23-%E8%87%AA%E5%88%86%E7%94%A8AWS-%E3%82%AF%E3%83%A9%E3%82%A6%E3%83%89%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E6%B4%BB%E7%94%A8%E8%B3%87%E6%96%99%E9%9B%86%E3%83%A1%E3%83%A2-Amazon-EC2%E7%B7%A8/</guid>
      <description>AWS クラウドサービス活用資料集メモ サービス別資料 コンピューティング Amazon EC2 情報元: 20180411 AWS Black Belt Online Seminar Amazon EC2 
 最新のC5, M5インスタンスはXenベースではなく、KVMベース 最小: 1vCPU, 0.5GBメモリ 最大: 128vCPU, 約4TBメモリ EC2インスタンスファミリー一覧  汎用、コンピューティング最適化、ストレージ最適化、メモリ最適化、GPU・FPGAアクセラレーテッド   T2インスタンスのCPUクレジット動作について  CPUクレジット1につきCPUコアの最大パフォーマンス（バースト性能）を1分間提供 T2 Unlimitedの場合24時間分のCPUクレジットを前借りして利用できる 前借りクレジットを使い切った状態においてはvCPU時間あたりLinuxでは$0.05/h, Windowsで$0.096/hが加算請求される 初期CPUクレジット、一時間あたりに受け取るCPUクレジット、ベースラインパフォーマンス(CPU使用率)、最大獲得CPUクレジットバランスはインスタンスタイプごとに異なる   Dedicated Hostsの場合、AWSまたはMarketplaceで提供されているRHEL, SUSE Linux, Windows　AMIは使えないので注意 Amazon EC2 Bare Metalについて  ハードウェアへのダイレクトアクセスを提供するインスタンス AWS各種サービスとの連携が可能 仮想化環境上からは利用できないエミュレータや、独自のハイパーバイザーを導入するときなどに利用   拡張ネットワーキングについて  Intel 82599VF (ixgbevf)  M4(m4.16xlarge以外), C3, C4, D2, I2, R3で使える   Elastic Network Adapter (ENA)  C5, F1, G3, H1, I3, M5, P2, P3, R4, X1, m4.</description>
    </item>
    
    <item>
      <title>mktmp, pushd, popdの使い方</title>
      <link>/post/2018-04-30-mktmp-popd-pushd%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9/</link>
      <pubDate>Mon, 30 Apr 2018 16:36:00 +0000</pubDate>
      
      <guid>/post/2018-04-30-mktmp-popd-pushd%E3%81%AE%E4%BD%BF%E3%81%84%E6%96%B9/</guid>
      <description>mktmp, pushd, popdはセットで使われることが多いと思います。 シェルスクリプト内で、一時ディレクトリを作成してそこにカレントディレクトリを変更し、また以前のカレントディレクトリに戻るといったときに使われます。
# (処理) # /tmp以下に一時ディレクトリを作成し、TMPDIR変数にパスを格納 TMPDIR=$(mktemp -d --tmpdir=/tmp) # 一時ディレクトリに移動 pushd $TMPDIR &amp;gt; /dev/null # (処理) # 元いたディレクトリに戻る popd &amp;gt; /dev/null # (処理) </description>
    </item>
    
    <item>
      <title>agettyがCPU100%に張り付いたときの対応</title>
      <link>/post/2018-04-30-agetty%E3%81%8CCPU100%E3%81%AB%E5%BC%B5%E3%82%8A%E4%BB%98%E3%81%84%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%BF%9C/</link>
      <pubDate>Mon, 30 Apr 2018 14:11:00 +0000</pubDate>
      
      <guid>/post/2018-04-30-agetty%E3%81%8CCPU100%E3%81%AB%E5%BC%B5%E3%82%8A%E4%BB%98%E3%81%84%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%BF%9C/</guid>
      <description>特に起動スクリプトがあるわけではないので、下記コマンドを使って再起動しました。
$ sudo initctl list rc stop/waiting tty (/dev/tty3) start/running, process 2914 tty (/dev/tty2) start/running, process 2911 tty (/dev/tty1) start/running, process 2907 tty (/dev/tty6) start/running, process 2921 tty (/dev/tty5) start/running, process 2918 tty (/dev/tty4) start/running, process 2916 update-motd stop/waiting plymouth-shutdown stop/waiting control-alt-delete stop/waiting rcS-emergency stop/waiting kexec-disable stop/waiting quit-plymouth stop/waiting rcS stop/waiting prefdm stop/waiting init-system-dbus stop/waiting print-image-id stop/waiting elastic-network-interfaces stop/waiting splash-manager stop/waiting start-ttys stop/waiting amazon-ssm-agent start/running, process 17313 rcS-sulogin stop/waiting serial (ttyS0) start/running, process 2906 $ sudo initctl status serial DEV=ttyS0 serial (ttyS0) start/running, process 2906 $ sudo initctl restart serial DEV=ttyS0 serial (ttyS0) start/running, process 5688 </description>
    </item>
    
    <item>
      <title>CodeBuildを使ってみたメモ</title>
      <link>/post/2018-03-21-CodeBuild%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E3%83%A1%E3%83%A2/</link>
      <pubDate>Wed, 21 Mar 2018 11:56:00 +0000</pubDate>
      
      <guid>/post/2018-03-21-CodeBuild%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%81%9F%E3%83%A1%E3%83%A2/</guid>
      <description>本当に今更だけどCodeBuildを使って、GitHubリポジトリのDockerfileをビルド&amp;amp;イメージプッシュ &amp;amp; Kubernetesにデプロイする設定を入れたので知見をメモする。
GitHubと連携できる てっきりリポジトリにコミットされたらCodeBuildを実行〜みたいな時、CodeCommitじゃないとできないのかなと思っていたのですが、GitHubでもできました。
CodeBuildでDockerイメージをビルド(dockerコマンドの実行)する際には、CodeBuildオリジナルのDockerイメージを使わなければならない &amp;ldquo;特権付与&amp;quot;にチェックを入れても、CodeBuild用のaws/codebuild/dockerイメージでなければdockerコマンドは使えません。
CodeBuildコンテナでのRubyインストール方法 前述の理由によりRubyを使いたい時、Rubyイメージが使えずコンテナにRubyをインストールするしかないのですが、普通にapt-get install rubyだと1.9が入ってしまいます。
2.4等新しいものをインストールする場合は次のようにします。
apt-get install -y software-properties-common apt-add-repository -y ppa:brightbox/ruby-ng apt-get update -y apt-get -y install ruby2.4 ruby2.4-dev イメージのタグなどに使う用のGitコミットID取得方法 下記変数が自動的にセットされているので、これが使えます。
※CodeBuild上のファイルは.gitがないようです。
CODEBUILD_RESOLVED_SOURCE_VERSION シークレットの取り扱い CodeBuildで環境変数を設定できるが、パスワード等のシークレットはAWS Systems Managerのパラメータストアを使います。
下記例は、パラメータストアにvalという名前で登録した値を、CodeBuild内でkeyという環境変数名前で使用できます。
env: parameter-store: key: &amp;#34;val&amp;#34; </description>
    </item>
    
    <item>
      <title>JAWS DAYS 2018 レポート</title>
      <link>/post/2018-03-21-JAWS-DAYS-2018-%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%88/</link>
      <pubDate>Wed, 21 Mar 2018 11:34:00 +0000</pubDate>
      
      <guid>/post/2018-03-21-JAWS-DAYS-2018-%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%88/</guid>
      <description>JAWS DAYS 2018 内容の正当性は保証できません。こういう雰囲気でした。
スライドとか公開されたら更新します。
概要 JAWS DAYS 2018レポート
日時: 2018年3月10日10時から
URL: https://jawsdays2018.jaws-ug.jp/
以下敬称略
コンテナでウェイウェイ (仮) by @keisuke69　西谷圭介
なぜコンテナなのか？  パッケージング 配布 イミュータブルインフラストラクチャー  ユースケース  マイクロサービスアーキテクチャ 非同期ジョブ実行（バッチコンピューティング）  柔軟にスケール   継続的インテグレーション、デプロイ  開発テスト本番まで一貫したイメージを利用    Amazon Container Service  レジストリ  Amazon ECR   コントロールプレーン  Amazon ECS  年間アクティブユーザ+450% 毎週数百万ものインスタンスで数億コンテナが起動 2015年のGA以来50以上の機能がリリース Task: コンテナ群の実行単位 Service: Taskの数を指定 IAM Role：　Taskごとに割当可能 TaskごとにENIを自動割当 Task内はlocalhostを共有   AWS Fargate  ECSと一緒に使う ECSのTaskでコンテナイメージを指定して実行 インスタンス管理不要 タスクに割り当てたリソース分の料金が掛かる CPUとメモリを秒単位で課金 Fargateで難しいもの  WindowsContainer GPU docker execのようなインタラクティブなデバッグ SpotやRIベースの価格モデルの適用 Taskレベルのメトリクス   Lambdaの方がいい場合  イベントドリブン ミリ秒単位のコンピュート ランタイムの管理をしたくない 分散バッチコンピューティング     EKS  Masterの管理運用をEKSでサポート (マネージド、Multi-AZ) EC2の管理は必要になるが、Fargateでのサポートも予定      Our ECS Journey by @calvinfo Calvin French-Owen</description>
    </item>
    
    <item>
      <title>Kubernetes Meetup Tokyo #10レポート</title>
      <link>/post/2018-03-10-Kubernetes-Meetup-Tokyo-#10%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%88/</link>
      <pubDate>Sat, 10 Mar 2018 13:09:00 +0000</pubDate>
      
      <guid>/post/2018-03-10-Kubernetes-Meetup-Tokyo-#10%E3%83%AC%E3%83%9D%E3%83%BC%E3%83%88/</guid>
      <description>内容の正当性は保証できません。こういう雰囲気でした。
スライドとか公開されたら更新します。
概要 Kubernetes Meetup Tokyo #10 日時: 2018年3月8日19時から URL: https://k8sjp.connpass.com/event/76816/
Open Service Broker APIとKubernetes Service Catalog by Toshiaki Maki (@making) (Pivotal)
データベースをどこにだれが作成していますか？
よくある例: 開発者がDBが必要な時にDBAに依頼 (DB作成、ユーザ作成)。
Service Brokerを使えば、DBの作成・構築・設定まで自動で行える。
Service Brokerを使うにはOpen Service Broker APIを使う。 これはもともとはCloud Foundryのサービスだった。
KubernetesではService Catalogを経由してService Brokerを使う。
Service Brokerによって作成される機密情報はSecretに入れてくれる・
helmでインストールできる。
ブローカーが構築済みであれば、開発者は下記手順を踏むことでリソース(DB等)を用意できる。
 ServiceInstance作成 -&amp;gt; リソース（DB等）が作成される ServiceBinding作成 -&amp;gt; パスワード等がシークレットにセットされる  Kubernetesセキュリティベストプラクティス by Ian Lewis (Google)
Guestbookアプリを例にベストプラクティスを紹介。
 フロントはHTML/CSS/JS メッセージが保存・閲覧できる NGワード検出機能がある よくあるマイクロサービス  Kubernetes API Serverについて シナリオ: フロントエンドPodからトークン取得、APIサーバを攻撃、シークレットを取得しさらに攻撃 Podにはトークンがマウントされているので、Podに侵入されるとトークンが抜かれるおそれがある。 トークンを使ってAPIサーバにアクセスすればシークレット（パスワード等)が抜かれる。
改善策1: RBACを使おう 例えばWebサーバはAPIサーバにアクセスする必要が無いので、アクセス出来ないようRBACを設定する。 GKEだとIAMと連携でき、管理が楽。</description>
    </item>
    
    <item>
      <title>GKEでなるべく安くKubernetesクラスタを作成してPrometheus &#43; Grafanaを使ってみる Part3 -SSL編-</title>
      <link>/post/2018-03-02-GKE%E3%81%A7%E3%81%AA%E3%82%8B%E3%81%B9%E3%81%8F%E5%AE%89%E3%81%8FKubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6Prometheus-&#43;-Grafana%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B-Part3-SSL%E7%B7%A8-/</link>
      <pubDate>Fri, 02 Mar 2018 22:26:00 +0000</pubDate>
      
      <guid>/post/2018-03-02-GKE%E3%81%A7%E3%81%AA%E3%82%8B%E3%81%B9%E3%81%8F%E5%AE%89%E3%81%8FKubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6Prometheus-&#43;-Grafana%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B-Part3-SSL%E7%B7%A8-/</guid>
      <description>タイトルの通りGKE (Google Kubernetes Engine)でKubernetesクラスタを作成して、その上でPrometheusとGrafanaを動かしてみます。
前回クラスタとそこにIngressを追加したので、今回はIngressでSSLを使えるようにします。
はじめに cert-managerを使ってLet&#39;s Encryptから証明書を取得・設定していきます。
cert-managerで証明書を取得するためにはDNS認証かHTTP認証のいずれかを行う必要があります。
DNS認証はRoute53ではうまく動かなかったので、HTTP認証で行います。
cert-managerのインストール helmを使ってインストールします。
下記コマンドを実行してください。
git clone https://github.com/jetstack/cert-manager cd cert-manager helm install \  --name cert-manager \  --namespace=kube-system \  contrib/charts/cert-manager \  --set ingressShim.extraArgs=&amp;#39;{--default-issuer-name=letsencrypt-prod,--default-issuer-kind=ClusterIssuer}&amp;#39; 設定 下記yamlをClusterIssuer.ymlとして保存してください。
※メールアドレスは自分のものを設定してください。
apiVersion: certmanager.k8s.io/v1alpha1 kind: ClusterIssuer metadata: name: letsencrypt-prod namespace: default spec: acme: # The ACME server URL server: https://acme-v01.api.letsencrypt.org/directory # Email address used for ACME registration email: (メールアドレス) # Name of a secret used to store the ACME account private key privateKeySecretRef: name: letsencrypt-prod # Enable the HTTP-01 challenge provider http01: {} 下記yamlをcertificate.</description>
    </item>
    
    <item>
      <title>GKEでなるべく安くKubernetesクラスタを作成してPrometheus &#43; Grafanaを使ってみる Part2 -Ingress編</title>
      <link>/post/2018-03-01-GKE%E3%81%A7%E3%81%AA%E3%82%8B%E3%81%B9%E3%81%8F%E5%AE%89%E3%81%8FKubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6Prometheus-&#43;-Grafana%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B-Part2-Ingress%E7%B7%A8-/</link>
      <pubDate>Thu, 01 Mar 2018 23:50:00 +0000</pubDate>
      
      <guid>/post/2018-03-01-GKE%E3%81%A7%E3%81%AA%E3%82%8B%E3%81%B9%E3%81%8F%E5%AE%89%E3%81%8FKubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6Prometheus-&#43;-Grafana%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B-Part2-Ingress%E7%B7%A8-/</guid>
      <description>タイトルの通りGKE (Google Kubernetes Engine)でKubernetesクラスタを作成して、その上でPrometheusとGrafanaを動かしてみます。
前回クラスタを作成したので今回はIngressを追加します。
Ingressを追加することで、クラスタ内のサービスにインターネットからアクセスできるようになります。
はじめに Ingressは普通にGKEで作成すると、Ingress ControllerがGCPのロードバランサーを作成します。
しかしこれが高い…。月額18ドルも掛かります。
そこでGCPのロードバランサーの代わりにnginx-ingressというNGINXを使います。
こちらを一番小さいf1-microのノードで動かせば4.28ドルで済みます。
しかもf1-microはAlways Freeの条件であるus-east1, us-west1, us-central1のいずれかで動かせばタダで動かせます。
なので今回はロードバランサーを使わず、nginx-ingressを使うことにします。
前提作業 前回の記事のGKEでなるべく安くKubernetesクラスタを作成してPrometheus + Grafanaを使ってみる Part1 -クラスタ作成編-の手順でクラスタを作成してあることを前提とします。
また疎通確認にドメインを使用しますので、用意してください。
ドメインを持っていない方はnip.ioとか使うといいと思います。知らんけど。
Ingress Controller用ノードを作成 前回作成したクラスタのノードはプリエンプティブノードのため一定時間で削除されます。
nginx-ingressでは静的グローバルIPをノードに割り当てる必要があるため、削除されないノードを別途作成します。
具体的にはIngress Controllerを動かすためのノードプールを作成します。
 クラスタ編集画面を開く &amp;ldquo;ノードプールを追加&amp;quot;ボタンを選択 名前にload-balancerと入力 マシンタイプにmicro (f1-micro)を選択 ノードあたりのブートディスク サイズに10GBと入力  Ingress Controller用ノードの設定 下記コマンドを実行します。
export CLUSTER_NAME=クラスタ名 export ZONE=us-west1-b export REGION=us-west1 # kubectlを使えるようにする gcloud container clusters get-credentials $CLUSTER_NAME --zone $ZONE # 静的グローバルIPアドレスを確保 gcloud compute addresses create $CLUSTER_NAME-ip --region $REGION # 静的グローバルIPアドレスを取得 export LB_ADDRESS_IP=$(gcloud compute addresses list | grep $CLUSTER_NAME-ip | awk &amp;#39;{print $3}&amp;#39;) # nginx-ingressで使うノード名を取得 export LB_INSTANCE_NAME=$(kubectl describe nodes | grep Name: | tail -n1 | awk &amp;#39;{print $2}&amp;#39;) # nginx-ingressしか動かないようにする (リソースの確保のため) kubectl taint nodes $LB_INSTANCE_NAME role=nginx-ingress-controller:NoSchedule # 静的グローバルIPアドレスをノードに紐付ける export LB_INSTANCE_NAT=external-nat gcloud compute instances delete-access-config $LB_INSTANCE_NAME --access-config-name &amp;#34;$LB_INSTANCE_NAT&amp;#34; --zone $ZONE gcloud compute instances add-access-config $LB_INSTANCE_NAME --access-config-name &amp;#34;$LB_INSTANCE_NAT&amp;#34; --address $LB_ADDRESS_IP --zone $ZONE # ラベルの設定 kubectl label nodes $LB_INSTANCE_NAME role=load-balancer # タグの設定 (これで80と443に外部からアクセスできるようになる) gcloud compute instances add-tags $LB_INSTANCE_NAME --tags http-server,https-server --zone $ZONE helmの導入 helmとはKubernetesのパッケージマネージャーです。</description>
    </item>
    
    <item>
      <title>GKEでなるべく安くKubernetesクラスタを作成してPrometheus &#43; Grafanaを使ってみる Part1 -クラスタ作成編-</title>
      <link>/post/2018-02-11-GKE%E3%81%A7Kubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6Prometheus-&#43;-Grafana%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B-Part1/</link>
      <pubDate>Sun, 11 Feb 2018 11:38:00 +0000</pubDate>
      
      <guid>/post/2018-02-11-GKE%E3%81%A7Kubernetes%E3%82%AF%E3%83%A9%E3%82%B9%E3%82%BF%E3%82%92%E4%BD%9C%E6%88%90%E3%81%97%E3%81%A6Prometheus-&#43;-Grafana%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B-Part1/</guid>
      <description>タイトルの通りGKE (Google Kubernetes Engine)でKubernetesクラスタを作成して、その上でPrometheusとGrafanaを動かしてみます。
まずはGKEでKubernetesクラスタを作成してみます。
はじめに GCP(Google Cloud Platform)アカウントの登録とプロジェクトの作成が終わってる前提でお話します。
適当に作っておいてください。
クラスタの作成 左上のハンバーガーメニューからKubernetes Engineを選択
※初回アクセス時には準備に数分かかります。
クラスタの作成ボタンを押下します。
設定 今回のように可用性 (ダウンタイム)に目をつぶるならノードにプリエンプティブを使うことで、インスタンスの費用を7割程度抑えることが出来ます (オレゴン、g1-smallの場合)。
※プリエンプティブにした場合、２４時間以内に勝手に落とされてしまうので気をつけてください。
ノードは価格の安い海外のリージョンを使い、マシンタイプはsmallを使います。
またデフォルトでは、ノードのディスクサイズが100GBという罠があるので、忘れずに減らしておきましょう。
 ゾーン: us-west1-b マシンタイプ: small（g1-small) 自動スケーリング: オン 最大サイズ: 6 プリエンプティブ ノード: 有効 ノードあたりのブートディスク サイズ: 10GB HTTP 負荷分散: 無効  接続 クラスタの作成が終わったらkubectlコマンドでクラスタに接続してみます。
接続ボタンを押下し、&amp;ldquo;Cloud Shellで実行&amp;quot;を押下します。
ウインドウ下部に、コマンドが入力済みの状態でコンソールが表示されます。 Enterキーを押してコマンドを実行します。
これでkubectlでアクセスできるようになりました。
kubectl get nodesを実行して作成したノードが表示されるかどうか確認します。
以上</description>
    </item>
    
    <item>
      <title>Mailuで簡単にWebUI付きのメールサーバを立てる</title>
      <link>/post/2018-02-06-Mailu%E3%81%A7%E7%B0%A1%E5%8D%98%E3%81%ABWebUI%E4%BB%98%E3%81%8D%E3%81%AE%E3%83%A1%E3%83%BC%E3%83%AB%E3%82%B5%E3%83%BC%E3%83%90%E3%82%92%E7%AB%8B%E3%81%A6%E3%82%8B/</link>
      <pubDate>Tue, 06 Feb 2018 13:15:00 +0000</pubDate>
      
      <guid>/post/2018-02-06-Mailu%E3%81%A7%E7%B0%A1%E5%8D%98%E3%81%ABWebUI%E4%BB%98%E3%81%8D%E3%81%AE%E3%83%A1%E3%83%BC%E3%83%AB%E3%82%B5%E3%83%BC%E3%83%90%E3%82%92%E7%AB%8B%E3%81%A6%E3%82%8B/</guid>
      <description>はじめに 自分用のメールサーバを建てようと思った時、セキュリティを気にしながら設定を調べて…となかなか大変ですよね。
でもMailuを使うと簡単にWebUI付きのメールサーバが構築できます！
この画像のようにWebUIからもメールの送受信ができるので便利です。
デモサイトがあるので興味のある方は覗いてみてください。
Mailuが備えている機能は次の通りです。
 IMAP, IMAP+, SMTPのメールサーバ WebUIと管理画面 自動返信、自動転送 クォーターなどの管理機能 TLS (Let&#39;s Encrypt対応！), DKIM, アンチウイルスなどのセキュリティ  詳細はプロジェクトのページを見ていただくとして、早速構築してみます。
構築 構築はDigitalOceanという海外のVPS上のdocker-composeでやってみます。
ちなみに下記のリンクから登録すると10ドルのクーポンが貰えます。
一番安いインスタンスであれば2ヶ月間無料で動かせます。是非。
https://m.do.co/c/dc73cf13e37a
構築手順 今回は公式推奨のDebian Stretch(9.3)を使います。
インスタンスが立ち上がったらおもむろに下記コマンドを実行してください。
準備 apt update # すべてYESと答える apt install -y iptables-persistent apt-get autoremove --purge exim4 exim4-base Dockerのインストール # E: Unable to locate package docker-engineと言われても大丈夫 apt-get remove docker docker-engine docker.io apt-get install -y apt-transport-https ca-certificates curl gnupg2 software-properties-common curl -fsSL https://download.docker.com/linux/$(. /etc/os-release; echo &amp;#34;$ID&amp;#34;)/gpg | sudo apt-key add - apt-key fingerprint 0EBFCD88 add-apt-repository &amp;#34;deb [arch=amd64] https://download.</description>
    </item>
    
    <item>
      <title>AWS VPCでRoute53のプライベートホストゾーンを使う</title>
      <link>/post/2018-01-25-AWS-VPC%E3%81%A7Route53%E3%81%AE%E3%83%97%E3%83%A9%E3%82%A4%E3%83%99%E3%83%BC%E3%83%88%E3%83%9B%E3%82%B9%E3%83%88%E3%82%BE%E3%83%BC%E3%83%B3%E3%82%92%E4%BD%BF%E3%81%86/</link>
      <pubDate>Thu, 25 Jan 2018 11:50:00 +0000</pubDate>
      
      <guid>/post/2018-01-25-AWS-VPC%E3%81%A7Route53%E3%81%AE%E3%83%97%E3%83%A9%E3%82%A4%E3%83%99%E3%83%BC%E3%83%88%E3%83%9B%E3%82%B9%E3%83%88%E3%82%BE%E3%83%BC%E3%83%B3%E3%82%92%E4%BD%BF%E3%81%86/</guid>
      <description>はじめに VPCでのプライベートホストゾーンについて説明します。
これはroute53.testのような実在しないドメインをRoute53に登録&amp;amp;設定すれば、設定したVPC限定でそのドメインが使えるというものです。
これを使って例えば次のようなことができます。
インスタンスAにweb.route53.testというレコードセットをRoute53に登録
↓
設定したVPCのインスタンスからはwebという名前でインスタンスAにアクセスできる（どちらかと言うとリゾルバの機能ですが）
踏み台からのSSHやリレー、プロキシ先の指定などに便利ですよね。
料金について こちらをご覧ください。月0.5ドルかかります。日割り計算はありません。
ただし作成から12時間は料金は発生しないようなので、テスト目的ならば12時間以内に削除しましょう。
設定 ドキュメントにいろいろ書かれていますが、大抵の場合次の手順でいけるはずです。
 Route53でプライベートホストゾーンを登録 VPCのDNS, DHCP設定を変更  VPCのDHCPの設定を変更すれば/etc/resolv.confの設定は自動で行われます。便利ですね。
1. Route53でプライベートホストゾーンを登録 Route53のページに行ってホストゾーンを作成します。
特に迷うことはないと思いますがこんな感じで
次にレコードを登録しましょう。
登録するIPはもちろんプライベートIPアドレスで。
Route53での作業は以上です。
2. VPCのDHCP設定を変更 VPC一覧のページに移動し、DNSホスト名をはいに設定します。
次にVPCのDHCP オプションセットというページに移動します。
ここで予めオプションの値をメモしておいてください。
※多分こんな感じで設定がされていると思います。
domain-name = ap-northeast-1.compute.internal;domain-name-servers = AmazonProvidedDNS;
ドメイン名にメモしたdomain-nameで指定されている値とスペースを開けて今回設定するプライベートホストゾーンの値を入力します。
ドメインネームサーバーにはAmazonProvidedDNSと入力してください。
最後にVCPの一覧画面に移動し、DHCPオプションセットの編集から、先ほど作成したオプションセットを指定します。
5分程度待つと、設定したVPC内のインスタンスの/etc/resolv.confが自動で変更され、instance01とinstance02でIPが引けるようになります。
※テストで作った場合は忘れずにホストゾーンを削除しましょう！
注意点 自分は試していないのですが、ドキュメントに記載がある通り、名前空間が重複するパブリックゾーンとプライベートホストゾーンだと注意が必要です。
たとえばdevドメインのような実在するパブリックなドメインをプライベートホストゾーンに登録してしまうと、パブリックな方のDNSサーバには問い合わせてくれないということです。 気をつけましょう。</description>
    </item>
    
    <item>
      <title>Kubernetes Meetup Tokyo #9 レポート</title>
      <link>/post/2018-01-13-KubernetesMeetupTokyo9/</link>
      <pubDate>Sat, 13 Jan 2018 13:56:00 +0000</pubDate>
      
      <guid>/post/2018-01-13-KubernetesMeetupTokyo9/</guid>
      <description>内容の正当性は保証できません。こういう雰囲気でした。
概要 Kubernetes Meetup Tokyo #9
日時: 2018年1月12日19時から
URL: https://k8sjp.connpass.com/event/75328
タイムテーブル 19:00-19:05 - Organizer &amp;amp; CyberAgent, Opening (5min)
19:05-19:20 - ianlewis, KubeCon Overview(15min)
19:25-19:40 - riywo, Review Adrian Cockroft’s keynote (15min)
19:45-20:00 - jyoshise, GPU, Deep Learning or Service mesh (15min)
20:05-20:20 - tnir, Kubernetes at GitHub (15min)
20:25-20:45 - CyberAgent Sponsor Session (20min)
Review Adrian Cockroft’s keynote @riywo
 AWSはCNCFに対してクレジットを補助したり、自社のサービスに取り入れたりと積極的にコントリビュートしている KubernetesのCNIのプラグインも作った ECSは繁盛している AWS Fargateをリリースした  LambdaのECS版的な   Kuberentesをデプロイしているユーザーの68%はAWSにもデプロイしている HeptioとかがKubernetesをAWSで動かすためのインテグレーションを開発している  IAM連携とか   AWS Fargate + Amazon EKSは2018年  フィードバックもよろしくね    GPU, Deep Learning or Service mesh @jyoshise</description>
    </item>
    
    <item>
      <title>EC2 IAMロールの作成と適用をCLIから行う</title>
      <link>/post/2018-01-10-EC2IAM%E3%83%AD%E3%83%BC%E3%83%AB%E3%81%AE%E4%BD%9C%E6%88%90%E3%81%A8%E9%81%A9%E7%94%A8%E3%82%92CLI%E3%81%8B%E3%82%89%E8%A1%8C%E3%81%86/</link>
      <pubDate>Wed, 10 Jan 2018 18:22:00 +0000</pubDate>
      
      <guid>/post/2018-01-10-EC2IAM%E3%83%AD%E3%83%BC%E3%83%AB%E3%81%AE%E4%BD%9C%E6%88%90%E3%81%A8%E9%81%A9%E7%94%A8%E3%82%92CLI%E3%81%8B%E3%82%89%E8%A1%8C%E3%81%86/</guid>
      <description>EC2 IAMロールの作成と適用をCLIから行う
AWSコンソールからであれば簡単なんですが、CLIからだとインスタンスプロファイル（EC2 IAMロール)を作るのにロールの作成から必要なので若干面倒です。
ここでは前提として、複数のインスタンスに対してそれぞれ違うロール(ポリシーは同一)を適用します。
表にすると次のような感じです。
| インスタンスID | ロール名 / インスタンスプロファイル名 | ポリシーARN | | instanceid1 | rolename1 | arn:aws:iam::aws:policy/service-role/servicerole | | instanceid2 | rolename2 | arn:aws:iam::aws:policy/service-role/servicerole |
手順 Assume-roleを準備 cat &amp;lt;&amp;lt; _EOF &amp;gt; Trust-Policy.json { &amp;#34;Version&amp;#34;: &amp;#34;2012-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: { &amp;#34;Service&amp;#34;: &amp;#34;ec2.amazonaws.com&amp;#34; }, &amp;#34;Action&amp;#34;: &amp;#34;sts:AssumeRole&amp;#34; } ] } _EOF インスタンスロール作成とロールのアタッチ INSTANCE_ROLE_NAMES=( rolename1 rolename2 ) for INSTANCE_ROLE_NAME in ${INSTANCE_ROLE_NAMES[@]}; do # ロール作成 aws iam create-role --role-name $INSTANCE_ROLE_NAME --assume-role-policy-document file://Trust-Policy.</description>
    </item>
    
    <item>
      <title>SREサイトリライアビリティエンジニアリングを読んだ (随時更新)</title>
      <link>/post/2018-01-05-SRE%E3%82%B5%E3%82%A4%E3%83%88%E3%83%AA%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%93%E3%83%AA%E3%83%86%E3%82%A3%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Fri, 05 Jan 2018 11:59:00 +0000</pubDate>
      
      <guid>/post/2018-01-05-SRE%E3%82%B5%E3%82%A4%E3%83%88%E3%83%AA%E3%83%A9%E3%82%A4%E3%82%A2%E3%83%93%E3%83%AA%E3%83%86%E3%82%A3%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>SREサイトリライアビリティエンジニアリングを読んだので、要点をメモ。
現行のシステム管理の問題点  サービスが成長すると運用コストも増加する 開発チームと運用チームでの対立が発生する  Googleのシステム管理について  SRE (サイトリライアビリティエンジニアリング) というアプローチを取る SREとは(Google的には)ソフトウェアエンジニアに運用チームの設計を依頼したときにできるもの UNIXシステム内部とネットワーキングに関する専門知識と、複雑な問題を解決するソフトウェアシステムの開発に対する信念と適正が必要 運用チームで行ってきたことをソフトウェアで自動化する  こうしたことをしない場合、サービス成長とともに運用負荷が増大し続け、多くの人員が必要となる   Googleの場合、運用の業務は全体の50%の時間以内に収めるようにしている  残りの時間はサービスを安定して運用できるようにするための開発作業に当てる    エラーバジェットについて  開発チームとSREチームの対立を解決するための仕組み 100%を信頼性の目標とすることは、基本的にいかなる場合にも間違っているとする  99.999%と100%の可用性は、他の要素（PC/SP, Wi-Fi, ISP, 電力網等)のノイズに紛れてしまう上に、0.001%を埋める労力はユーザーにメリットがない (リリースも遅く、少なくなってしまう）   次の3点を考慮に入れた上で可用性のターゲットを決める。1からそれを引いたものがエラーバジェットとなる (可用性が99.9%の場合は0.1%がエラーバジェット)  ユーザーが満足する可用性のレベル 満足できなかったユーザーにとっての大対策はどのようなものがあるか 可用性のレベルを変更したとしてユーザーのプロダクトの利用の仕方にに何が起こるか   エラーバジェットは超過しない限り自由に使うことができる  機能のローンチに関わるリスク (段階的ロールアウトや1% experiment)のために使うことができる SREの目的をサービス障害をゼロにすることではなく機能のリリース速度を最大化するためにエラーバジェットを使うことになる サービス障害を予測済みのものにすることができ、これが悪いことではなくなる。コントロールすることができるようになる。 必要以上に信頼性をあげない SREと開発者との間でリリース速度と可用性の利害を一致させることができ、リスクについて揉めることなく共通の結論にすることができる    モニタリングについて  人間がメールを読み、何らかの対応アクションの必要性を判断しなければならないシステムは根本的に問題がある  アラートはソフトウェアが解釈を行い、人間はアクションを行わなければならないときのみ通知を受けるようになっているべき   MTTF (平均故障時間)とMTTR (平均修復時間)を考える たとえ障害が多くとも、手作業での介入を必要としないシステムは、介入を必要とする障害が少ないシステムより高い可用性を持つ 人間の作業は手順書に記録していくことで、MTTRに3倍の改善が見られた (Google談) およそ70%のサービス障害は動作中のシステム変更によって生じるもの (Googleの場合) ベストプラクティスは自動化によって下記3点を実現すること。  漸進的なロールアウトの実装 高速かつ正確な問題の検出 安全なロールバック   需要予測とキャパシティプランニングは次の2点を考慮に入れる必要がある。  自然な成長 (プロダクトの利用が進むなど) 突発的な成長 (機能のリリースやマーケティングキャンペーン等)    リスクについて  信頼性と機能追加等のリリースはトレードオフの関係にある  そのため必要以上に信頼性をあげない   可用性はリクエスト数を集計(成功したリクエスト数/総リクエスト数)すると、バッチやストレージ等にも当てはめることができる 可用性のターゲットレベルは下記のことを考慮するべき  期待されているサービスのレベル サービスが直接的に収入(顧客と自身の)につながっているか サービスの有償・無償 競合サービスのレベル コンシューマー向け・企業向け   可用性のレベルを変更してどれだけのコストに影響があるかも考える必要がある  サービスの収益がXXX円だから、可用性0.</description>
    </item>
    
    <item>
      <title>1月1日のハイライト</title>
      <link>/post/2018-01-01-1%E6%9C%881%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</link>
      <pubDate>Mon, 01 Jan 2018 19:01:00 +0000</pubDate>
      
      <guid>/post/2018-01-01-1%E6%9C%881%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</guid>
      <description>酒飲んで年越しそば食べて、日付が変わったあとに特別ダイヤの小田急に乗って明治神宮に初詣に行った。
明治神宮は入場規制をしていたけどそこまで時間はかからなかった。
それから念願の終夜運行の年末年始特別ダイヤの列車に乗れてよかった。
朝は餅を焼いてお汁粉にして食べた。
順序が前後したけど、夜には世田谷八幡にも行った (明治神宮と同じくらい時間がかかった)。</description>
    </item>
    
    <item>
      <title>T2 Unlimitedを有効にしてみた</title>
      <link>/post/2017-12-30-t2-unlimited%E3%82%92%E6%9C%89%E5%8A%B9%E3%81%AB%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F/</link>
      <pubDate>Sat, 30 Dec 2017 01:16:00 +0000</pubDate>
      
      <guid>/post/2017-12-30-t2-unlimited%E3%82%92%E6%9C%89%E5%8A%B9%E3%81%AB%E3%81%97%E3%81%A6%E3%81%BF%E3%81%9F/</guid>
      <description>T2インスタンスに対してT2 Unlimited機能を有効にしてみた。
T2 Unlimited機能について T2インスタンスはCPUクレジットを消費してCPU能力を上げるバーストという機能が使用できる。
このバーストはCPUクレジットを消費し尽くした場合は使えなくなってしまうが、消費し尽くした場合でもバーストし続けることができる機能をT2 Unlimitedと呼ぶ。
CPUクレジットの消費量は1vCPU毎1分間に1クレジットで、CPUクレジットの回復量と回復上限はインスタンスタイプごとに違う。具体的には下記ページの表にまとまっている。http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/t2-instances.html
バースト / T2 Unlimited詳細 CPUクレジットを消費し尽くした後T2 Unlimitedによりバーストが発生してもすぐには課金されない。
この場合CPUクレジットの回復上限の値までCPUクレジットを使って、初めて課金 (vCPU時間あたり0.05ドル)が発生する。
これらはそれぞれCPUSurplusCreditBalanceとCPUSurplusCreditsChargedというメトリクスで追跡できる。
つまり、バースト発生 → クレジットを使い切る → CPUSurplusCreditBalanceも上限 (CPUクレジットの回復上限の値) まで使い切る → 課金が発生という流れになる。
なおCPUSurplusCreditBalanceを使った場合では、CPUクレジットの回復にはまずCPUSurplusCreditBalanceの返済が必要で、返済が終わった段階からCPUクレジットの回復が始まる。
監視 (アラート) 何らかの問題によりバーストが発生し続けて、T2 Unlimitedの課金が気が付かれずに発生し続けることを避けるため、監視とアラートを設定する。
CloudWatchで設定を行い、アラートは課金が始まった時、つまりCPUSurplusCreditsChargedが0より大きくなった場合にアラートを送信するよう設定する。
設定 下記設定でT2 Unlimitedの設定と監視（アラート）の設定を行った。
アラート条件: CPUSurplusCreditsChargedが0より大きくなった時 (5分間隔1回連続)
アラート送信先: (既存SNSトピックを使用)
#!/bin/bash set -euo pipefail RET=$(aws ec2 describe-instances --query \  &amp;#39;Reservations[].Instances[].{HostName:Tags[?Key==`Name`].Value|[0],InstanceId:InstanceId}&amp;#39; \  --filters &amp;#34;Name=instance-type,Values=t2.*&amp;#34; --output text | awk &amp;#39;{ print $1&amp;#34;,&amp;#34;$2}&amp;#39; | sort | grep -v stg ) for LINES in $RET; do INSTANCE_NAME=$(echo $LINES | awk -F, &amp;#39;{ print $1 }&amp;#39;) INSTANCE_ID=$(echo $LINES | awk -F, &amp;#39;{ print $2 }&amp;#39;) echo $INSTANCE_NAME aws ec2 modify-instance-credit-specification \  --instance-credit-specification &amp;#34;[{\&amp;#34;InstanceId\&amp;#34;: \&amp;#34;${INSTANCE_ID}\&amp;#34;,\&amp;#34;CpuCredits\&amp;#34;: \&amp;#34;unlimited\&amp;#34;}]&amp;#34; aws cloudwatch put-metric-alarm \  --alarm-name &amp;#34;$INSTANCE_NAMEでのT2 Unlimited課金発生&amp;#34; \  --namespace AWS/EC2 \  --metric-name CPUSurplusCreditsCharged \  --dimensions &amp;#34;Name=InstanceId,Value=$INSTANCE_ID&amp;#34; \  --period 300 \  --statistic Average \  --threshold 0 \  --comparison-operator GreaterThanThreshold \  --evaluation-periods 1 \  --alarm-actions (既存SNSトピックを使用) \  --ok-actions (既存SNSトピックを使用) echo &amp;#34;-----------&amp;#34; done 参考 https://aws.</description>
    </item>
    
    <item>
      <title>Macから別のMacへのThunderbirdの移行をしたら簡単だった</title>
      <link>/post/2017-12-27-Mac%E3%81%8B%E3%82%89Mac%E3%81%B8%E3%81%AEThunderbird%E3%81%AE%E7%A7%BB%E8%A1%8C%E3%82%92%E3%81%97%E3%81%9F%E3%82%89%E7%B0%A1%E5%8D%98%E3%81%A0%E3%81%A3%E3%81%9F/</link>
      <pubDate>Wed, 27 Dec 2017 01:01:00 +0000</pubDate>
      
      <guid>/post/2017-12-27-Mac%E3%81%8B%E3%82%89Mac%E3%81%B8%E3%81%AEThunderbird%E3%81%AE%E7%A7%BB%E8%A1%8C%E3%82%92%E3%81%97%E3%81%9F%E3%82%89%E7%B0%A1%E5%8D%98%E3%81%A0%E3%81%A3%E3%81%9F/</guid>
      <description>職場で使っているMacを別のMacに移行をする必要があり、使っていたThunderbirdをどうやって移行するか調べた。
自分で試した限り、~/Library/Thunderbird/以下のディレクトリをそのまま古いMacから新しいMacにコピーすれば大丈夫だった。
Thunderbirdの設定やメールも保持された。
なお新旧Mac間のファイルコピーはAirDropを使うのがおすすめ。</description>
    </item>
    
    <item>
      <title>12月25日のハイライト</title>
      <link>/post/2017-12-25-12%E6%9C%8825%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</link>
      <pubDate>Mon, 25 Dec 2017 01:01:00 +0000</pubDate>
      
      <guid>/post/2017-12-25-12%E6%9C%8825%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</guid>
      <description>横須賀の牧場と城ヶ島に行ってマグロを食べて海岸を散歩して温泉入ってきて帰ってきた。
帰りは遅くなってしまったので高速道路で。PAに食堂があったので食べて帰ってくるなど。
ニッポンレンタカーで借りたらノートだったんだけど、ノートはカーシェアリングで散々乗ってるのでもういいなという気持ち。
![] ( /assets/img/20171225/IMG_1810.jpg )
![] ( /assets/img/20171225/IMG_1813.jpg )
![] ( /assets/img/20171225/IMG_1819.jpg )
![] ( /assets/img/20171225/IMG_1822.jpg )
![] ( /assets/img/20171225/IMG_1823.jpg )
![] ( /assets/img/20171225/IMG_1831.jpg )
![] ( /assets/img/20171225/IMG_1833.jpg )
![] ( /assets/img/20171225/IMG_1868.jpg )
![] ( /assets/img/20171225/IMG_1890.jpg )
![] ( /assets/img/20171225/IMG_1898.jpg )
![] ( /assets/img/20171225/IMG_1904.jpg )</description>
    </item>
    
    <item>
      <title>12月22日のハイライト</title>
      <link>/post/2017-12-22-12%E6%9C%8822%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</link>
      <pubDate>Fri, 22 Dec 2017 01:01:00 +0000</pubDate>
      
      <guid>/post/2017-12-22-12%E6%9C%8822%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</guid>
      <description>鍋と日本酒を家で頂いた。
やはり寒い日は温かい鍋に限る。作るのも片付けるのも楽だし。</description>
    </item>
    
    <item>
      <title>12月20日のハイライト</title>
      <link>/post/2017-12-21-12%E6%9C%8820%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</link>
      <pubDate>Thu, 21 Dec 2017 01:01:00 +0000</pubDate>
      
      <guid>/post/2017-12-21-12%E6%9C%8820%E6%97%A5%E3%81%AE%E3%83%8F%E3%82%A4%E3%83%A9%E3%82%A4%E3%83%88/</guid>
      <description>六本木方面にイルミネーションを見に行って、お茶漬け食べて帰ってきた。</description>
    </item>
    
    <item>
      <title>改行コードの変更</title>
      <link>/post/2017-12-11-%E6%94%B9%E8%A1%8C%E3%82%B3%E3%83%BC%E3%83%89%E3%81%AE%E5%A4%89%E6%9B%B4/</link>
      <pubDate>Mon, 11 Dec 2017 17:49:00 +0000</pubDate>
      
      <guid>/post/2017-12-11-%E6%94%B9%E8%A1%8C%E3%82%B3%E3%83%BC%E3%83%89%E3%81%AE%E5%A4%89%E6%9B%B4/</guid>
      <description>改行コードはtrコマンドで変更できる。 標準入力で入力を与えると、標準出力で出力が返ってくる。
tr (置き換え前の改行コード) (置き換え後の改行コード) 例えば、CRをLFに変更したい場合は次の通り。
tr \\r \\n &amp;lt; cr.txt &amp;gt; lf.txt </description>
    </item>
    
    <item>
      <title>JenkinsでGitHubのWebHookを受ける</title>
      <link>/post/2017-12-10-jenkins%E3%81%A7GitHub%E3%81%AEWebHook%E3%82%92%E5%8F%97%E3%81%91%E3%82%8B/</link>
      <pubDate>Sun, 10 Dec 2017 19:55:47 +0000</pubDate>
      
      <guid>/post/2017-12-10-jenkins%E3%81%A7GitHub%E3%81%AEWebHook%E3%82%92%E5%8F%97%E3%81%91%E3%82%8B/</guid>
      <description>JenkinsでGitHubのWebhookを受けるのに手こずったので、手順を軽くメモ。
要点だけ軽くまとめます。
ポイントは認証トークンとAPIトークンをそれぞれ必要だということでした。
  GitHub側の設定
WebHookURLとして下記URLを指定する。
https://ユーザ名:APIトークン（認証トークンではない)@JenkinsのURL/job/Job名/build?token=(認証トークン)   Jenkins側の設定
認証トークンとAPIトークンを払い出す。
認証トークンはプロジェクトの設定ページの&amp;quot;ビルド・トリガ&amp;quot;から任意の値を設定。
APIトークンはユーザ情報の設定ページ(https://JenkinsのURL/user/(ユーザ名)/configure)から払い出す。
  </description>
    </item>
    
    <item>
      <title>AnsibleでLetsencryptによる証明書を自動作成する</title>
      <link>/post/2017-12-08-Ansible%E3%81%A7Letsencrypt%E3%81%AB%E3%82%88%E3%82%8B%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%82%92%E8%87%AA%E5%8B%95%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B/</link>
      <pubDate>Fri, 08 Dec 2017 16:29:47 +0000</pubDate>
      
      <guid>/post/2017-12-08-Ansible%E3%81%A7Letsencrypt%E3%81%AB%E3%82%88%E3%82%8B%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%82%92%E8%87%AA%E5%8B%95%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B/</guid>
      <description>証明書を作成するためにはドメインを登録しないといけませんが、下記Taskで自動作成できます。
登録するIPアドレスはipify.orgで取得しています。
注意点としてはfullchain-pathで指定したディレクトリ配下にdomain1の名前でディレクトリが作成され、そのディレクトリ内に証明書と秘密鍵が生成されることです。
- name: &amp;#34;外部アドレスを取得&amp;#34; uri: url: https://api.ipify.org/ return_content: yes register: external_address - name: &amp;#34;レコード登録 (反映を待つので少し時間がかかります)&amp;#34; route53: aws_access_key: (アクセスキー) aws_secret_key: (シークレットアクセスキー) command: create zone: (Route53ゾーン名) record: &amp;#34;{{ item }}&amp;#34; type: A ttl: 300 value: &amp;#34;{{ external_address.content }}&amp;#34; wait: yes with_items: - (ドメイン1) - (ドメイン2) - name: &amp;#34;certbot インストールディレクトリの作成&amp;#34; file: path=/opt/certbot state=directory owner=root group=root mode=0755 - name: &amp;#34;certbot のダウンロード&amp;#34; get_url: url: https://dl.eff.org/certbot-auto dest: /opt/certbot/certbot-auto mode: 755 - name: &amp;#34;certbot を実行してSSL証明書を取得&amp;#34; shell: | /opt/certbot/certbot-auto certonly \ --debug \ --text \ --non-interactive \ --agree-tos \ --standalone \ --fullchain-path=(設置場所) \ --email (メールアドレス) \ -d (ドメイン1) \ -d (ドメイン2) </description>
    </item>
    
    <item>
      <title>Ansibleで配列を定義する</title>
      <link>/post/2017-12-08-ansible%E3%81%A7%E9%85%8D%E5%88%97%E3%82%92%E5%AE%9A%E7%BE%A9%E3%81%99%E3%82%8B/</link>
      <pubDate>Fri, 08 Dec 2017 13:15:47 +0000</pubDate>
      
      <guid>/post/2017-12-08-ansible%E3%81%A7%E9%85%8D%E5%88%97%E3%82%92%E5%AE%9A%E7%BE%A9%E3%81%99%E3%82%8B/</guid>
      <description>Ansibleで配列を定義するには、角括弧で配列の中身をくくり、カンマで区切れば良い。
例:
array=[&amp;quot;data1&amp;quot;,&amp;quot;data2&amp;quot;] </description>
    </item>
    
    <item>
      <title>Kubernetesのsecrets用のbase64の結果が2行になってしまうとき</title>
      <link>/post/2017-11-12-kubernetes%E3%81%AEsecrets%E7%94%A8%E3%81%AEbase64%E3%81%AE%E7%B5%90%E6%9E%9C%E3%81%8C2%E8%A1%8C%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%86%E3%81%A8%E3%81%8D/</link>
      <pubDate>Sun, 12 Nov 2017 16:29:47 +0000</pubDate>
      
      <guid>/post/2017-11-12-kubernetes%E3%81%AEsecrets%E7%94%A8%E3%81%AEbase64%E3%81%AE%E7%B5%90%E6%9E%9C%E3%81%8C2%E8%A1%8C%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%97%E3%81%BE%E3%81%86%E3%81%A8%E3%81%8D/</guid>
      <description>Kubernetesのsecretsはbase64でエンコードした値を入力します。
 この時エンコードする文字列が長いとエンコード結果が2行になってしまうときがあります。
 2行の文字列をどうやってsecretsのymlファイルに書こうか少し迷いましたが、2行を単純に連結するだけで問題ありませんでした (知らなかった…)。
 ちなみにecho ‘hoge’ | base64してもいいですが、base64 &amp;lt;&amp;lt;&amp;lt; ‘hoge’とした方が短くてスマートですね (こちらも知らなかった…)。
 </description>
    </item>
    
    <item>
      <title>GKEからminikubeに移行した</title>
      <link>/post/2017-11-01-gke%E3%81%8B%E3%82%89minikube%E3%81%AB%E7%A7%BB%E8%A1%8C%E3%81%97%E3%81%9F/</link>
      <pubDate>Wed, 01 Nov 2017 01:08:47 +0000</pubDate>
      
      <guid>/post/2017-11-01-gke%E3%81%8B%E3%82%89minikube%E3%81%AB%E7%A7%BB%E8%A1%8C%E3%81%97%E3%81%9F/</guid>
      <description>GKEがとにかく高い。
ロードバランサーとn1-standard-1 (だったかな？)2つで月5, 6千円はかかっていた。
いままでは3万円分くらいのクレジットを使って実質無料で運用できていたけど、それも尽きそうだったので月1000円 メモリ2GBのVPSでminikubeを使って運用することにした。
移行はそこまで大変ではなく、NFSのデータとMySQLのダンプデータを載せ替えることと、GKE特有の設定の修正だけだった。
具体的には
 nodeSelectorの削除 gcePersistentDiskをhostPathに変更 ingressの静的IPアドレス設定を削除 ingressタイプをgceからnginxに変更 (annotationのingress.classをgceからnginxに変更) ingressのpathsで、既存の/*だけではなく/も追加 (GCEでは/*だけでも動いた） readinessProbeとlivenessProbeの秒数を長めに (スペックが落ちるので)  これでクレジット切れでサーバ運用費が極端に高くなることはなくなった。
この調子で他のメールサーバやjenkinsもkubenetesに集約して節約したい。
今回は調べた限りで一番安かったVultrというVPSサービスを利用した。
メモリ512MBで2.5ドル、1GBでは5ドルで、さくらVPSと比べるとほぼ半額ほど。
海外のサービスだけど東京リージョンもあるので、何ら不自由なく使えている。
ちなみに登録は下記バナーからしていただけると私にデポジットが入るので是非。</description>
    </item>
    
    <item>
      <title>minikubeが次のエラーで動かない時の対応  x509: certificate signed by unknown authority (possibly because of &amp;#8220;crypto/rsa: verification error&amp;#8221;</title>
      <link>/post/2017-10-27-543/</link>
      <pubDate>Fri, 27 Oct 2017 01:10:26 +0000</pubDate>
      
      <guid>/post/2017-10-27-543/</guid>
      <description>を実行した上で
を実行すると次のエラーが発生した。
 代わりに、下記コマンドを実行したところうまく行った。
 </description>
    </item>
    
    <item>
      <title>kubectlのオプションメモ</title>
      <link>/post/2017-10-26-kubectl%E3%81%AE%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%A1%E3%83%A2/</link>
      <pubDate>Thu, 26 Oct 2017 00:41:12 +0000</pubDate>
      
      <guid>/post/2017-10-26-kubectl%E3%81%AE%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%A1%E3%83%A2/</guid>
      <description>tips  getやdescribeサブコマンドはカンマ区切りで複数指定できる  * -w で結果をリアルタイムに出力できる（表示がおかしくなることが多々ある）
  -o wideで情報をより多く出すことができる # 例 $ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE nfs-server-1786322612-p0pw3 1/1 Running 0 1d 172.17.0.6 minikube  -o jsonや-o yamlでそれぞれの形式で出力することができる (情報もより多く出る) 例 $ kubectl get pods -o json { &amp;ldquo;apiVersion&amp;rdquo;: &amp;ldquo;v1&amp;rdquo;, &amp;ldquo;items&amp;rdquo;: [ { &amp;ldquo;apiVersion&amp;rdquo;: &amp;ldquo;v1&amp;rdquo;, &amp;ldquo;kind&amp;rdquo;: &amp;ldquo;Pod&amp;rdquo;, &amp;ldquo;metadata&amp;rdquo;: { &amp;ldquo;annotations&amp;rdquo;: { &amp;ldquo;kubernetes.io/created-by&amp;rdquo;: &amp;ldquo;{&amp;quot;kind&amp;quot;:&amp;quot;SerializedReference&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;v1&amp;quot;,&amp;quot;reference&amp;quot;:{&amp;quot;kind&amp;quot;:&amp;quot;ReplicaSet&amp;quot;,&amp;quot;namespace&amp;quot;:&amp;quot;default&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;nfs-server-1786322612&amp;quot;,&amp;quot;uid&amp;quot;:&amp;quot;e8cf196e-b80f-11e7-87c4-080027159c1b&amp;quot;,&amp;quot;apiVersion&amp;quot;:&amp;quot;extensions&amp;quot;,&amp;quot;resourceVersion&amp;quot;:&amp;quot;13198&amp;quot;}}\n&amp;rdquo; }, &amp;ldquo;creationTimestamp&amp;rdquo;: &amp;ldquo;2017-10-23T16:33:32Z&amp;rdquo;, &amp;ldquo;generateName&amp;rdquo;: &amp;ldquo;nfs-server-1786322612-&amp;quot;, &amp;ldquo;labels&amp;rdquo;: { &amp;ldquo;pod-template-hash&amp;rdquo;: &amp;ldquo;1786322612&amp;rdquo;, &amp;ldquo;role&amp;rdquo;: &amp;ldquo;nfs-server&amp;rdquo; }, &amp;ldquo;name&amp;rdquo;: &amp;ldquo;nfs-server-1786322612-p0pw3&amp;rdquo;, &amp;ldquo;namespace&amp;rdquo;: &amp;ldquo;default&amp;rdquo;, 略  --no-headersでヘッダーを取り除くことができる (パイプを使うときに便利） # 例 $ kubectl get pods &amp;ndash;no-headers nfs-server-1786322612-p0pw3 1/1 Running 0 1d  -o jsonpath --template={(フィールド)}で指定のフィールドのみを出力することができる # 例 $ kubectl get pods -o jsonpath &amp;ndash;template {.</description>
    </item>
    
    <item>
      <title>サーバで通信をポートフォワードする</title>
      <link>/post/2017-09-21-%E3%82%B5%E3%83%BC%E3%83%90%E3%81%A7%E9%80%9A%E4%BF%A1%E3%82%92%E3%83%9D%E3%83%BC%E3%83%88%E3%83%95%E3%82%A9%E3%83%AF%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 21 Sep 2017 19:10:53 +0000</pubDate>
      
      <guid>/post/2017-09-21-%E3%82%B5%E3%83%BC%E3%83%90%E3%81%A7%E9%80%9A%E4%BF%A1%E3%82%92%E3%83%9D%E3%83%BC%E3%83%88%E3%83%95%E3%82%A9%E3%83%AF%E3%83%BC%E3%83%89%E3%81%99%E3%82%8B/</guid>
      <description>サーバ内で通信をポートフォワードする。例えば3000ポートで動いているWebサーバを、外からは80ポートで通信を受け取りたいという場合。
iptablesを使うと次のようになる。
 1行目はポートフォワードの設定で、2行目はeth0への他の通信をすべて許可する設定となっている。
これはiptablesをファイアウォールとしてではなく、完全にポートフォワードするためだけの設定を想定している。
もしiptablesをファイアウォールとしてすでに使っている場合は、2行目のコマンドは実行しないようにする。
※ローカルからの通信はポートフォワードされないので注意する。</description>
    </item>
    
    <item>
      <title>ThinkPad X220を買った</title>
      <link>/post/2017-09-04-thinkpad-x220%E3%82%92%E8%B2%B7%E3%81%A3%E3%81%9F/</link>
      <pubDate>Mon, 04 Sep 2017 23:52:51 +0000</pubDate>
      
      <guid>/post/2017-09-04-thinkpad-x220%E3%82%92%E8%B2%B7%E3%81%A3%E3%81%9F/</guid>
      <description>目的   Windowsで遊びたかった ThinkPadにあこがれていた Microsoftがデベロッパー寄りになっているし、Linux SubsystemでWindowsも開発に使えるのではないかと思った  PCについて 
 ThinkPad X220 i5-2520M, 4GB, 300GB オークションで入手 送料込みで1.1万円程度 英字キーボード Windows10 Pro 充放電サイクル82回  やったこと 初期化 Windows自体の機能で初期化の機能がついているのでこれを利用する。
設定 -&amp;gt; 更新とセキュリティ -&amp;gt; このPCを初期状態に戻す -&amp;gt; すべて削除する
更新 Windows Updateを実行
キー配列変更 キー配列をJISから英字に変更。
設定 -&amp;gt; 時刻と言語 -&amp;gt; 地域と言語 -&amp;gt; 日本語 -&amp;gt; オプション -&amp;gt; レイアウトを変更する
参考: Windows10日本語版で英語配列キーボードを使用する
System Update LenovoからSystem Updateをインストール
Lenovoのサポートサイトから各ドライバをインストール（Windows10向けのものはないため、Windows8を使う)
Linux Sybsystem Microsoftの手順に従ってインストールをする
hyper-v Microsoftの手順に従ってインストールをする
cmder cmderというターミナルから直接Ubuntuのbashにアクセスする
http://cmder.net/
http://qiita.com/yutaszk/items/fb77435296b131fd0a3a
Ubuntu環境構築 zsh apt-get install zsh</description>
    </item>
    
    <item>
      <title>Androidアプリの定期購入の返金（払い戻し・キャンセル）方法</title>
      <link>/post/2017-09-04-android%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AE%E5%AE%9A%E6%9C%9F%E8%B3%BC%E5%85%A5%E3%81%AE%E8%BF%94%E9%87%91%E6%89%95%E3%81%84%E6%88%BB%E3%81%97%E3%82%AD%E3%83%A3%E3%83%B3%E3%82%BB/</link>
      <pubDate>Mon, 04 Sep 2017 22:45:26 +0000</pubDate>
      
      <guid>/post/2017-09-04-android%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AE%E5%AE%9A%E6%9C%9F%E8%B3%BC%E5%85%A5%E3%81%AE%E8%BF%94%E9%87%91%E6%89%95%E3%81%84%E6%88%BB%E3%81%97%E3%82%AD%E3%83%A3%E3%83%B3%E3%82%BB/</guid>
      <description>Androidアプリの場合、定期購入の課金がされてしまっても、48時間以内なら返金できる場合があります。
次の手順にしたがって返金申請を行いましょう。
 下記ページにアクセス  https://play.google.com/store/account
 払い戻ししたいアプリの横の3点アイコンを選択
  “問題を報告”を選択
  フォームに必要事項を記入 (無料期間中にキャンセルするつもりだったが、キャンセルするのを忘れていたことを記載)
  以上のステップで返金できる場合があります。
私の場合はフォーム記入・送信後すぐに返金するとの旨のメールを受信しました。
参考:
https://support.google.com/googleplay/answer/2479637</description>
    </item>
    
    <item>
      <title>ImportError: No module named paramiko</title>
      <link>/post/2017-08-20-importerror-no-module-named-paramiko/</link>
      <pubDate>Sun, 20 Aug 2017 15:38:54 +0000</pubDate>
      
      <guid>/post/2017-08-20-importerror-no-module-named-paramiko/</guid>
      <description>Ansible徹底入門を写経していたところ、Dynamic Inventoryのvagrant.py実行で下記エラーが出てしまった。
 元入ってるpythonとこの本に従って入れたpythonがごっちゃになっているようだった。
vagrant.pyの実行だけなら “`python2 ./vagrant.py“` で動くが、ansible-playbookでインベントリにvagrant.pyを使うとなるとエラーとなる。
そこでvirtualenvを使って、ディレクトリ単位でpythonを管理する。
 具体的には次のようにする。
 virtualenv環境を終了する場合は次のコマンドを実行する。
  </description>
    </item>
    
    <item>
      <title>Route53をGitで管理するようにした</title>
      <link>/post/2017-08-11-roadworker%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6route53%E3%82%92git%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%99%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%97%E3%81%9F/</link>
      <pubDate>Fri, 11 Aug 2017 09:03:57 +0000</pubDate>
      
      <guid>/post/2017-08-11-roadworker%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6route53%E3%82%92git%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%99%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%97%E3%81%9F/</guid>
      <description>Route53のレコード管理は困難を極める。
いつの間にかレコードが増えてきて、後から消そうと思っても用途などが思い出せず消すに消せない…そんなレコードが増える経験をした。
Route53をGitで管理するようにすればPRによる第三者のレビューがやりやすいし、何より誰がいつどんな用途でレコードを追加・変更・削除したのかが丸分かりである。
ここではroadworkerというナイスなRuby製のGemを使った。
https://github.com/codenize-tools/roadworker
使い方は上記リポジトリもあるが、基本的には次の通り。
  現在のRoute53登録情報をファイルにする (初回のみ) roadwork -e -o Routefile  ファイルを編集する
  確認のためにdry-runする roadwork -a &amp;ndash;dry-run  Route53に反映 roadwork -a  反映確認 roadwork -t    これでRoute53の管理が楽になった。
次はGitHubにファイルをプッシュするとCIツールによってRoute53に自動的に反映させるようにしたい。
8/20追記
Jenkinsで自動反映するようにした。
GitHubのWebHookをJenkinsで受けて、roadworkを実行。進捗はJenkinsのSlackプラグインを使った。</description>
    </item>
    
    <item>
      <title>ImageMagicのコマンドで画像サイズを調べる方法</title>
      <link>/post/2017-07-24-imagemagic%E3%81%AE%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E7%94%BB%E5%83%8F%E3%82%B5%E3%82%A4%E3%82%BA%E3%82%92%E8%AA%BF%E3%81%B9%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 24 Jul 2017 15:33:16 +0000</pubDate>
      
      <guid>/post/2017-07-24-imagemagic%E3%81%AE%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E7%94%BB%E5%83%8F%E3%82%B5%E3%82%A4%E3%82%BA%E3%82%92%E8%AA%BF%E3%81%B9%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>identifyコマンドを使う。具体的には次の通り。
formatオプションで表示内容を制御できる。</description>
    </item>
    
    <item>
      <title>kubectl cluster-infoがエラーで表示できない場合</title>
      <link>/post/2017-07-23-kubectl-cluster-info%E3%81%8C%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%A7%E8%A1%A8%E7%A4%BA%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88/</link>
      <pubDate>Sun, 23 Jul 2017 22:47:50 +0000</pubDate>
      
      <guid>/post/2017-07-23-kubectl-cluster-info%E3%81%8C%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%A7%E8%A1%A8%E7%A4%BA%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88/</guid>
      <description>kubectl cluster-infoが下記エラーで表示できない場合の対応
  下記コマンドを実行してみる。
 </description>
    </item>
    
    <item>
      <title>Apacheでユーザエージェントでアクセス拒否する</title>
      <link>/post/2017-07-23-apache%E3%81%A7%E3%83%A6%E3%83%BC%E3%82%B6%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88%E3%81%A7%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E6%8B%92%E5%90%A6%E3%81%99%E3%82%8B/</link>
      <pubDate>Sun, 23 Jul 2017 22:40:43 +0000</pubDate>
      
      <guid>/post/2017-07-23-apache%E3%81%A7%E3%83%A6%E3%83%BC%E3%82%B6%E3%82%A8%E3%83%BC%E3%82%B8%E3%82%A7%E3%83%B3%E3%83%88%E3%81%A7%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9%E6%8B%92%E5%90%A6%E3%81%99%E3%82%8B/</guid>
      <description>こんな感じで拒否できる (Apache 2.2系以前の場合)。
  </description>
    </item>
    
    <item>
      <title>OpsJAWS Systems Manager勉強会メモ</title>
      <link>/post/2017-07-19-opsjaws-systems-manager%E5%8B%89%E5%BC%B7%E4%BC%9A%E3%83%A1%E3%83%A2/</link>
      <pubDate>Wed, 19 Jul 2017 21:47:14 +0000</pubDate>
      
      <guid>/post/2017-07-19-opsjaws-systems-manager%E5%8B%89%E5%BC%B7%E4%BC%9A%E3%83%A1%E3%83%A2/</guid>
      <description>OpsJAWSの Meetup#12 ~ Systems Manager祭り ~に参加してきたので内容をメモ。
Amazon EC2 Systems Manager OS内部の構成を管理
下記の自動化
  ソフトウェアインベントリの収集
  OSパッチの適用
  システムイメージの作成
  OS設定
  Systems Managerは複数サービスで構成されている
Run Command リモートから任意の実行が可能
JSONベースでコマンド・タスクを定義
SSHポートを開ける必要がない
ステートマネージャー OSとアプリケーションの設定を定義、状態を維持する
JSONベースでポリシーを定義
EC2だけではなくオンプレも管理できる
インベントリ ソフトウェアインベントリの情報収集
オンプレも対応
JSONベースで取得するデータを定義
ステートマネージャから定期的に呼び出せる
メンテナンスウィンドウ 事前に設定した時間でメンテナンスを実施
組み込み済みのコマンド、Run Commandの実行が可能
可用性と信頼性の向上
時間と繰り返し間隔を設定 -&amp;gt; メンテナンス対象のターゲットを指定 -&amp;gt; 実行するタスクを設定
パッチマネージャ ベースラインを定義してWindows/Linuxのパッチを適用
Patch Baselineを使ってカスタムパッチポリシーを定義
オートメーション シンプルなワークフローをつかって一般的なタスクを自動化
パラメータストア IT資産の集中管理
ログイン、DB接続情報などを一元管理
Run Command, State Manager, Automationやコンソールから参照、更新可能
細かく権限管理して必要な人に必要な情報を提供
KMSで暗号化
IAMで制限できるため、パラメータ名の命名規則によって、環境ごとにアクセス可能なユーザを定義することができる
定義済みドキュメントが豊富</description>
    </item>
    
    <item>
      <title>KubernetesでNFSを使う</title>
      <link>/post/2017-07-19-kubernetes%E3%81%A7nfs%E3%82%92%E4%BD%BF%E3%81%86/</link>
      <pubDate>Wed, 19 Jul 2017 16:50:32 +0000</pubDate>
      
      <guid>/post/2017-07-19-kubernetes%E3%81%A7nfs%E3%82%92%E4%BD%BF%E3%81%86/</guid>
      <description>KurbernetesのPod / Node間でファイルを共有するために、NFSを使ってみる。
ググったり公式のリポジトリを参考にしたけどうまくいかなかったのでメモ。
 おおまかな手順   Compute Engineでディスクを用意
  NFSコンテナの用意
  コンテナからNFSを利用
   手順  Compute Engineでディスクを用意 コンソールかCLI等から普通に作成。
  NFSコンテナの用意 下記2ファイルを用意してkubectl createする。</description>
    </item>
    
    <item>
      <title>[Excel] PDF出力時シート毎にPDFファイルが分割される場合の対応</title>
      <link>/post/2017-07-14-excel-pdf%E5%87%BA%E5%8A%9B%E6%99%82%E3%82%B7%E3%83%BC%E3%83%88%E6%AF%8E%E3%81%ABpdf%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%8C%E5%88%86%E5%89%B2%E3%81%95%E3%82%8C%E3%82%8B%E5%A0%B4%E5%90%88/</link>
      <pubDate>Fri, 14 Jul 2017 14:59:24 +0000</pubDate>
      
      <guid>/post/2017-07-14-excel-pdf%E5%87%BA%E5%8A%9B%E6%99%82%E3%82%B7%E3%83%BC%E3%83%88%E6%AF%8E%E3%81%ABpdf%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%8C%E5%88%86%E5%89%B2%E3%81%95%E3%82%8C%E3%82%8B%E5%A0%B4%E5%90%88/</guid>
      <description>PDF出力時シート毎にPDFファイルが分割される場合の対応
レイアウトタブから印刷セクションの倍率を、全シートで同じ値に設定します。
※同じ値に設定されているように見えても、設定されていない場合があるため、一旦値を選択状態にしてEnterキーを押し、設定します。
それでも直らない場合、用紙サイズがシート毎に異なるかもしれません。
用紙サイズはシート毎に変更できるため、全シートで同じ物を設定してみてください。</description>
    </item>
    
    <item>
      <title>minikubeを使った後にGKEを使いたい場合</title>
      <link>/post/2017-07-14-minikube%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E5%BE%8C%E3%81%ABgke%E3%82%92%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%84%E5%A0%B4%E5%90%88/</link>
      <pubDate>Fri, 14 Jul 2017 13:04:59 +0000</pubDate>
      
      <guid>/post/2017-07-14-minikube%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E5%BE%8C%E3%81%ABgke%E3%82%92%E4%BD%BF%E3%81%84%E3%81%9F%E3%81%84%E5%A0%B4%E5%90%88/</guid>
      <description>minikubeを使ったあとにGKEを使おうと(kubectlコマンドを実行)すると、次のエラーが発生して接続できない。
対応としてはgcloud container clustersコマンドでクラスタ名を指定すればよい。
  </description>
    </item>
    
    <item>
      <title>kubernetes on GKEでLet&amp;#8217;s Encryptを使う</title>
      <link>/post/2017-07-09-kubernetes-on-gke%E3%81%A7lets-encrypt%E3%82%92%E4%BD%BF%E3%81%86/</link>
      <pubDate>Sun, 09 Jul 2017 13:05:28 +0000</pubDate>
      
      <guid>/post/2017-07-09-kubernetes-on-gke%E3%81%A7lets-encrypt%E3%82%92%E4%BD%BF%E3%81%86/</guid>
      <description>kubernetes on GKEでLet’s Encryptを使ったときのメモ
kubenetesでLet’s Encryptを使うのに、kube-legoを使用します。
kube-legoではGCEのロードバランサーとNginx Ingress Controllerが使えるようですが、今回はロードバランサーを使う手順でやります（このあたりよく分かっていない…)。
 7月13日追記
GCEのロードバランサーを使わない手順ができました。
https://github.com/kter/kube-study/tree/master/ingress/nginx-tls
kube-legoのダウンロード (メールアドレスを自分のものに編集)
 IPの払い出し IPを払い出す
払い出したIPにドメインを紐付けておく。
 ファイルの作成 kube-legoで使用するnginx-ingress.ymlを作成する。
SSL化したいサービスを下記web-service.ymlとした場合、nginx-ingress.ymlは次のようになるので適当な場所に作成しておく。
 kube-legoを作成する 設定が反映されるまで、十数分掛かるので暫く待つ。
備考 作成されるものはkube-legoというnamespaceとなっているため、kubectlを実行する際は--namespace kube-legoが必要になる。</description>
    </item>
    
    <item>
      <title>FUJI Wifiを契約して1ヶ月が経った</title>
      <link>/post/2017-06-29-fuji-wifi%E3%82%92%E5%A5%91%E7%B4%84%E3%81%97%E3%81%A61%E3%83%B6%E6%9C%88%E3%81%8C%E7%B5%8C%E3%81%A3%E3%81%9F/</link>
      <pubDate>Thu, 29 Jun 2017 13:18:35 +0000</pubDate>
      
      <guid>/post/2017-06-29-fuji-wifi%E3%82%92%E5%A5%91%E7%B4%84%E3%81%97%E3%81%A61%E3%83%B6%E6%9C%88%E3%81%8C%E7%B5%8C%E3%81%A3%E3%81%9F/</guid>
      <description>自宅の遅いソフトバンク光に嫌気がさしたのでFUJI Wifiを契約しました。

 速度はこんな感じです。

 使用用途は、モバイルと家の回線が遅いとき用です。
通勤時間帯の電車の中でもちょっと遅いながらも十分使える速度がでます。
格安SIMであるIIJmioではページの読み込みがタイムアウトになってしまうような状態でも、FUJI wifiであればちゃんとページを読み込んでくれます。
バッテリは13時間ほど持つ感覚ですね。
バッテリ残量が0%になった後も結構粘ってくれます。
 契約当初はこれで家のネット回線を解約できないかなと思ったけど、100GBプランでは足りないことが分かりました。
Amazon Prime Videoで映画を見たり、撮影した写真や動画をバックアップしたりするとあっという間に通信量を使ってしまい、無制限じゃないと使えないなと思った次第。
 料金は期間限定で毎月596円値引きキャンペーンをやっていて、税込み3,348円でした。</description>
    </item>
    
    <item>
      <title>ディスク容量 / ディスク使用量が空き容量 (%)と一致しない場合</title>
      <link>/post/2017-06-23-%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E5%AE%B9%E9%87%8F-%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E4%BD%BF%E7%94%A8%E9%87%8F%E3%81%8C%E7%A9%BA%E3%81%8D%E5%AE%B9%E9%87%8F-%E3%81%A8%E4%B8%80%E8%87%B4/</link>
      <pubDate>Fri, 23 Jun 2017 17:20:08 +0000</pubDate>
      
      <guid>/post/2017-06-23-%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E5%AE%B9%E9%87%8F-%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E4%BD%BF%E7%94%A8%E9%87%8F%E3%81%8C%E7%A9%BA%E3%81%8D%E5%AE%B9%E9%87%8F-%E3%81%A8%E4%B8%80%E8%87%B4/</guid>
      <description>ext4ディスクの場合、デフォルトで総容量の5%が/root用として予約されている。
ディスク容量 / ディスク使用量が空き容量 (%)と一致しない場合、こちらの可能性が高い。
 この領域を使用しない場合はこの予約容量を0にすることができる。
 予約容量の確認  Reserved block count × Block size が 予約容量[byte]となる。
 予約容量の削除   </description>
    </item>
    
    <item>
      <title>Google Cloud Next 2日目に行ってきた</title>
      <link>/post/2017-06-16-google-cloud-next-2%E6%97%A5%E7%9B%AE%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Fri, 16 Jun 2017 11:56:52 +0000</pubDate>
      
      <guid>/post/2017-06-16-google-cloud-next-2%E6%97%A5%E7%9B%AE%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>スペースのインデントが消えるのでGistに書いた…
[gist https://gist.github.com/kter/ae7dc4f598a9ef14838aacf956c67a9d]</description>
    </item>
    
    <item>
      <title>docker-composeのインストール</title>
      <link>/post/2017-06-03-docker-compose%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/</link>
      <pubDate>Sat, 03 Jun 2017 08:13:23 +0000</pubDate>
      
      <guid>/post/2017-06-03-docker-compose%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB/</guid>
      <description>AmazonLinuxでDockerが使いたくて、yum install dockerでDockerをインストールしたものの、docker-composeが使えなかった。
調べたところ、docker-composeのインストールは、バイナリをダウンロードするだけのようだった。
具体的にはGitHubのリリースページからダウンロードする。
実際に実行したコマンドは次の通り。</description>
    </item>
    
    <item>
      <title>データベース単位でいい感じにダンプする方法</title>
      <link>/post/2017-05-23-%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9%E5%8D%98%E4%BD%8D%E3%81%A7%E3%81%84%E3%81%84%E6%84%9F%E3%81%98%E3%81%AB%E3%83%80%E3%83%B3%E3%83%97%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Tue, 23 May 2017 17:31:18 +0000</pubDate>
      
      <guid>/post/2017-05-23-%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9%E5%8D%98%E4%BD%8D%E3%81%A7%E3%81%84%E3%81%84%E6%84%9F%E3%81%98%E3%81%AB%E3%83%80%E3%83%B3%E3%83%97%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Linuxコマンドで添付ファイル付きのメールを送る</title>
      <link>/post/2017-05-12-linux%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E6%B7%BB%E4%BB%98%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E4%BB%98%E3%81%8D%E3%81%AE%E3%83%A1%E3%83%BC%E3%83%AB%E3%82%92%E9%80%81%E3%82%8B/</link>
      <pubDate>Fri, 12 May 2017 19:02:55 +0000</pubDate>
      
      <guid>/post/2017-05-12-linux%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%81%A7%E6%B7%BB%E4%BB%98%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E4%BB%98%E3%81%8D%E3%81%AE%E3%83%A1%E3%83%BC%E3%83%AB%E3%82%92%E9%80%81%E3%82%8B/</guid>
      <description>Linuxコマンドで添付ファイル付きのメールを送りたい場合の手順です。
下記内容をsendmail -i -tにパイプで渡します。
`From: (送信元メールアドレス)To: (送信先メールアドレス)Subject: (件名)Content-Type: multipart/mixed; boundary=&amp;quot;BOUNDARY&amp;quot;・コンテンツタイプにはapplication/pdf等添付ファイルに応じたものを入力します。
・boundary=&amp;quot;BOUNDARY&amp;quot;のBOUNDARYは任意の文字列で大丈夫です。</description>
    </item>
    
    <item>
      <title>SSHで踏み台を利用する場合の.ssh/config</title>
      <link>/post/2017-05-12-ssh%E3%81%A7%E8%B8%8F%E3%81%BF%E5%8F%B0%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE-sshconfig/</link>
      <pubDate>Fri, 12 May 2017 18:54:38 +0000</pubDate>
      
      <guid>/post/2017-05-12-ssh%E3%81%A7%E8%B8%8F%E3%81%BF%E5%8F%B0%E3%82%92%E5%88%A9%E7%94%A8%E3%81%99%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE-sshconfig/</guid>
      <description>SSHでサーバにログインする時、踏み台を経由する場合があります。
そんな時の.ssh/configの設定です。
下記設定であれば、
ssh (SSH先識別名)
で踏み台サーバを経由して目的のサーバにログインできます。
`SSH先 Host (SSH先識別名)Hostname IPアドレスProxyCommand ssh -W %h:%p SSH踏み台識別名</description>
    </item>
    
    <item>
      <title>Apple Watchの裏蓋が外れたけど無償交換になった</title>
      <link>/post/2017-04-06-apple-watch%E3%81%AE%E8%A3%8F%E8%93%8B%E3%81%8C%E5%A4%96%E3%82%8C%E3%81%9F%E3%81%91%E3%81%A9%E7%84%A1%E5%84%9F%E4%BA%A4%E6%8F%9B%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F/</link>
      <pubDate>Thu, 06 Apr 2017 12:55:51 +0000</pubDate>
      
      <guid>/post/2017-04-06-apple-watch%E3%81%AE%E8%A3%8F%E8%93%8B%E3%81%8C%E5%A4%96%E3%82%8C%E3%81%9F%E3%81%91%E3%81%A9%E7%84%A1%E5%84%9F%E4%BA%A4%E6%8F%9B%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%9F/</guid>
      <description>3月29日朝、Apple Watchを充電器から外すと裏蓋が外れてしまった。
 
 すぐにGenius Barを予約して31日にApple Storeに赴いた。
 修理について保証期間は終わっていたが、無償修理の対象ということで修理代金は無料だった。
しかし工場に配送する必要があり、1 ~ 2週間ほどかかるとのこと。
 4日後の4月4日、修理が終わりApple Storeで交換品を受け取った。
少しかすり傷があったのだが、修理ではなく交換となったので新品同様のものが手に入ってラッキーだった。</description>
    </item>
    
    <item>
      <title>Sierraにアップデートした後メモアプリが立ち上がらなくなった場合の対処</title>
      <link>/post/2016-09-24-sierra%E3%81%AB%E3%82%A2%E3%83%83%E3%83%97%E3%83%87%E3%83%BC%E3%83%88%E3%81%97%E3%81%9F%E5%BE%8C%E3%83%A1%E3%83%A2%E3%82%A2%E3%83%97%E3%83%AA%E3%81%8C%E7%AB%8B%E3%81%A1%E4%B8%8A%E3%81%8C%E3%82%89/</link>
      <pubDate>Sat, 24 Sep 2016 11:19:59 +0000</pubDate>
      
      <guid>/post/2016-09-24-sierra%E3%81%AB%E3%82%A2%E3%83%83%E3%83%97%E3%83%87%E3%83%BC%E3%83%88%E3%81%97%E3%81%9F%E5%BE%8C%E3%83%A1%E3%83%A2%E3%82%A2%E3%83%97%E3%83%AA%E3%81%8C%E7%AB%8B%E3%81%A1%E4%B8%8A%E3%81%8C%E3%82%89/</guid>
      <description>Sierraにアップデートしてから、メモアプリを立ち上げると直ぐにアプリが強制終了するようになってしまいました。
これはiCloudにブラウザでログインして、何行か書き込んでからメモアプリを立ち上げると上手くいくようです。
 参考
Notes Crashing in macOS Sierra</description>
    </item>
    
    <item>
      <title>艦これ 2016年期間限定夏イベント 「迎撃！第二次マレー沖海戦」</title>
      <link>/post/2016-08-29-%E8%89%A6%E3%81%93%E3%82%8C-2016%E5%B9%B4%E6%9C%9F%E9%96%93%E9%99%90%E5%AE%9A%E5%A4%8F%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-%E8%BF%8E%E6%92%83%E7%AC%AC%E4%BA%8C%E6%AC%A1%E3%83%9E/</link>
      <pubDate>Mon, 29 Aug 2016 11:03:01 +0000</pubDate>
      
      <guid>/post/2016-08-29-%E8%89%A6%E3%81%93%E3%82%8C-2016%E5%B9%B4%E6%9C%9F%E9%96%93%E9%99%90%E5%AE%9A%E5%A4%8F%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-%E8%BF%8E%E6%92%83%E7%AC%AC%E4%BA%8C%E6%AC%A1%E3%83%9E/</guid>
      <description>E-1  E-1甲伊26掘り消費資材 1000/-1000/2000/-1000/85
出撃回数およそ76回。あきつ丸1、まるゆ6
 E-2  E-3    E-4  消費資材 E-1掘りはイベント攻略後に行いましたが、その時にまるゆが6隻出たのは幸運だったと思います。</description>
    </item>
    
    <item>
      <title>日本丸の総帆展帆を見てきた</title>
      <link>/post/2016-07-23-%E6%97%A5%E6%9C%AC%E4%B8%B8%E3%81%AE%E7%B7%8F%E5%B8%86%E5%B1%95%E5%B8%86%E3%82%92%E8%A6%8B%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Sat, 23 Jul 2016 15:31:06 +0000</pubDate>
      
      <guid>/post/2016-07-23-%E6%97%A5%E6%9C%AC%E4%B8%B8%E3%81%AE%E7%B7%8F%E5%B8%86%E5%B1%95%E5%B8%86%E3%82%92%E8%A6%8B%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>7/18 横浜にある日本丸の総帆展帆を見てきました。
総帆展帆とは普段は畳んでいる帆を広げる行事です。
20メートル以上はありそうなマストの頂上付近まで登って、ボランティアの方達が作業していました。

帰りは山下公園まで散歩して帰りました。
大さん橋では飛鳥Ⅱが出港するところだったので、お見送りをしました。</description>
    </item>
    
    <item>
      <title>入谷朝顔市に行ってきた</title>
      <link>/post/2016-07-23-%E5%85%A5%E8%B0%B7%E6%9C%9D%E9%A1%94%E5%B8%82%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Sat, 23 Jul 2016 15:04:01 +0000</pubDate>
      
      <guid>/post/2016-07-23-%E5%85%A5%E8%B0%B7%E6%9C%9D%E9%A1%94%E5%B8%82%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>7/6鶯谷駅の近くにある入谷朝顔市に行ってきました。
江戸時代から続いている市のようです。
現地では歩道の脇に朝顔を売っている露店が軒を連ねていてなかなかに風情があります。
反対側では屋台も出ていて、夜は道路も歩行者天国になります。
地方発送も受け付けているので去年に引き続き今年も買い求めました。</description>
    </item>
    
    <item>
      <title>免許証を更新した</title>
      <link>/post/2016-07-06-%E5%85%8D%E8%A8%B1%E8%A8%BC%E3%82%92%E6%9B%B4%E6%96%B0%E3%81%97%E3%81%9F/</link>
      <pubDate>Wed, 06 Jul 2016 14:38:22 +0000</pubDate>
      
      <guid>/post/2016-07-06-%E5%85%8D%E8%A8%B1%E8%A8%BC%E3%82%92%E6%9B%B4%E6%96%B0%E3%81%97%E3%81%9F/</guid>
      <description>免許証を更新しました。
今回で優良区分だったので視力検査と写真を取りなおして30分の講習で更新完了。
更新料は3000円でした。
新宿免許証センターだったので、講習の待ち時間は都庁の展望台で時間を潰しました。

免許証に金の帯が入るのは知っていましたが優良マークも付くんですね。</description>
    </item>
    
    <item>
      <title>EC2のRetirement Notificationに対応した</title>
      <link>/post/2016-07-03-ec2%E3%81%AEretirement-notification%E3%81%AB%E5%AF%BE%E5%BF%9C%E3%81%97%E3%81%9F/</link>
      <pubDate>Sun, 03 Jul 2016 13:10:55 +0000</pubDate>
      
      <guid>/post/2016-07-03-ec2%E3%81%AEretirement-notification%E3%81%AB%E5%AF%BE%E5%BF%9C%E3%81%97%E3%81%9F/</guid>
      <description>EC2のRetirement Notificationが来ていたので対応しました。
メールでの対応方法では次のように来ていて、つまりAMIからインスタンスを作りなおせと書いてありました。
 You may still be able to access the instance. We recommend that you replace the instance by creating an AMI of your instance and launch a new instance from the AMI. For more information please see Amazon Machine Images (http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html&amp;lt;/a&amp;gt;) in the EC2 User Guide. In case of difficulties stopping your EBS-backed instance, please see the Instance FAQ (http://aws.amazon.com/instance-help/#ebs-stuck-stopping&amp;lt;/a&amp;gt;).
 実際にはインスタンスを停止してから起動するだけで大丈夫でした。</description>
    </item>
    
    <item>
      <title>横浜に行ってきた</title>
      <link>/post/2016-07-02-%E6%A8%AA%E6%B5%9C%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Sat, 02 Jul 2016 10:27:37 +0000</pubDate>
      
      <guid>/post/2016-07-02-%E6%A8%AA%E6%B5%9C%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>6月18日に横浜に観光に行ってきました。
 14:30 帆船日本丸見学 日本丸は1930年に進水した大型練習帆船です。現在は引退しており横浜に係留されています。
年に何回か帆を広げる日があるらしいので次は是非その日に訪れたいですね。
               
 15:40 横浜みなと博物館見学 横浜みなと博物館は日本丸の隣にある博物館で、横浜の開港前から戦時、そして現在までの歴史が詳しく展示がされています。
また港の仕組みなどの展示もあり勉強になりました。
実は途中で閉館時間が来てしまい、最後のほうがよく見れていないので日本丸の総帆展帆の日と合わせてもう一度見学したいです。
 18:00 大さん橋 横浜みなと博物館で横浜港の歴史を見てきたので帰る前に立ち寄りました。
夕日が綺麗そうだったので大さん橋内の喫茶店で時間を潰した後、夕日を眺めました。</description>
    </item>
    
    <item>
      <title>タイムズプラスに入会した</title>
      <link>/post/2016-07-01-%E3%82%BF%E3%82%A4%E3%83%A0%E3%82%BA%E3%83%97%E3%83%A9%E3%82%B9%E3%81%AB%E5%85%A5%E4%BC%9A%E3%81%97%E3%81%9F/</link>
      <pubDate>Fri, 01 Jul 2016 21:11:54 +0000</pubDate>
      
      <guid>/post/2016-07-01-%E3%82%BF%E3%82%A4%E3%83%A0%E3%82%BA%E3%83%97%E3%83%A9%E3%82%B9%E3%81%AB%E5%85%A5%E4%BC%9A%E3%81%97%E3%81%9F/</guid>
      <description>思うところがあってカーシェアリングのタイムズプラスに入会しました。
最初店舗で入会しようと思っていましたが、手続きに数日かかるようだったので、即日入会できる無人機を利用しました。
無人機は新宿サブナード地下の駐車場ロビーにありました。
住所などを端末に入力した後、免許証とクレジットカードを読み込ませるだけだったので簡単でした。</description>
    </item>
    
    <item>
      <title>横須賀に行ってきた</title>
      <link>/post/2016-06-12-%E6%A8%AA%E9%A0%88%E8%B3%80%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Sun, 12 Jun 2016 22:23:32 +0000</pubDate>
      
      <guid>/post/2016-06-12-%E6%A8%AA%E9%A0%88%E8%B3%80%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>本命は はいふりのトークショーだったのですが、日付を間違え1日早く行ってしまいました… 。
ということで気を取り直して横須賀観光をしていました。
 軍港めぐり
当日券が空いていたので予約無しで乗ることができました。
その日は護衛艦が特別多かったようで、日米合わせてイージス艦だけで10隻ほどいたようです。
世界にはイージス艦が100隻ほどあるそうなので一割が集まっていたことになります。
軍港めぐりは以前にも参加したことがありますが、毎回停泊している艦艇が違うので飽きませんね。
 よこすかYYのりものフェスタ2016
[よこすかYYのりものフェスタ2016](https://www.cocoyoko.net/event/norimono-fes.html) では「いずも」の一般公開がありました。
いずもに乗るのは二回目ですが相変わらず大きいです。建て物と比べるとスケールがおかしい… 。護衛艦いずも いずもの一般公開の後は横須賀カレー本舗でカレーを食べてきました。あまり辛くなく食べやすくて美味しかったです。
ハイスクール・フリートとのコラボのせいなのか、混んでいて店外で1時間待ちましたが。金剛カレー カレーを食べた後は馬堀海岸の湯楽の里へ温泉に入りに行きました。
道すがら夕日と海が一望できました。馬堀海岸の夕暮れ ここの露天風呂は東京湾に面しています。
なので刻々と色を変える夕日と東京湾と夜景が露天風呂に入りながら堪能できました。</description>
    </item>
    
    <item>
      <title>ExpansysでXperia Z5 Compactを買った</title>
      <link>/post/2016-06-11-expansys%E3%81%A7xperia-z5-compact%E3%82%92%E8%B2%B7%E3%81%A3%E3%81%9F/</link>
      <pubDate>Sat, 11 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-06-11-expansys%E3%81%A7xperia-z5-compact%E3%82%92%E8%B2%B7%E3%81%A3%E3%81%9F/</guid>
      <description>ExpansysでXperia Z5 Compactを購入しました。
買うきっかけはスマホ版艦これをプレイするためです。
手持ちのAndroid端末はOSが4.4で推奨環境を満たせないことと、バッテリがすぐ切れることと。それから動作がもっさりしていたので新しく買うことにしました。
Z5 Compactの理由は技適が通っていて、スペックも良く、また4万円前半で手に入るからでした。
また以前Z3 Compactを使っていたという理由もあります。
注文したのが6月6日15時、渋谷で受け取れたのが6月8日の2時半でした。
触ってみての感想は側面がやや安っぽく見えるものの背面のサラサラ感はいいと思いました。
画面の解像度は低めですがディスプレイが小さいことも相まって気になりません。
またIIJmioのデータ通信専用SIMを使っているせいか、セルスタンバイ現象と常に「選択したネットワークは利用不可です」という警告が通知バーに出ています。
そのためSMSシムに交換手続きをしました。
Source: New feed</description>
    </item>
    
    <item>
      <title>艦これアーケードプレイの巻</title>
      <link>/post/2016-05-30-%E8%89%A6%E3%81%93%E3%82%8C%E3%82%A2%E3%83%BC%E3%82%B1%E3%83%BC%E3%83%89%E3%83%97%E3%83%AC%E3%82%A4%E3%81%AE%E5%B7%BB/</link>
      <pubDate>Mon, 30 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-05-30-%E8%89%A6%E3%81%93%E3%82%8C%E3%82%A2%E3%83%BC%E3%82%B1%E3%83%BC%E3%83%89%E3%83%97%E3%83%AC%E3%82%A4%E3%81%AE%E5%B7%BB/</guid>
      <description>春イベントの最終海域で沼ることを想定して5月30日は有給をとっていました。
ところが最終海域は割とあっさり抜け、また親潮も割と直ぐ邂逅できたため、前からやりたかった艦これアーケードをプレイしてきました。
まず動いている艦娘が大画面で見れるのがいいと思いました。
ゲーム内容も運に任せるしかないブラウザ版にくらべて、プレイヤーの操作次第で結果を変えられるアーケード版はストレスがなくていいですね。
ただ難があるのは順番待ち時間。平日の午前中に行ったにもかからわずプレイまで2時間も掛かりました。
戦果はこんな感じ。運良く中破ホロを二回連続で引くことができました。
帰りは前から食べたかったシロノワールを食べて帰宅。うわさ通りの美味しさでした。
しかし900キロカロリーもあるとは…
Source: New feed</description>
    </item>
    
    <item>
      <title>2016年春イベント 開設！基地航空隊</title>
      <link>/post/2016-05-29-2016%E5%B9%B4%E6%98%A5%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-%E9%96%8B%E8%A8%AD%E5%9F%BA%E5%9C%B0%E8%88%AA%E7%A9%BA%E9%9A%8A/</link>
      <pubDate>Sun, 29 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-05-29-2016%E5%B9%B4%E6%98%A5%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-%E9%96%8B%E8%A8%AD%E5%9F%BA%E5%9C%B0%E8%88%AA%E7%A9%BA%E9%9A%8A/</guid>
      <description>艦これ 2016年春イベント 「開設！基地航空隊」をクリアしたので所感のほどを。
難易度は報酬と海域の難易度で決めていますが、今回はすべて甲で。
イベント攻略に要したリソースは次の通り。
  消費資材
63000/66000/8000/27000
  消費高速修復材
296
  以下各海域と掘りのメモ。
E-1   消費資源
4000/4500/1000/600
  消費高速修復材
31
  艦隊編成
  撃破時
  E-2   消費資源
5000/8000/2000/100
  消費高速修復材
20
  艦隊編成
  撃破時
  E-3   消費資源
2000/-100/-5000/-1000
  消費高速修復材
22
  艦隊編成
  撃破時
  E-4   消費資源</description>
    </item>
    
    <item>
      <title>よこすかカレーフェスティバルに行ってきた</title>
      <link>/post/2016-05-17-%E3%82%88%E3%81%93%E3%81%99%E3%81%8B%E3%82%AB%E3%83%AC%E3%83%BC%E3%83%95%E3%82%A7%E3%82%B9%E3%83%86%E3%82%A3%E3%83%90%E3%83%AB%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Tue, 17 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-05-17-%E3%82%88%E3%81%93%E3%81%99%E3%81%8B%E3%82%AB%E3%83%AC%E3%83%BC%E3%83%95%E3%82%A7%E3%82%B9%E3%83%86%E3%82%A3%E3%83%90%E3%83%AB%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>5月14日に横須賀 三笠公園で開催された よこすかカレーフェスティバル に行ってきました。
ハイスクール・フリートのコラボ中だったので、カレーフェスティバルの前に、さかくら総本家にも行きました。
コラボ商品はどら焼き、ラムネ、プリンがありました。
プリンについては人気で売り切れていましたが、並んでいる時に入荷したため運良く買うことができました。
その後カレーフェスティバルの会場である三笠公園に移動。
よこすかカレーフェスティバルでは、全国ご当地カレーグランプリと、よこすか海軍カレーと横須賀海上自衛隊カレーのバイキングがありました。
ただ15時少し前についたためほとんど売り切れという悲しい状態でした。
その中で頂いたのは黒部ダムカレー、銀山温泉のカリーパンでした。
帰り際串かつが割引になっていたので夕飯に買いました。
その後ヴェルニー公園でバラを見てきました。
Source: New feed</description>
    </item>
    
    <item>
      <title>艦これオーケストラに行ってきた</title>
      <link>/post/2016-05-07-%E8%89%A6%E3%81%93%E3%82%8C%E3%82%AA%E3%83%BC%E3%82%B1%E3%82%B9%E3%83%88%E3%83%A9%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Sat, 07 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-05-07-%E8%89%A6%E3%81%93%E3%82%8C%E3%82%AA%E3%83%BC%E3%82%B1%E3%82%B9%E3%83%88%E3%83%A9%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>5月7日、東京オペラシティにて「艦これ」クラシックスタイルオーケストラに行ってきました。
オーケストラを生演奏で聴くのは初めてのことでしたが、普段聴いている音楽がこうして演奏されるのは感慨深いものがありました。
特に終盤の母港と出撃の曲は一番よく聞く曲だけに感動もひとしおで、その後の提督との絆で泣けてしまいました。
Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2016-04-25-author-reference/</link>
      <pubDate>Mon, 25 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2016-04-25-author-reference/</guid>
      <description>April the twenty-fifth? </description>
    </item>
    
    <item>
      <title>上野東照宮ぼたん苑に行ってきた</title>
      <link>/post/2016-04-24-%E4%B8%8A%E9%87%8E%E6%9D%B1%E7%85%A7%E5%AE%AE%E3%81%BC%E3%81%9F%E3%82%93%E8%8B%91%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Sun, 24 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-04-24-%E4%B8%8A%E9%87%8E%E6%9D%B1%E7%85%A7%E5%AE%AE%E3%81%BC%E3%81%9F%E3%82%93%E8%8B%91%E3%81%AB%E8%A1%8C%E3%81%A3%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>タイトルの通り上野にある 上野東照宮ぼたん苑 に行ってきました。
何枚か写真を撮ったのでそれをお見せします。









ぼたん苑の後は上野東照宮にお参りし、上野恩賜公園と花園稲荷神社と不忍池弁天堂に寄って帰ってきました。
ぼたん苑は5月10日までやっています。
Source: New feed</description>
    </item>
    
    <item>
      <title>LetsEncrypt証明書発行方法</title>
      <link>/post/2016-04-17-letsencrypt%E8%A8%BC%E6%98%8E%E6%9B%B8%E7%99%BA%E8%A1%8C%E6%96%B9%E6%B3%95/</link>
      <pubDate>Sun, 17 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-04-17-letsencrypt%E8%A8%BC%E6%98%8E%E6%9B%B8%E7%99%BA%E8%A1%8C%E6%96%B9%E6%B3%95/</guid>
      <description>Dockerで証明書を発行できる。
※外部から443にアクセスできるようポートを開けておく
生成されたファイルは下記ファイルに保存される
Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/2016/04/03/%E9%94%99%E8%AF%AF.html</link>
      <pubDate>Sun, 03 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/04/03/%E9%94%99%E8%AF%AF.html</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/2016/04/02/%E9%94%99%E8%AF%AF.html</link>
      <pubDate>Sat, 02 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/04/02/%E9%94%99%E8%AF%AF.html</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2016-04-01-%E9%94%99%E8%AF%AF/</link>
      <pubDate>Fri, 01 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2016-04-01-%E9%94%99%E8%AF%AF/</guid>
      <description></description>
    </item>
    
    <item>
      <title>3-5北ルート編成</title>
      <link>/post/2016-03-21-3-5%E5%8C%97%E3%83%AB%E3%83%BC%E3%83%88%E7%B7%A8%E6%88%90/</link>
      <pubDate>Mon, 21 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-03-21-3-5%E5%8C%97%E3%83%AB%E3%83%BC%E3%83%88%E7%B7%A8%E6%88%90/</guid>
      <description>3-5北ルート編成を自分用にメモ
南ルートに比べて資源消費は多いけどその分大破撤退は少ないので攻略は楽
Source: New feed</description>
    </item>
    
    <item>
      <title>4-4艦隊編成</title>
      <link>/post/2016-03-21-4-4%E8%89%A6%E9%9A%8A%E7%B7%A8%E6%88%90/</link>
      <pubDate>Mon, 21 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-03-21-4-4%E8%89%A6%E9%9A%8A%E7%B7%A8%E6%88%90/</guid>
      <description>4-4の艦隊編成です。
ウィークリー任務の南方海域珊瑚諸島沖の制空権を握れ！の任務の前提が的東方中枢艦隊を撃破せよ！となっており、4-4のボス戦をAもしくはS勝利を一度する必要があります。
Source: New feed</description>
    </item>
    
    <item>
      <title>敵北方艦隊主力を撃滅せよ！任務編成</title>
      <link>/post/2016-03-21-%E6%95%B5%E5%8C%97%E6%96%B9%E8%89%A6%E9%9A%8A%E4%B8%BB%E5%8A%9B%E3%82%92%E6%92%83%E6%BB%85%E3%81%9B%E3%82%88%E4%BB%BB%E5%8B%99%E7%B7%A8%E6%88%90/</link>
      <pubDate>Mon, 21 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-03-21-%E6%95%B5%E5%8C%97%E6%96%B9%E8%89%A6%E9%9A%8A%E4%B8%BB%E5%8A%9B%E3%82%92%E6%92%83%E6%BB%85%E3%81%9B%E3%82%88%E4%BB%BB%E5%8B%99%E7%B7%A8%E6%88%90/</guid>
      <description>ウィークリー任務の的北方主力を撃滅せよ！任務の艦隊編成です。
敵艦隊を撃破せよと、敵艦隊主力を撃滅せよと、敵補給艦3隻撃沈せよと、い号作戦と、海上護衛戦を終えると出てきます。
内容は3-3〜3-5ボス戦勝利5回ですが、私は3-3で行っています。
Source: New feed</description>
    </item>
    
    <item>
      <title>水上打撃部隊南方へ！任務艦隊編成</title>
      <link>/post/2016-03-21-%E6%B0%B4%E4%B8%8A%E6%89%93%E6%92%83%E9%83%A8%E9%9A%8A%E5%8D%97%E6%96%B9%E3%81%B8%E4%BB%BB%E5%8B%99%E8%89%A6%E9%9A%8A%E7%B7%A8%E6%88%90/</link>
      <pubDate>Mon, 21 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-03-21-%E6%B0%B4%E4%B8%8A%E6%89%93%E6%92%83%E9%83%A8%E9%9A%8A%E5%8D%97%E6%96%B9%E3%81%B8%E4%BB%BB%E5%8B%99%E8%89%A6%E9%9A%8A%E7%B7%A8%E6%88%90/</guid>
      <description>マンスリー任務の水上打撃部隊南方へ任務の艦隊編成です。
高速戦艦不可で、戦艦3隻、軽巡1隻、他2隻で5-1ボス戦S勝利が条件です。
Source: New feed</description>
    </item>
    
    <item>
      <title>2016年冬イベント攻略しました</title>
      <link>/post/2016-02-28-2016%E5%B9%B4%E5%86%AC%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E6%94%BB%E7%95%A5%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Sun, 28 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-02-28-2016%E5%B9%B4%E5%86%AC%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E6%94%BB%E7%95%A5%E3%81%97%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>2016年冬イベント攻略しました。
時間的にも戦力的にもかなり危うかったです。
E-1 E-2 E-3 今回はかなり苦戦しました。
最初は削り中は旗艦撃破が1度しかありませんでした。
ゲージ破壊段階で二十数回ほど試行した後、火力キャップ等を考慮し今の編成に落ち着きました。
大口径砲の装備改修が進んでなかったのがつらかったです。
やはり装備と編成は重要ですね。最後は小破0でボスにT字有利でたどり着きS勝利を収めることができました。
輸送作戦 本作戦 消費資源・資材     燃料 弾薬 鋼材 ボーキサイト 高速修復材     イベント前 174461 99029 156892 59168 784   E-2攻略後 168837 95352 155583 60126 744   E-3攻略後 96801 38804 78090 56990 539   イベント開始前後差分 77660 60225 78802 2178 245    Source: New feed</description>
    </item>
    
    <item>
      <title>Jekyllでテーブルを表示できるようにする</title>
      <link>/post/2016-02-28-jekyll%E3%81%A7%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB%E3%82%92%E8%A1%A8%E7%A4%BA%E3%81%A7%E3%81%8D%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B/</link>
      <pubDate>Sun, 28 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-02-28-jekyll%E3%81%A7%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB%E3%82%92%E8%A1%A8%E7%A4%BA%E3%81%A7%E3%81%8D%E3%82%8B%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B/</guid>
      <description>Jekyllでテーブルを表示できるように設定する。
_config.ymlに次の行を追加する。
Source: New feed</description>
    </item>
    
    <item>
      <title>DaisyDiskでMacのディスク空き容量を増やした</title>
      <link>/post/2016-02-11-daisydisk%E3%81%A7mac%E3%81%AE%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E7%A9%BA%E3%81%8D%E5%AE%B9%E9%87%8F%E3%82%92%E5%A2%97%E3%82%84%E3%81%97%E3%81%9F/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-02-11-daisydisk%E3%81%A7mac%E3%81%AE%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E7%A9%BA%E3%81%8D%E5%AE%B9%E9%87%8F%E3%82%92%E5%A2%97%E3%82%84%E3%81%97%E3%81%9F/</guid>
      <description>Macの空きディスク容量が1割を切ったので、原因となっているファイルを調べてみた。
フリーのツールもいくつかあるのだが、今回はDaisyDiskという有償のアプリを使って調べてみた。
256GBのSSDの調査に数十秒かかり、後はディレクトリをたどりながら、今いるディレクトリの使用容量を円グラフで表示できる。
これで調べてみるとどうやらEvernoteで約20GB使っているようだった。
Evernoteは今後デスクトップアプリ版ではなく、Webアプリ版を使用することにして、アプリはAppCleanerで削除しました。
というような作業を繰り返し、最終的にホームディレクトリの使用量を142GBまでに広げることができました。
Source: New feed</description>
    </item>
    
    <item>
      <title>AWS 請求情報のみ閲覧できるIAMユーザ</title>
      <link>/post/2016-01-28-aws-%E8%AB%8B%E6%B1%82%E6%83%85%E5%A0%B1%E3%81%AE%E3%81%BF%E9%96%B2%E8%A6%A7%E3%81%A7%E3%81%8D%E3%82%8Biam%E3%83%A6%E3%83%BC%E3%82%B6/</link>
      <pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-01-28-aws-%E8%AB%8B%E6%B1%82%E6%83%85%E5%A0%B1%E3%81%AE%E3%81%BF%E9%96%B2%E8%A6%A7%E3%81%A7%E3%81%8D%E3%82%8Biam%E3%83%A6%E3%83%BC%E3%82%B6/</guid>
      <description>請求情報のみ閲覧できるIAMユーザの作り方
下記のポリシーを割り当てるとともに、別途設定が必要です。
こちらの指示に従って、上部ナビゲーションバーのアカウント名を選択しMy Accountを選択し、IAM User Access to Billing InformationのEditボタンを押してActivate IAM Accessのチェックボックスにチェックを入れる必要があります（英語の場合)。
Source: New feed</description>
    </item>
    
    <item>
      <title>拡張海域1-6編成</title>
      <link>/post/2016-01-14-%E6%8B%A1%E5%BC%B5%E6%B5%B7%E5%9F%9F1-6%E7%B7%A8%E6%88%90/</link>
      <pubDate>Thu, 14 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-01-14-%E6%8B%A1%E5%BC%B5%E6%B5%B7%E5%9F%9F1-6%E7%B7%A8%E6%88%90/</guid>
      <description>拡張海域1-6の編成をメモ。
航空マスの敗北がいやなので航巡とあきつ丸を編成に加えています。
ただしこの編成の場合ルートが北に逸れる場合があります。
Source: New feed</description>
    </item>
    
    <item>
      <title>6-2クリア</title>
      <link>/post/2016-01-04-6-2%E3%82%AF%E3%83%AA%E3%82%A2/</link>
      <pubDate>Mon, 04 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-01-04-6-2%E3%82%AF%E3%83%AA%E3%82%A2/</guid>
      <description>新春任務の迎春！「機動部隊」抜錨せよ！で6-2を初攻略しました。
道中ワンパン大破が続いたものの、たまたまだったようで数回道中撤退した後はスムーズにボスまで行きS勝利をおさめることができました。
編成は下記のとおりでした。
Source: New feed</description>
    </item>
    
    <item>
      <title>6-3クリア</title>
      <link>/post/2016-01-04-6-3%E3%82%AF%E3%83%AA%E3%82%A2/</link>
      <pubDate>Mon, 04 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-01-04-6-3%E3%82%AF%E3%83%AA%E3%82%A2/</guid>
      <description>長らくほったらかしだった6-3をクリアしました。
理由は新春任務の前提っぽかったためです。でもこれとは関係無かったかも。
かなり難易度が高く苦労しましたが、結局練度150以上の阿賀野型3隻を投入し無事クリア。
軽巡3隻とすることで戦闘回数は増えますがこちらのほうが安定しました。
確か3回中3回ともボスまで到達し、うちS勝利1回、A勝利2回だったと思います。やはり阿賀野型か。
編成は下記のとおりでした。今気がついたけど瑞穂の艦載機熟練度が飛んでる…
Source: New feed</description>
    </item>
    
    <item>
      <title>艦これ 2015年新春グラフィック</title>
      <link>/post/2016-01-01-%E8%89%A6%E3%81%93%E3%82%8C-2015%E5%B9%B4%E6%96%B0%E6%98%A5%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A3%E3%83%83%E3%82%AF/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/2016-01-01-%E8%89%A6%E3%81%93%E3%82%8C-2015%E5%B9%B4%E6%96%B0%E6%98%A5%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A3%E3%83%83%E3%82%AF/</guid>
      <description>艦これ 2015年新春グラフィックをまとめました。
秋津洲
秋津洲 中破
香取
香取 中破
瑞鳳
瑞鳳 中破
天城
天城 中破
扶桑
扶桑 中破
山城
山城 中破
龍鳳
龍鳳 中破
子日
子日 中破
伊401
伊401 中破
夕雲
夕雲 中破
瑞穂
瑞穂 中破
潮改二
潮改二 中破
大鯨
大鯨 中破
巻雲
巻雲 中破
夕立改二
夕立改二 中破
大淀
大淀 中破
明石
明石 中破
Source: New feed</description>
    </item>
    
    <item>
      <title>コミックマーケットC89二日目に参加してきた</title>
      <link>/post/2015-12-30-%E3%82%B3%E3%83%9F%E3%83%83%E3%82%AF%E3%83%9E%E3%83%BC%E3%82%B1%E3%83%83%E3%83%88c89%E4%BA%8C%E6%97%A5%E7%9B%AE%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%A6%E3%81%8D%E3%81%9F/</link>
      <pubDate>Wed, 30 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-30-%E3%82%B3%E3%83%9F%E3%83%83%E3%82%AF%E3%83%9E%E3%83%BC%E3%82%B1%E3%83%83%E3%83%88c89%E4%BA%8C%E6%97%A5%E7%9B%AE%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%A6%E3%81%8D%E3%81%9F/</guid>
      <description>2015年通称冬コミ2日目に参加してきました。
コミケに参加するのは5年程以来で、冬コミは初参加でした。
始発で参加するため、前日は22時就寝の4時起床。あまり寝られた気がしませんでしたが。
1車両につき1つのドアしか空いてませんでした。
こんなに空いている新宿駅始めてみましたよ…
その後若干人の多い山手線を乗り継ぎゆりかもめで超満員のまま国際展示場駅まで運ばれ、そのまま自分の意志で動くことができず気がついたら改札前まで運ばれていました。
道中、まだ暗いです。
待機列に並んだ直後です。まだ夜明け前ですがうっすら東の空が明るくなっています。
靴下に貼るタイプと衣服に貼るタイプのカイロを使いましたが、海に近いせいかあまり役に立ちませんでした。
待機列はこんな感じでした。奥の方に仮設トイレが並んでいます。列には8時までに戻ってくるようにとのことでした。
MacBook Proを持って行きましたが、テザリングの調子が悪くて艦隊運営はできませんでした…
夜が明けてきました。奥に見えるのは東京ゲートブリッジでしょうか。
完全に日が昇りました。
東待機列はこの辺りでした。
入場時の様子です。
一番混む時間・場所では満員電車並みの混雑でした。一番並んだサークルでは1時間程並んでいました。
予めチェックしていたサークルを回った後は西に行っていろんなジャンルのサークルを回り、予定外ではありましたが幾つか興味を引いたものを購入しました。
西は本当に色々なジャンルがあって同じ島を何周もしました。
久しぶりのコミケ参加でしたが、やはりあの独特の雰囲気は好きです。
いつか何か出展する側になりたいものです。
戦利品1
戦利品2
Source: New feed</description>
    </item>
    
    <item>
      <title>2015年クリスマス限定グラフィック</title>
      <link>/post/2015-12-29-2015%E5%B9%B4%E3%82%AF%E3%83%AA%E3%82%B9%E3%83%9E%E3%82%B9%E9%99%90%E5%AE%9A%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A3%E3%83%83%E3%82%AF/</link>
      <pubDate>Tue, 29 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-29-2015%E5%B9%B4%E3%82%AF%E3%83%AA%E3%82%B9%E3%83%9E%E3%82%B9%E9%99%90%E5%AE%9A%E3%82%B0%E3%83%A9%E3%83%95%E3%82%A3%E3%83%83%E3%82%AF/</guid>
      <description>2015年クリスマス限定グラフィック
今年は初風と谷風と江風と大淀に実装されたようです。
初風
谷風
江風
大淀
初風(中破)
谷風(中破)
江風(中破)
大淀(中破)
Source: New feed</description>
    </item>
    
    <item>
      <title>ちきゅう一般開放</title>
      <link>/post/2015-12-29-%E3%81%A1%E3%81%8D%E3%82%85%E3%81%86%E4%B8%80%E8%88%AC%E9%96%8B%E6%94%BE/</link>
      <pubDate>Tue, 29 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-29-%E3%81%A1%E3%81%8D%E3%82%85%E3%81%86%E4%B8%80%E8%88%AC%E9%96%8B%E6%94%BE/</guid>
      <description>先月ですが横浜のちきゅう一般開放に行ってきました。
ちきゅうとは国立研究開発法人 海洋研究開発機構が所有する地球深部調査船です。
海底を掘削して地震のメカニズムや生命の起源などを調査しているようです。
今回は就航10周年ということで船内を見学できる一般公開が催されました。


相当大きいです

かっこいい計器たち

特徴的な掘削機



船内とは思えない

掘削に使うライザー管



Source: New feed</description>
    </item>
    
    <item>
      <title>拡張海域4-5編成</title>
      <link>/post/2015-12-28-%E6%8B%A1%E5%BC%B5%E6%B5%B7%E5%9F%9F4-5%E7%B7%A8%E6%88%90/</link>
      <pubDate>Mon, 28 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-28-%E6%8B%A1%E5%BC%B5%E6%B5%B7%E5%9F%9F4-5%E7%B7%A8%E6%88%90/</guid>
      <description>拡張海域4-5の編成をメモ
各空母には艦爆を積んで、ボス戦で旗艦の随伴艦みを倒し夜戦で旗艦を仕留める作戦です。
削り編成 ゲージ破壊編成 Source: New feed</description>
    </item>
    
    <item>
      <title>AttributeError: &amp;#039;module&amp;#039; object has no attribute &amp;#039;GPIO&amp;#039;</title>
      <link>/post/2015-12-27-attributeerror-module-object-has-no-attribute-gpio/</link>
      <pubDate>Sun, 27 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-27-attributeerror-module-object-has-no-attribute-gpio/</guid>
      <description>PythonからwebiopiのGPIOを使おうとした時、
AttributeError: &amp;lsquo;module&amp;rsquo; object has no attribute &amp;lsquo;GPIO&amp;rsquo;
と表示される場合の対処。
WebIOPi-0.7.1をRaspberry Pi2に対応させます こちらを参考にpython/native/cpuinfo.cとpython/native/gpio.cを修正します。
  cpuinfo.c
BCM2708をBCM2709に変更
  gpio.c
define BCM2708_PERI_BASE 0x20000000をdefine BCM2708_PERI_BASE 0x3f000000に変更
  その後setup.shを実行し直します。
WiringPi2-PythonをPython3で動くようにします Python3をインストール
sudo aptitude install python3
Python3をデフォルトにする
&amp;lt;br /&amp;gt; sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1&amp;lt;br /&amp;gt; sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.4 2&amp;lt;br /&amp;gt;
WiringPi2-Pythonをインストールしなおす
sudo ./setup.py install
Source: New feed</description>
    </item>
    
    <item>
      <title>艦隊安全お飾り材料集め</title>
      <link>/post/2015-12-27-%E8%89%A6%E9%9A%8A%E5%AE%89%E5%85%A8%E3%81%8A%E9%A3%BE%E3%82%8A%E6%9D%90%E6%96%99%E9%9B%86%E3%82%81/</link>
      <pubDate>Sun, 27 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-27-%E8%89%A6%E9%9A%8A%E5%AE%89%E5%85%A8%E3%81%8A%E9%A3%BE%E3%82%8A%E6%9D%90%E6%96%99%E9%9B%86%E3%82%81/</guid>
      <description>艦隊安全お飾りの材料集め
検討した結果、未攻略のEO海域のほか、2-5を周回してお飾り材料を集めることにしました。
2-5周回編成は次の通りです。
お飾り材料ですが大体8割位？ほぼ毎回お飾り材料はドロップしていたと思います。
実は必要個数を勘違いしていて32個で良いはずが36個集めていました…
消費資源は燃料2000、弾薬-2000、鋼材1000、ボーキサイト2000、バケツ50ほどでした。
余ったお飾り材料は燃料にできます。
Source: New feed</description>
    </item>
    
    <item>
      <title>個人用名刺作った</title>
      <link>/post/2015-12-22-%E5%80%8B%E4%BA%BA%E7%94%A8%E5%90%8D%E5%88%BA%E4%BD%9C%E3%81%A3%E3%81%9F/</link>
      <pubDate>Tue, 22 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-22-%E5%80%8B%E4%BA%BA%E7%94%A8%E5%90%8D%E5%88%BA%E4%BD%9C%E3%81%A3%E3%81%9F/</guid>
      <description>前々から作ろう作ろうと思っていてなかなか作れずにいた個人用の名刺をついに作りました。
選んだサービスはプリントライです。
フリーソフトで始める印刷通販：プリントライ
こちらを選んだ理由は自分で名刺のデザインを作れる上、GIMPなどのフリーソフト (というかPNG形式など) にも対応しているところです。
自分でデザインを作れるところはたくさんあるのですがその殆どが.aiファイルが必要だったり専門知識が必要だったりするようでした。
その点こちらのサイトではテンプレートファイルを配布していますしデータの作り方も丁寧に説明されていました。
22日の17時くらいにデータの入稿をすませ、発送されたのが23日の15時でした。その間もデータ確認着手、完了、請求、作成開始などのお知らせメールが届いていました。
今回の名刺は片面カラー60枚の、マット180kgで料金は806円+配送料支払い手数料(PayPal)193円で999円でした。
Source: New feed</description>
    </item>
    
    <item>
      <title>高専カンファレンス100に参加してきました</title>
      <link>/post/2015-12-22-%E9%AB%98%E5%B0%82%E3%82%AB%E3%83%B3%E3%83%95%E3%82%A1%E3%83%AC%E3%83%B3%E3%82%B9100%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%A6%E3%81%8D%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Tue, 22 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-22-%E9%AB%98%E5%B0%82%E3%82%AB%E3%83%B3%E3%83%95%E3%82%A1%E3%83%AC%E3%83%B3%E3%82%B9100%E3%81%AB%E5%8F%82%E5%8A%A0%E3%81%97%E3%81%A6%E3%81%8D%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>高専カンファレンス100に参加してきたので所感をば。
高専カンファレンス100は12月19日、20日に電気通信大学で開催されました。
高専カンファレンスとは高等専門学校生とそのOBや関係者が集まり発表やLTをする場です。
今回は記念すべき100回ということと、割と近くということで初参加と相成りました。
http://kosenconf.jp/?100tokyo
会場の電通大
B棟というところが会場でした。
二日間のうち両日+懇親会に参加してきました。
一日目 おもいっきり寝坊しアイスブレイクの途中から参加。
コミュ力が足りず隅のほうで愛想笑いをしてやり過ごしました…。
その後夢これというLTが行われ懇親会へ。
懇親会では今まで一度もあっていなあったフォロワー数人と会えてよかった！
二日間 4セッション同時進行でどれを聴こうか迷いましたが、
 インフラ Node.jsではじめるウェブ開発 移動させるだけではもったいない「ルンバ」の魅力と攻略方法 15分でおぼえる！イマドキの電子工作のすゝめ入門編  を選択しました。
全体としてみんな高度なことやってるなぁという印象でした。
高専2年生でNode.jsでウェブ開発とか、私が同じ2年生の頃なんてネトゲやりまくって単位落としかけてた記憶しかない…。
学生でこれなのだから将来はもっとすごいことになっているだろうなと思うと同時に、自分もこのままではいけない、もっと頑張ろうという危機感のような刺激を受けることができました。
Source: New feed</description>
    </item>
    
    <item>
      <title>Raspberry PiでWiFiに繋ぐ方法</title>
      <link>/post/2015-12-18-raspberry-pi%E3%81%A7wifi%E3%81%AB%E7%B9%8B%E3%81%90%E6%96%B9%E6%B3%95/</link>
      <pubDate>Fri, 18 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-18-raspberry-pi%E3%81%A7wifi%E3%81%AB%E7%B9%8B%E3%81%90%E6%96%B9%E6%B3%95/</guid>
      <description>Raspberry PiでWiFiに繋ぐ方法
Xが立ち上がっていない場合のWiFiの設定方法が分からなかったのでメモ。
次のファイルに下記内容を追記すれば良い。
繋げたいWiFiが複数ある場合は、そのままnetworkの項目を増やせばいい。
/etc/wpa_supplicant/wpa_supplicant.conf
Source: New feed</description>
    </item>
    
    <item>
      <title>VPC削除時、We could not delete the following VPCと表示され削除できない場合</title>
      <link>/post/2015-12-13-vpc%E5%89%8A%E9%99%A4%E6%99%82we-could-not-delete-the-following-vpc%E3%81%A8%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E5%89%8A%E9%99%A4%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88/</link>
      <pubDate>Sun, 13 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-13-vpc%E5%89%8A%E9%99%A4%E6%99%82we-could-not-delete-the-following-vpc%E3%81%A8%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E5%89%8A%E9%99%A4%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88/</guid>
      <description>VPC削除時、We could not delete the following VPCと表示され削除できない場合
VPCにエンドポイントがあるとだめらしいので、VPCエンドポイントを手動で削除してからVPCを削除する。
Source: New feed</description>
    </item>
    
    <item>
      <title>Zabbix FrontendでDBに接続できない場合の対処</title>
      <link>/post/2015-12-13-zabbix-frontend%E3%81%A7db%E3%81%AB%E6%8E%A5%E7%B6%9A%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%87%A6/</link>
      <pubDate>Sun, 13 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-12-13-zabbix-frontend%E3%81%A7db%E3%81%AB%E6%8E%A5%E7%B6%9A%E3%81%A7%E3%81%8D%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%87%A6/</guid>
      <description>zabbix-serverはDBに繋がるのにweb frontはDBがタイムアウトになる場合
RPMでインストールした場合、フロントエンドのDB設定は/usr/share/zabbix/conf/zabbix.conf.phpではなく/etc/zabbix/web/zabbix.conf.phpを参照するため、このファイルを変更する必要があります。
Source: New feed</description>
    </item>
    
    <item>
      <title>Nginxで特定のヘッダの有無や内容によってアクセスを制限する方法について</title>
      <link>/post/2015-08-31-nginx%E3%81%A7%E7%89%B9%E5%AE%9A%E3%81%AE%E3%83%98%E3%83%83%E3%83%80%E3%81%AE%E6%9C%89%E7%84%A1%E3%82%84%E5%86%85%E5%AE%B9%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9/</link>
      <pubDate>Mon, 31 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-08-31-nginx%E3%81%A7%E7%89%B9%E5%AE%9A%E3%81%AE%E3%83%98%E3%83%83%E3%83%80%E3%81%AE%E6%9C%89%E7%84%A1%E3%82%84%E5%86%85%E5%AE%B9%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E3%82%A2%E3%82%AF%E3%82%BB%E3%82%B9/</guid>
      <description>Nginxで特定のヘッダ (リクエストヘッダ) の有無や内容によってアクセスを制限する方法
こんな感じにすればOK。
$http_ACCESS_RESTRICTIONのACCESS_RESTRICTION部分は制限させたいヘッダを書きます。
ただし小文字は大文字に、ハイフンはアンダースコアにしてください。
の部分はヘッダの内容を書きます。=なので完全一致です。
もし内容ではなくヘッダの有無だけ確認したい場合はこの部分は必要ないです。
Source: New feed</description>
    </item>
    
    <item>
      <title>docker-machineでStarted machines may have new IP addresses. You may need to re-run the `docker-machine env` command.と言われる件について</title>
      <link>/post/2015-08-29-docker-machine%E3%81%A7started-machines-may-have-new-ip-addresses-you-may-need-to-re-run-the-docker-machine-env-command-%E3%81%A8%E8%A8%80%E3%82%8F%E3%82%8C%E3%82%8B%E4%BB%B6%E3%81%AB%E3%81%A4/</link>
      <pubDate>Sat, 29 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-08-29-docker-machine%E3%81%A7started-machines-may-have-new-ip-addresses-you-may-need-to-re-run-the-docker-machine-env-command-%E3%81%A8%E8%A8%80%E3%82%8F%E3%82%8C%E3%82%8B%E4%BB%B6%E3%81%AB%E3%81%A4/</guid>
      <description>docker-machineでStarted machines may have new IP addresses. You may need to re-run the `docker-machine env` command.と言われる件について
とdocker-machine envを実行してもdocker-machine startを実行しろと言われ堂々巡りに。
おもむろにVirtualBoxで直接起動しようとしたらエラーがでて起動できませんでした。
VirtualBoxのバグのようなので4.3にダウングレードしました。
その後docker-machine start default, docker-machine regenerate-certs default, docker-machine env defaultで無事dockerが使えるようになりました。Source: New feed</description>
    </item>
    
    <item>
      <title>nasneのtorneアプリで音が途切れ途切れになる</title>
      <link>/post/2015-08-25-nasne%E3%81%AEtorne%E3%82%A2%E3%83%97%E3%83%AA%E3%81%A7%E9%9F%B3%E3%81%8C%E9%80%94%E5%88%87%E3%82%8C%E9%80%94%E5%88%87%E3%82%8C%E3%81%AB%E3%81%AA%E3%82%8B/</link>
      <pubDate>Tue, 25 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-08-25-nasne%E3%81%AEtorne%E3%82%A2%E3%83%97%E3%83%AA%E3%81%A7%E9%9F%B3%E3%81%8C%E9%80%94%E5%88%87%E3%82%8C%E9%80%94%E5%88%87%E3%82%8C%E3%81%AB%E3%81%AA%E3%82%8B/</guid>
      <description>前々から欲しかったnasneを買ったので、PS3のtorneアプリで早速テレビを見てみました。
しかし音声がとぎれとぎれ…というより、たまに音声が聞こえなくなります。
 PS3が古いのでそのせいかなぁと思っていましたが、PS3をWiFiではなくLANケーブルで接続したところ音が途切れることはなくなりました。
WiFiの帯域が不足していたようです。
 Source: New feed</description>
    </item>
    
    <item>
      <title>NginxでSSL証明書を設定するとX509_check_private_key:key values mismatchが表示される件について</title>
      <link>/post/2015-08-25-nginx%E3%81%A7ssl%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B%E3%81%A8x509_check_private_keykey-values-mismatch%E3%81%8C%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%82%8B/</link>
      <pubDate>Tue, 25 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-08-25-nginx%E3%81%A7ssl%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%82%92%E8%A8%AD%E5%AE%9A%E3%81%99%E3%82%8B%E3%81%A8x509_check_private_keykey-values-mismatch%E3%81%8C%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%82%8B/</guid>
      <description>NginxでSSLを使用とした時、次のようなエラーが発生した。
 検索すると証明書が間違っているとか出てきますが、私は中間証明書のインストール位置を間違えていました。
中間証明書は証明書の末尾に追記しましょう。
Source: New feed</description>
    </item>
    
    <item>
      <title>WordPressのpermalinksの設定を変更したら500エラーが発生した件</title>
      <link>/post/2015-08-22-wordpress%E3%81%AEpermalinks%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%97%E3%81%9F%E3%82%89500%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E7%99%BA%E7%94%9F%E3%81%97%E3%81%9F%E4%BB%B6/</link>
      <pubDate>Sat, 22 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-08-22-wordpress%E3%81%AEpermalinks%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%82%92%E5%A4%89%E6%9B%B4%E3%81%97%E3%81%9F%E3%82%89500%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E7%99%BA%E7%94%9F%E3%81%97%E3%81%9F%E4%BB%B6/</guid>
      <description>WordPressのpermalinksの設定を変更したら500 Internal Server Errorが発生し、一切のアクセスができなくなった。
問題はApacheの設定で、.htaccessファイルの設定が有効になっていなかったせいでした。
具体的にはAllowOverrideの設定を
に変更したらページが表示されるようになりました。
 参考
core – Apache HTTP サーバ バージョン 2.2 Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-08-08-stuck-in-the-middle/</link>
      <pubDate>Sat, 08 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-08-08-stuck-in-the-middle/</guid>
      <description>This content should not be in feed.</description>
    </item>
    
    <item>
      <title>muninから09:06にメールが届く件について</title>
      <link>/post/2015-07-31-munin%E3%81%8B%E3%82%890906%E3%81%AB%E3%83%A1%E3%83%BC%E3%83%AB%E3%81%8C%E5%B1%8A%E3%81%8F%E4%BB%B6%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/</link>
      <pubDate>Fri, 31 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-07-31-munin%E3%81%8B%E3%82%890906%E3%81%AB%E3%83%A1%E3%83%BC%E3%83%AB%E3%81%8C%E5%B1%8A%E3%81%8F%E4%BB%B6%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/</guid>
      <description>Muninから9時6分頃にこんなメールが来るようになった
 これは9時ジャストに行われているMuninの処理が次の9時5分になっても終わっていないため送信されている。
なぜ終わっていないのかというと、午前9時に日毎、週ごと、年ごとのグラフが更新されているらしかった。
生成されるグラフの数が多いためこのようなことが起こっているのだろう。
 Muninの処理は各サーバから情報を収集、グラフの生成、HTMLの生成の3つが行われており、通常は&#39;usr&#39;bin&#39;munin-cronがその3つの処理を個別に呼び出している。
 ということなので、9時5分に関しては情報の収集だけ行うことにした。
&#39;etc&#39;cron.d&#39;muninは下記のようになった。</description>
    </item>
    
    <item>
      <title>tarファイルの部分解凍</title>
      <link>/post/2015-07-29-tar%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%AE%E9%83%A8%E5%88%86%E8%A7%A3%E5%87%8D/</link>
      <pubDate>Wed, 29 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-07-29-tar%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%AE%E9%83%A8%E5%88%86%E8%A7%A3%E5%87%8D/</guid>
      <description>でっかいtarファイルがあってこの中のあるディレクトリだけ取り出したいというときは次のようにすれば良い
  Source: New feed</description>
    </item>
    
    <item>
      <title>標準エラー出力を標準出力とする方法</title>
      <link>/post/2015-07-24-%E6%A8%99%E6%BA%96%E3%82%A8%E3%83%A9%E3%83%BC%E5%87%BA%E5%8A%9B%E3%82%92%E6%A8%99%E6%BA%96%E5%87%BA%E5%8A%9B%E3%81%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Fri, 24 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-07-24-%E6%A8%99%E6%BA%96%E3%82%A8%E3%83%A9%E3%83%BC%E5%87%BA%E5%8A%9B%E3%82%92%E6%A8%99%E6%BA%96%E5%87%BA%E5%8A%9B%E3%81%A8%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>標準エラー出力を標準出力とする方法例えばcrontabなどで、標準エラー出力にerrorという文字列があった場合メールを送信するという時は次のようにすれば良い何らかの処理 3&amp;gt;&#39;dev&#39;null 2&amp;gt;&amp;amp;1 1&amp;gt;&amp;amp;3 | grep -i error
標準出力は3のファイルディスクリプタ経由で&#39;dev&#39;nullに送り、標準エラー出力は標準出力に送るという流れ。
これで標準エラー出力は標準出力として送られるのでパイプで処理することができる。
 Source: New feed</description>
    </item>
    
    <item>
      <title>Nortonの自動延長が有効になっていたので返金してもらった話</title>
      <link>/post/2015-06-15-norton%E3%81%AE%E8%87%AA%E5%8B%95%E5%BB%B6%E9%95%B7%E3%81%8C%E6%9C%89%E5%8A%B9%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%84%E3%81%9F%E3%81%AE%E3%81%A7%E8%BF%94%E9%87%91%E3%81%97%E3%81%A6%E3%82%82/</link>
      <pubDate>Mon, 15 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-06-15-norton%E3%81%AE%E8%87%AA%E5%8B%95%E5%BB%B6%E9%95%B7%E3%81%8C%E6%9C%89%E5%8A%B9%E3%81%AB%E3%81%AA%E3%81%A3%E3%81%A6%E3%81%84%E3%81%9F%E3%81%AE%E3%81%A7%E8%BF%94%E9%87%91%E3%81%97%E3%81%A6%E3%82%82/</guid>
      <description>タイトルのとおりですが、Nortonはデフォルトで自動延長が有効になっているようです。
クレジットカードの利用明細で初めて気が付きました。
 対象のPCは既に処分しているのでサポートに連絡して自動延長の無効と返金をお願いしました。
お願いしたのは平日の22時台でしたが直ぐにサポートとチャットでつながりスムーズに解約出来ました。
対応いいなあ
Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-05-18-author-detail/</link>
      <pubDate>Mon, 18 May 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-05-18-author-detail/</guid>
      <description>December the twelfth, actually. </description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-05-12-liquid/</link>
      <pubDate>Tue, 12 May 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-05-12-liquid/</guid>
      <description>{% capture liquidstring %} Liquid is not rendered. {% endcapture %} {{ liquidstring | replace:&amp;lsquo;not &amp;lsquo;,&amp;rsquo;&amp;rsquo; }}</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-05-12-pre/</link>
      <pubDate>Tue, 12 May 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-05-12-pre/</guid>
      <description> Line 1 Line 2 Line 3 </description>
    </item>
    
    <item>
      <title>艦これ 2015年春イベント</title>
      <link>/post/2015-05-09-%E8%89%A6%E3%81%93%E3%82%8C-2015%E5%B9%B4%E6%98%A5%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88/</link>
      <pubDate>Sat, 09 May 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-05-09-%E8%89%A6%E3%81%93%E3%82%8C-2015%E5%B9%B4%E6%98%A5%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88/</guid>
      <description>E-1

 E-2


 E-3


 E-4


 E-5

 E-6




 全作戦成功

Source: New feed</description>
    </item>
    
    <item>
      <title>vagrant plugin install vagrant-awsでインストールに失敗するとき</title>
      <link>/post/2015-02-20-vagrant-plugin-install-vagrant-aws%E3%81%A7%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%AB%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D/</link>
      <pubDate>Fri, 20 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-02-20-vagrant-plugin-install-vagrant-aws%E3%81%A7%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%AB%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E3%81%A8%E3%81%8D/</guid>
      <description>vagrant plugin install vagrant-awsdでインストールに失敗するとき
-vvvオプションを付けるとnokogiriのインストールで失敗しているのが分かった。
nokogiri単体でのインストールは上手く行っていた。
最終的にはNOKOGIRI_USE_SYSTEM_LIBRARIES=1をつけてvagrant installすることで上手く行った。
Source: New feed</description>
    </item>
    
    <item>
      <title>The plugin will properly strip newlines.</title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-02-12-strip-newlines/</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-02-12-strip-newlines/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-01-18-jekyll-last-modified-at/</link>
      <pubDate>Sun, 18 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2015-01-18-jekyll-last-modified-at/</guid>
      <description>Please don&#39;t modify this file. It&#39;s modified time is important.</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2015-01-18-jekyll-last-modified-at/</link>
      <pubDate>Sun, 18 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2015-01-18-jekyll-last-modified-at/</guid>
      <description>Please don&#39;t modify this file. It&#39;s modified time is important.</description>
    </item>
    
    <item>
      <title>MuninのMySQLプラグイン有効方法</title>
      <link>/post/2015-01-15-munin%E3%81%AEmysql%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E6%9C%89%E5%8A%B9%E6%96%B9%E6%B3%95/</link>
      <pubDate>Thu, 15 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-01-15-munin%E3%81%AEmysql%E3%83%97%E3%83%A9%E3%82%B0%E3%82%A4%E3%83%B3%E6%9C%89%E5%8A%B9%E6%96%B9%E6%B3%95/</guid>
      <description>初期状態ではMuninがMySQLのRootアカウントを使用してデータを収集しようとするので失敗する。
そのためMuninのデータ収集用MySQLアカウントを作成し、そのアカウントでデータ収集するよう設定する必要がある。
専用MySQLアカウント作成
 専用MySQLアカウントを使用するようMuninを設定
  設定の確認と反映
  参考URL:
http:&#39;&#39;alexcline.net&#39;2013&#39;07&#39;12&#39;setting-up-the-mysql_-plugin-in-munin&#39;
Source: New feed</description>
    </item>
    
    <item>
      <title>（自己署名）証明書の作成方法とその確認方法</title>
      <link>/post/2015-01-14-%E8%87%AA%E5%B7%B1%E7%BD%B2%E5%90%8D%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%81%AE%E4%BD%9C%E6%88%90%E6%96%B9%E6%B3%95%E3%81%A8%E3%81%9D%E3%81%AE%E7%A2%BA%E8%AA%8D%E6%96%B9%E6%B3%95/</link>
      <pubDate>Wed, 14 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/post/2015-01-14-%E8%87%AA%E5%B7%B1%E7%BD%B2%E5%90%8D%E8%A8%BC%E6%98%8E%E6%9B%B8%E3%81%AE%E4%BD%9C%E6%88%90%E6%96%B9%E6%B3%95%E3%81%A8%E3%81%9D%E3%81%AE%E7%A2%BA%E8%AA%8D%E6%96%B9%E6%B3%95/</guid>
      <description>調べればいくらでも出てくるんだけど自分用にメモ
“`
openssl genrsa -out server.key 2048
“`
“`
openssl req -new -sha256 -key server.key -out server.csr
“`
“`
openssl x509 -days 3650 -req -signkey server.key server.crt
“`
server.keyが秘密鍵、server.csrが証明書署名要求、server.crtが証明書。
証明書をちゃんとしたCAに作ってもらうなら、途中で生成される証明書署名要求を提出すれば良い。
 自己署名証明書だけ欲しいという時は次のコマンドでも生成できる。
“`
openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout server.key -sha256 -out server.crt
“`
 作成された証明書署名要求と証明書の確認は下記opensslコマンドで行える。
証明書確認
“`
openssl x509 -text -noout -in server.csr
“` 証明書署名要求確認“`
openssl req -in certificate.crt -text -noout
“`
 Source: New feed</description>
    </item>
    
    <item>
      <title>PG::ObjectInUse: ERROR: データベース&amp;quot;database_name&amp;quot;は他のユーザからアクセスされています</title>
      <link>/post/2014-12-18-pgobjectinuse-error-%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9database_name%E3%81%AF%E4%BB%96%E3%81%AE%E3%83%A6%E3%83%BC%E3%82%B6%E3%81%8B%E3%82%89%E3%82%A2%E3%82%AF/</link>
      <pubDate>Thu, 18 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-12-18-pgobjectinuse-error-%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9database_name%E3%81%AF%E4%BB%96%E3%81%AE%E3%83%A6%E3%83%BC%E3%82%B6%E3%81%8B%E3%82%89%E3%82%A2%E3%82%AF/</guid>
      <description>Postgresqlを使用している時、データベースの削除などをした時下記のようなエラーが表示された時の対処
エラー文の通り操作しようとしているデータベースにアクセスしているユーザがいるためなので、このユーザを強制的に追い出します。
まずアクセスしているユーザを調べます。
“`
SELECT * FROM pg_stat_activity;
“`
該当ユーザのprocidとusernameをメモし、追い出します
“`
SELECT pg_terminate_backend(procpid) FROM pg_stat_activity WHERE usename = ‘usename’;
“`
 以上
Source: New feed</description>
    </item>
    
    <item>
      <title>RPMファイルから設定ファイルを抜き出す方法</title>
      <link>/post/2014-12-15-rpm%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%8B%E3%82%89%E8%A8%AD%E5%AE%9A%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E6%8A%9C%E3%81%8D%E5%87%BA%E3%81%99%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 15 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-12-15-rpm%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%8B%E3%82%89%E8%A8%AD%E5%AE%9A%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E6%8A%9C%E3%81%8D%E5%87%BA%E3%81%99%E6%96%B9%E6%B3%95/</guid>
      <description>とあるRPMパッケージでインストールしたソフトのデフォルトの設定ファイルが欲しい時があって調べたので手順をメモしておく。
  RPMファイルをダウンロードする  yumリポジトリからRPMをダウンロードする場合はyumdownloader [パッケージ名]を使うと良い。yumにない場合は適当にググってダウンロードする。     &amp;lt;/li&amp;gt; * rpm2cpioコマンドを使って取り出す &amp;amp;#8220;\` rpm2cpio ファイル名.rpm | cpio -id &amp;amp;#8220;\` &amp;lt;/li&amp;gt; &amp;lt;/ol&amp;gt; 以上のコマンドによりRPMファイルからファイルを取り出すことができる。 ファイルとディレクトリはカレントディレクトリをルートにして作成されるので、適当なディレクトリを作成してその中でやるといいかもしれない。 Source: New feed </description>
    </item>
    
    <item>
      <title>AMIから起動した時のエラー EXT2-fs: sda1: couldn&amp;#039;t mount because of unsupported optional features (244).</title>
      <link>/post/2014-12-08-ami%E3%81%8B%E3%82%89%E8%B5%B7%E5%8B%95%E3%81%97%E3%81%9F%E6%99%82%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC-ext2-fs-sda1-couldnt-mount-because-of-unsupported-optional-features-244/</link>
      <pubDate>Mon, 08 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-12-08-ami%E3%81%8B%E3%82%89%E8%B5%B7%E5%8B%95%E3%81%97%E3%81%9F%E6%99%82%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC-ext2-fs-sda1-couldnt-mount-because-of-unsupported-optional-features-244/</guid>
      <description>ちょっと古いEC2のインスタンスのボリュームをスナップショット経由でAMIにしてそれを起動した時、一向に起動しない事案があった。
Instance SettingsのGet System Logでログを覗くと次のエラーが
カーネルを同じにすればよいとのことだったので、既存のインスタンスと同じKernel IDを、Image作成時に指定すればよいのでした。
それからImage作成時にArchitectureの指定もしっかり合わせましょう。
Source: New feed</description>
    </item>
    
    <item>
      <title>秋イベント E-4攻略編成</title>
      <link>/post/2014-11-16-%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-e-4%E6%94%BB%E7%95%A5%E7%B7%A8%E6%88%90/</link>
      <pubDate>Sun, 16 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-16-%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-e-4%E6%94%BB%E7%95%A5%E7%B7%A8%E6%88%90/</guid>
      <description>編成は次の通り。ゴリ押し編成です。
空母4だとボスの前にIマスに飛ばされ大破するので、ボスでの航空優勢は完全に捨てて空母2にした上で艦戦もなるべく減らしました。
クリア後に知ったけど道中2戦になる編成があるみたいですね…



Source: New feed</description>
    </item>
    
    <item>
      <title>秋イベント全海域クリア！</title>
      <link>/post/2014-11-16-%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%85%A8%E6%B5%B7%E5%9F%9F%E3%82%AF%E3%83%AA%E3%82%A2/</link>
      <pubDate>Sun, 16 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-16-%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88%E5%85%A8%E6%B5%B7%E5%9F%9F%E3%82%AF%E3%83%AA%E3%82%A2/</guid>
      <description>消費資材
燃料: 18566
弾薬: 19864
鋼材: 12680
ボーキサイト: 2957
高速修復材: 104



いやあ、金曜日の深夜から初めて土曜日の深夜に終わりました。中規模とはいえこんなに早くイベントクリアしたのは初めてですね。
残り期間は初風と朝雲を探しに行きます。
Source: New feed</description>
    </item>
    
    <item>
      <title>2014年秋イベント E-3攻略編成</title>
      <link>/post/2014-11-15-2014%E5%B9%B4%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-e-3%E6%94%BB%E7%95%A5%E7%B7%A8%E6%88%90/</link>
      <pubDate>Sat, 15 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-15-2014%E5%B9%B4%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-e-3%E6%94%BB%E7%95%A5%E7%B7%A8%E6%88%90/</guid>
      <description>E-3は大和型でごり押せたから楽でした。支援もいらなかったしキラ付けももちろん必要なかった。


Source: New feed</description>
    </item>
    
    <item>
      <title>清霜三隈でました！</title>
      <link>/post/2014-11-15-%E6%B8%85%E9%9C%9C%E4%B8%89%E9%9A%88%E3%81%A7%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Sat, 15 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-15-%E6%B8%85%E9%9C%9C%E4%B8%89%E9%9A%88%E3%81%A7%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>E-3ボスドロップです！
やっと三隈手に入ったー！


Source: New feed</description>
    </item>
    
    <item>
      <title>艦これ 2014年秋イベント E-1</title>
      <link>/post/2014-11-15-%E8%89%A6%E3%81%93%E3%82%8C-2014%E5%B9%B4%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-e-1/</link>
      <pubDate>Sat, 15 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-15-%E8%89%A6%E3%81%93%E3%82%8C-2014%E5%B9%B4%E7%A7%8B%E3%82%A4%E3%83%99%E3%83%B3%E3%83%88-e-1/</guid>
      <description>2軍でも余裕でしたね。ルートもそれなかったし


SSとってから気がついたけど五十鈴…
Source: New feed</description>
    </item>
    
    <item>
      <title>s3cmdでERROR: Parameter problem: Nothing to upload.と表示される場合の対処</title>
      <link>/post/2014-11-11-s3cmd%E3%81%A7error-parameter-problem-nothing-to-upload-%E3%81%A8%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%87%A6/</link>
      <pubDate>Tue, 11 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-11-s3cmd%E3%81%A7error-parameter-problem-nothing-to-upload-%E3%81%A8%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%87%A6/</guid>
      <description>s3cmd putで下記エラーが出たことがある
原因は簡単で宛先のS3のパスの最後に&#39;が抜けているだけだった。
Source: New feed</description>
    </item>
    
    <item>
      <title>コマンドラインからファイルを作成する方法</title>
      <link>/post/2014-11-10-%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%8B%E3%82%89%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 10 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-10-%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%8B%E3%82%89%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95/</guid>
      <description>コマンドラインから文章をファイルに書き出す方法です
下記コマンドでhoge.txtにline1からline3までの内容を作成することができます。
hoge.txtまで打ったら改行してline1の入力に移ってください。
“`
cat &amp;lt;&amp;gt; hoge.txt
line1
line2
line3
__EOF__
“`
Source: New feed</description>
    </item>
    
    <item>
      <title>ApacheのSSLの設定で、エラーログにOops, no RSA or DSA server certificate found for &amp;#039;server.host.name:0&amp;#039;?!と表示された時の対処</title>
      <link>/post/2014-11-09-apache%E3%81%AEssl%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%81%A7%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%AD%E3%82%B0%E3%81%ABoops-no-rsa-or-dsa-server-certificate-found-for-server-host-name0/</link>
      <pubDate>Sun, 09 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-09-apache%E3%81%AEssl%E3%81%AE%E8%A8%AD%E5%AE%9A%E3%81%A7%E3%82%A8%E3%83%A9%E3%83%BC%E3%83%AD%E3%82%B0%E3%81%ABoops-no-rsa-or-dsa-server-certificate-found-for-server-host-name0/</guid>
      <description>ApacheのSSLの設定で、エラーログにOops, no RSA or DSA server certificate found for ‘server.host.name:0’?!と表示された時の対処
設定していたVirtualHostにSSLEngine onを追記したらうまくいきました。
Source: New feed</description>
    </item>
    
    <item>
      <title>VirtualBoxにWindows8をインストールしようとした時のエラーについて</title>
      <link>/post/2014-11-09-virtualbox%E3%81%ABwindows8%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E6%99%82%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%AB/</link>
      <pubDate>Sun, 09 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-09-virtualbox%E3%81%ABwindows8%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E6%99%82%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%AB/</guid>
      <description>VirtualBoxにWindows8をインストールしようとしたら次のようなエラーが表示されました。
Your PC needs to restart.
Please hold down the power button.
Error code: 0x000000C4
…
対処ですが、まず下記コマンドを実行してVMの名前を調べます。
次に下記コマンドを実行してからVMを起動し直すと、起動できるようになります。
参考URL:
Windows Server 2012 R2 on VirtualBox – Error 0x000000C4Source: New feed</description>
    </item>
    
    <item>
      <title>横須賀軍港めぐり</title>
      <link>/post/2014-11-08-%E6%A8%AA%E9%A0%88%E8%B3%80%E8%BB%8D%E6%B8%AF%E3%82%81%E3%81%90%E3%82%8A/</link>
      <pubDate>Sat, 08 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-08-%E6%A8%AA%E9%A0%88%E8%B3%80%E8%BB%8D%E6%B8%AF%E3%82%81%E3%81%90%E3%82%8A/</guid>
      <description>先月横須賀軍港めぐりに行ってきました。
遊覧船に乗って湾内の護衛艦を周るツアーですね。
何が見れるかはその時のお楽しみで、私が行った時の停泊しているイージス艦はアメリカの1隻だけでした。
料金は1400円ですが、めったに見られない護衛艦を間近で見ることができるのでおすすめです。
当日券もあるようですが下記URLから予約もできます。
YOKOSUKA軍港めぐり公式サイト
   
Source: New feed</description>
    </item>
    
    <item>
      <title>mysqldumpをパスワードなしで実行する</title>
      <link>/post/2014-11-06-mysqldump%E3%82%92%E3%83%91%E3%82%B9%E3%83%AF%E3%83%BC%E3%83%89%E3%81%AA%E3%81%97%E3%81%A7%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-06-mysqldump%E3%82%92%E3%83%91%E3%82%B9%E3%83%AF%E3%83%BC%E3%83%89%E3%81%AA%E3%81%97%E3%81%A7%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B/</guid>
      <description>cronなどでmysqldumpを実行したいけどパスワードをそのまま書くのはちょっと…という場合はパスワードをファイルに書き出し、それを読みこませることでパスワードの指定なしに実行できます。
実行ユーザのホームディレクトリに.my.cnfという名前で下記3行を書きましょう。
これでOK
Source: New feed</description>
    </item>
    
    <item>
      <title>PostfixでHost or domain name not found. Name service error for name=hostname type=A: Hostというエラーが出る場合の対処</title>
      <link>/post/2014-11-06-postfix%E3%81%A7host-or-domain-name-not-found-name-service-error-for-namehostname-typea-host%E3%81%A8%E3%81%84%E3%81%86%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%82%8B%E5%A0%B4%E5%90%88/</link>
      <pubDate>Thu, 06 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-11-06-postfix%E3%81%A7host-or-domain-name-not-found-name-service-error-for-namehostname-typea-host%E3%81%A8%E3%81%84%E3%81%86%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%82%8B%E5%A0%B4%E5%90%88/</guid>
      <description>CentOSのPostfixで
Host or domain name not found. Name service error for name=hostname type=A: Host not found
などというエラーが出て上手くいかない時
設定が合っている場合でもOS側でsendmailが選択されている場合があります。
sudo alternatives –config mtaコマンドでpostfixを選択してみてください。
Source: New feed</description>
    </item>
    
    <item>
      <title>艦これ拡張海域2-5攻略メンバー</title>
      <link>/post/2014-10-25-%E8%89%A6%E3%81%93%E3%82%8C%E6%8B%A1%E5%BC%B5%E6%B5%B7%E5%9F%9F2-5%E6%94%BB%E7%95%A5%E3%83%A1%E3%83%B3%E3%83%90%E3%83%BC/</link>
      <pubDate>Sat, 25 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-10-25-%E8%89%A6%E3%81%93%E3%82%8C%E6%8B%A1%E5%BC%B5%E6%B5%B7%E5%9F%9F2-5%E6%94%BB%E7%95%A5%E3%83%A1%E3%83%B3%E3%83%90%E3%83%BC/</guid>
      <description>2-5攻略メンバーを載せておく。
最初重巡2航巡1としたが、2回連続で逸れたので重巡1航巡2としたら殆どそれ無くなった。
装備などはもっと考察する余地はあると思う。というかほとんど考えていない
普通にクリアする分にはこれでも十分だった。

Source: New feed</description>
    </item>
    
    <item>
      <title>rails generate rspec:installのときundefined methodが出るときの対処</title>
      <link>/post/2014-10-06-rails-generate-rspecinstall%E3%81%AE%E3%81%A8%E3%81%8Dundefined-method%E3%81%8C%E5%87%BA%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%87%A6/</link>
      <pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-10-06-rails-generate-rspecinstall%E3%81%AE%E3%81%A8%E3%81%8Dundefined-method%E3%81%8C%E5%87%BA%E3%82%8B%E3%81%A8%E3%81%8D%E3%81%AE%E5%AF%BE%E5%87%A6/</guid>
      <description>を実行した時次のエラーが表示された(Rails4.0.5)。
 config&#39;environments&#39;development.rbの一行目を次のように変更するとうまく行った。
 Source: New feed</description>
    </item>
    
    <item>
      <title>Apache 2.4系でのサーバ情報抑制</title>
      <link>/post/2014-09-28-apache-2-4%E7%B3%BB%E3%81%A7%E3%81%AE%E3%82%B5%E3%83%BC%E3%83%90%E6%83%85%E5%A0%B1%E6%8A%91%E5%88%B6/</link>
      <pubDate>Sun, 28 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-09-28-apache-2-4%E7%B3%BB%E3%81%A7%E3%81%AE%E3%82%B5%E3%83%BC%E3%83%90%E6%83%85%E5%A0%B1%E6%8A%91%E5%88%B6/</guid>
      <description>Apache 2.4系でもデフォルトでサーバ情報をリクエストヘッダに出力します。
表示を最小限にするには次の行を追加する必要があります
 また、PHPの情報を出力しないようにするためには次の行をphp.iniに書く必要があります
 Source: New feed</description>
    </item>
    
    <item>
      <title>Rails Passengerでstderr: &amp;#047;usr&amp;#047;bin&amp;#047;env: ruby No such file or directory</title>
      <link>/post/2014-07-08-rails-passenger%E3%81%A7stderr-usrbinenv-ruby-no-such-file-or-directory/</link>
      <pubDate>Tue, 08 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-07-08-rails-passenger%E3%81%A7stderr-usrbinenv-ruby-no-such-file-or-directory/</guid>
      <description>passengerを組み込んだapacheのerror_logに次の行が表示される時の対処
 App 7560 stderr: &#39;usr&#39;bin&#39;env:
  App 7560 stderr: ruby
  App 7560 stderr: : No such file or directory
 apacheからパスが通っていないので、&#39;etc&#39;sysconfig&#39;httpdに次の行を追記します。
 export PATH=&#39;usr&#39;local&#39;bin:$PATH
 パスは適宜変更してください。
Source: New feed</description>
    </item>
    
    <item>
      <title>[warn] _default_ VirtualHost overlap on port 80, the first has precedenceと表示される時の対処</title>
      <link>/post/2014-07-07-warn-_default_-virtualhost-overlap-on-port-80-the-first-has-precedence%E3%81%A8%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%82%8B%E6%99%82%E3%81%AE%E5%AF%BE%E5%87%A6/</link>
      <pubDate>Mon, 07 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-07-07-warn-_default_-virtualhost-overlap-on-port-80-the-first-has-precedence%E3%81%A8%E8%A1%A8%E7%A4%BA%E3%81%95%E3%82%8C%E3%82%8B%E6%99%82%E3%81%AE%E5%AF%BE%E5%87%A6/</guid>
      <description>バーチャルホストを使用するときapachectl -tなどで、[warn] _default_ VirtualHost overlap on port 80, the first has precedenceと表示される時の対処
httpd.confに次の行を書きましょう。デフォルトではコメントアウトになっているはずです。
 NameVirtualHost *:80
 Source: New feed</description>
    </item>
    
    <item>
      <title>yum remove phpでphpが削除されない</title>
      <link>/post/2014-06-24-yum-remove-php%E3%81%A7php%E3%81%8C%E5%89%8A%E9%99%A4%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84/</link>
      <pubDate>Tue, 24 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-06-24-yum-remove-php%E3%81%A7php%E3%81%8C%E5%89%8A%E9%99%A4%E3%81%95%E3%82%8C%E3%81%AA%E3%81%84/</guid>
      <description>yum remove phpでphpが削除されない場合
phpのモジュールがインストールされている場合があります
 yum remove php*
 とすればphpのモジュールが削除できます。
 Source: New feed</description>
    </item>
    
    <item>
      <title>redis, redis-sentinelが起動しない場合の対処</title>
      <link>/post/2014-06-19-redis-redis-sentinel%E3%81%8C%E8%B5%B7%E5%8B%95%E3%81%97%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%87%A6/</link>
      <pubDate>Thu, 19 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-06-19-redis-redis-sentinel%E3%81%8C%E8%B5%B7%E5%8B%95%E3%81%97%E3%81%AA%E3%81%84%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%87%A6/</guid>
      <description>設定ファイルがredis, redis-sentinelユーザで書き込めないと起動しないっぽいです
Source: New feed</description>
    </item>
    
    <item>
      <title>generating known_errors.inc executable host ruby is required. use &amp;#8211;with-baseruby option. make: *** [known_errors.inc] エラー 1</title>
      <link>/post/2014-06-12-generating-known_errors-inc-executable-host-ruby-is-required-use-with-baseruby-option-make-known_errors-inc-%E3%82%A8%E3%83%A9%E3%83%BC-1/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-06-12-generating-known_errors-inc-executable-host-ruby-is-required-use-with-baseruby-option-make-known_errors-inc-%E3%82%A8%E3%83%A9%E3%83%BC-1/</guid>
      <description>Ruby2.1.2のソースインストール時に次のようなエラーが表示された
  generating known_errors.inc
  executable host ruby is required. use –with-baseruby option.
  make: *** [known_errors.inc] エラー 1
  RubyをインストールするにはRubyが必要とのことでした
が今まではRubyが入っていない状態でもインストールできていたので、ホストを再起動を試したらインストールできました。
思い当たる節がyum updateとyum groupinstall “Development Tools”を行ったということくらいしかありませんが、多分このせいなんだろうなぁ
Source: New feed</description>
    </item>
    
    <item>
      <title>メール送信でRelay access denied</title>
      <link>/post/2014-06-12-%E3%83%A1%E3%83%BC%E3%83%AB%E9%80%81%E4%BF%A1%E3%81%A7relay-access-denied/</link>
      <pubDate>Thu, 12 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-06-12-%E3%83%A1%E3%83%BC%E3%83%AB%E9%80%81%E4%BF%A1%E3%81%A7relay-access-denied/</guid>
      <description>Postfixでメールを送信しようとしたところ、rcptでRelay access deniedと言われてしまいました。
このとき&#39;var&#39;log&#39;maillogを見ると次のようにありました。
よくみると、RCPT from localhost[::1]と、IPv6のアドレスでアクセスしていることが分かります。 main.cfのinet_protocolsを次のようにしてIPv4を使うようにすればOKです
腑に落ちませんがこれで解消ですSource: New feed</description>
    </item>
    
    <item>
      <title>ZabbixでSSH server is runningがどうしても障害(Down)とされてしまう場合の対処</title>
      <link>/post/2014-05-26-zabbix%E3%81%A7ssh-server-is-running%E3%81%8C%E3%81%A9%E3%81%86%E3%81%97%E3%81%A6%E3%82%82%E9%9A%9C%E5%AE%B3down%E3%81%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%97%E3%81%BE%E3%81%86%E5%A0%B4%E5%90%88/</link>
      <pubDate>Mon, 26 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-05-26-zabbix%E3%81%A7ssh-server-is-running%E3%81%8C%E3%81%A9%E3%81%86%E3%81%97%E3%81%A6%E3%82%82%E9%9A%9C%E5%AE%B3down%E3%81%A8%E3%81%95%E3%82%8C%E3%81%A6%E3%81%97%E3%81%BE%E3%81%86%E5%A0%B4%E5%90%88/</guid>
      <description>Zabbixを使っているとき、SSH server is runnningが障害と見なされる場合があります。
そもそもこのアイテムはどう判定しているのかというと、サーバからエージェントのアクセスでは無く、エージェントから自身のSSHサーバにアクセスして判定をしています。
ということでssh localhostと打って確認してみましょう。
 …どうでしょうか。ssh_exchange_identificationと表示されたなら、次に&#39;etc&#39;hosts.allowを確認してみてください。
おそらく何かかしらのルールが書いてあるはずなので、sshd : localhostなどと書いておきましょう。
これでいけるはずです
Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-25-oh-yes/</link>
      <pubDate>Sun, 25 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-25-oh-yes/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-24-whateva/</link>
      <pubDate>Sat, 24 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-24-whateva/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-23-hey-there/</link>
      <pubDate>Fri, 23 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-23-hey-there/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-22-humor/</link>
      <pubDate>Thu, 22 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-22-humor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>s3cmdでserver-side-encryptionを使うようにする</title>
      <link>/post/2014-05-22-s3cmd%E3%81%A7server-side-encryption%E3%82%92%E4%BD%BF%E3%81%86%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B/</link>
      <pubDate>Thu, 22 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-05-22-s3cmd%E3%81%A7server-side-encryption%E3%82%92%E4%BD%BF%E3%81%86%E3%82%88%E3%81%86%E3%81%AB%E3%81%99%E3%82%8B/</guid>
      <description>s3cmdでserver-side-encryptionを使おうとして普通に–server-side-encryptionをオプションとしてつけても
と言われるだけでだめだった。
その代わり、
--add-header=x-amz-server-side-encryption:AES256  というオプションをつけるとちゃんと暗号化された。
要するにこんな感じでコマンドを実行すると
s3cmd put --add-header=x-amz-server-side-encryption:AES256 uploadfile s3:&amp;amp;#047;&amp;amp;#047;bucketname&amp;amp;#047;&amp;lt;/p&amp;gt;  Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-21-bleh/</link>
      <pubDate>Wed, 21 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-21-bleh/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ホスト名を再起動なしで変更する</title>
      <link>/post/2014-05-21-%E3%83%9B%E3%82%B9%E3%83%88%E5%90%8D%E3%82%92%E5%86%8D%E8%B5%B7%E5%8B%95%E3%81%AA%E3%81%97%E3%81%A7%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B/</link>
      <pubDate>Wed, 21 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-05-21-%E3%83%9B%E3%82%B9%E3%83%88%E5%90%8D%E3%82%92%E5%86%8D%E8%B5%B7%E5%8B%95%E3%81%AA%E3%81%97%E3%81%A7%E5%A4%89%E6%9B%B4%E3%81%99%E3%82%8B/</guid>
      <description>ホスト名を再起動なしで変更するには次のようにします
 &#39;etc&#39;sysconfig&#39;networkのHOSTNAMEという項目を変更後のホスト名で置き換えます。
これで再起動すれば(しても)ホスト名が変更されます。
 echo ‘変更後のホスト名’ &amp;gt; &#39;proc&#39;sys&#39;kernel&#39;hostname
こうすることで再起動せずともホスト名が変更できます。
 一度ログアウトしてからもう一度入り直すと変更後のホスト名が確認できると思います。
Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-20-blah/</link>
      <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-paginate-1.1.0/spec/source/2014-05-20-blah/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2014-05-11-exclude-this-post/</link>
      <pubDate>Sun, 11 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2014-05-11-exclude-this-post/</guid>
      <description>This post should not appear in the sitemap.</description>
    </item>
    
    <item>
      <title>卯月出ました！</title>
      <link>/post/2014-05-03-%E5%8D%AF%E6%9C%88%E5%87%BA%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Sat, 03 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-05-03-%E5%8D%AF%E6%9C%88%E5%87%BA%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>春イベントE-1道中にて
やったぜ
 
Source: New feed</description>
    </item>
    
    <item>
      <title>浜風でました</title>
      <link>/post/2014-05-01-%E6%B5%9C%E9%A2%A8%E3%81%A7%E3%81%BE%E3%81%97%E3%81%9F/</link>
      <pubDate>Thu, 01 May 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-05-01-%E6%B5%9C%E9%A2%A8%E3%81%A7%E3%81%BE%E3%81%97%E3%81%9F/</guid>
      <description>2-2でポロッと…まさか出るとは思わなかったからびっくりした。

Source: New feed</description>
    </item>
    
    <item>
      <title>Ruby2.1系をソースからインストールしたときのOpenSSLのインストール</title>
      <link>/post/2014-04-12-ruby2-1%E7%B3%BB%E3%82%92%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%8B%E3%82%89%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AEopenssl%E3%81%AE%E3%82%A4/</link>
      <pubDate>Sat, 12 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-04-12-ruby2-1%E7%B3%BB%E3%82%92%E3%82%BD%E3%83%BC%E3%82%B9%E3%81%8B%E3%82%89%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%81%9F%E3%81%A8%E3%81%8D%E3%81%AEopenssl%E3%81%AE%E3%82%A4/</guid>
      <description>Ruby2.1系をソースインストールした時、Railsなどをインストールしようとすると、OpenSSLのインストールを促されますが、OpenSSLパッケージをインストールするだけではいけません。
ソースのext&#39;opensslでextconf.rbを実行し、生成されたMakefileでmake installする必要がありますが、Makefileが間違えているので修正する必要があります。修正しないと次のエラーが出ます
 make: *** `ossl.o’ に必要なターゲット `&#39;thread_native.h’ を make するルールがありません. 中止.
 よってRuby2.1.0でOpenSSLをインストールする際は次のようにする必要があります。
cd &#39;usr&#39;local&#39;src&#39;ruby2.1.0&#39;ext&#39;openssl
&#39;usr&#39;local&#39;bin&#39;ruby extconf.rb
cp -iv Makefile .__Makefile.bak
vim Makefile
diff Makefile .__Makefile.20140407-01
17d16
&amp;lt; top_srcdir = $(srcdir)&#39;..&#39;..
sudo make
sudo make install
Source: New feed</description>
    </item>
    
    <item>
      <title>Zabbix-Server2.2をRPMだけでインストールする</title>
      <link>/post/2014-04-12-zabbix-server2-2%E3%82%92rpm%E3%81%A0%E3%81%91%E3%81%A7%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B/</link>
      <pubDate>Sat, 12 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-04-12-zabbix-server2-2%E3%82%92rpm%E3%81%A0%E3%81%91%E3%81%A7%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%99%E3%82%8B/</guid>
      <description>やたら依存パッケージが多いのでメモを残しておきます。ちなみにMySQL使う場合です
PHPをソースからインストールした場合は少し違うかも知れません
Source: New feed</description>
    </item>
    
    <item>
      <title>SIMパスワードを3回間違えた時の対処法</title>
      <link>/post/2014-03-16-sim%E3%83%91%E3%82%B9%E3%83%AF%E3%83%BC%E3%83%89%E3%82%923%E5%9B%9E%E9%96%93%E9%81%95%E3%81%88%E3%81%9F%E6%99%82%E3%81%AE%E5%AF%BE%E5%87%A6%E6%B3%95/</link>
      <pubDate>Sun, 16 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-03-16-sim%E3%83%91%E3%82%B9%E3%83%AF%E3%83%BC%E3%83%89%E3%82%923%E5%9B%9E%E9%96%93%E9%81%95%E3%81%88%E3%81%9F%E6%99%82%E3%81%AE%E5%AF%BE%E5%87%A6%E6%B3%95/</guid>
      <description>SIMパスワードをかけたのはいいが、パスワードを忘れてしまってロックが掛かってしまった時の対処。
画面に書かれていると思いますが、PUKコードを入力すればパスワードをリセットすることができます
docomoの場合はこちらに対処法が書いてありますが、PINロック解除コード（PUK）というコードを入力すればよいです。
 このコードはXiサービス契約申込書に8桁のPINロック解除コードとして書いてあります。これを入力すればパスワードがロックできます！
Source: New feed</description>
    </item>
    
    <item>
      <title>yumのfastestmirrorが有効にもかかわらずダウンロードが遅い場合</title>
      <link>/post/2014-03-07-yum%E3%81%AEfastestmirror%E3%81%8C%E6%9C%89%E5%8A%B9%E3%81%AB%E3%82%82%E3%81%8B%E3%81%8B%E3%82%8F%E3%82%89%E3%81%9A%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89%E3%81%8C%E9%81%85%E3%81%84/</link>
      <pubDate>Fri, 07 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-03-07-yum%E3%81%AEfastestmirror%E3%81%8C%E6%9C%89%E5%8A%B9%E3%81%AB%E3%82%82%E3%81%8B%E3%81%8B%E3%82%8F%E3%82%89%E3%81%9A%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89%E3%81%8C%E9%81%85%E3%81%84/</guid>
      <description>yumプラグインのfastestmirrorが有効にもかかわらずダウンロードが遅い場合の対処法
Ctrl+cを押しましょう。次のミラーサイトへの接続で続行されます
 &#39;var&#39;cache&#39;yum以下にあるtimedhosts.txtに各ミラーサイトの応答速度が書いてるので、これを削除してリセット。という手もありますが、大抵の場合は遅かったらもう次のミラーサイトで接続というようにやっちゃった方がいいんじゃないかなーっと思います
それでも駄目ならネットワークインターフェースが怪しいので以前書いた記事を参考に、どうぞ！
Source: New feed</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2014-03-04-march-the-fourth/</link>
      <pubDate>Tue, 04 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2014-03-04-march-the-fourth/</guid>
      <description>March the fourth!</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2014-03-04-march-the-fourth/</link>
      <pubDate>Tue, 04 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2014-03-04-march-the-fourth/</guid>
      <description>March the fourth!</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2014-03-02-march-the-second/</link>
      <pubDate>Sun, 02 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2014-03-02-march-the-second/</guid>
      <description>March the second!</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2014-03-02-march-the-second/</link>
      <pubDate>Sun, 02 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2014-03-02-march-the-second/</guid>
      <description>March the second!</description>
    </item>
    
    <item>
      <title>【艦これ】5-3クリア</title>
      <link>/post/2014-03-01-%E8%89%A6%E3%81%93%E3%82%8C5-3%E3%82%AF%E3%83%AA%E3%82%A2/</link>
      <pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-03-01-%E8%89%A6%E3%81%93%E3%82%8C5-3%E3%82%AF%E3%83%AA%E3%82%A2/</guid>
      <description>総試行回数20回ほど
編成はこちら！
ただこの装備だと3回中1回しかボスの潜水艦を落とせなかった気がするので、駆逐艦は全員対潜装備にしたほうがいいかもね

Source: New feed</description>
    </item>
    
    <item>
      <title>矢矧さん</title>
      <link>/post/2014-03-01-%E7%9F%A2%E7%9F%A7%E3%81%95%E3%82%93/</link>
      <pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-03-01-%E7%9F%A2%E7%9F%A7%E3%81%95%E3%82%93/</guid>
      <description>つい先日矢矧さんを引き当てることに成功しました。
阿賀野型は全員Lv100超えてたからうれしい！
ちなみに大型建造初期資材で13回ほど回しました。

Source: New feed</description>
    </item>
    
    <item>
      <title>AWS EC2でタイムゾーンがUTCに戻る場合の対応</title>
      <link>/post/2014-01-23-aws-ec2%E3%81%A7%E3%82%BF%E3%82%A4%E3%83%A0%E3%82%BE%E3%83%BC%E3%83%B3%E3%81%8Cutc%E3%81%AB%E6%88%BB%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%BF%9C/</link>
      <pubDate>Thu, 23 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-01-23-aws-ec2%E3%81%A7%E3%82%BF%E3%82%A4%E3%83%A0%E3%82%BE%E3%83%BC%E3%83%B3%E3%81%8Cutc%E3%81%AB%E6%88%BB%E3%82%8B%E5%A0%B4%E5%90%88%E3%81%AE%E5%AF%BE%E5%BF%9C/</guid>
      <description>タイムゾーンって/usr/share/zoneinfo/Asia/Tokyoを/etc/localtimeにコピーするなりシンボリックリンクを貼るなりすると思うんですけど、EC2の場合はyum updateのタイミングでUTCに戻ってしまう場合があります。ありました
ということで、/etc/sysconfig/clockを書き換えましょう。
/etc/sysconfig/clockは、ハードウェアクロックから読み込んだ値を制御するそうです。
http://web.mit.edu/rhel-doc/4/RH-DOCS/rhel-rg-ja-4/ch-sysconfig.html
/etc/sysconfig/clockの内容は
となってると思います。それを
と書き換えましょう。
私の場合は今のところこれでタイムゾーンがJSTで設定できています。
Source: New feed</description>
    </item>
    
    <item>
      <title>大鳳お迎え完了！</title>
      <link>/post/2014-01-13-%E5%A4%A7%E9%B3%B3%E3%81%8A%E8%BF%8E%E3%81%88%E5%AE%8C%E4%BA%86/</link>
      <pubDate>Mon, 13 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-01-13-%E5%A4%A7%E9%B3%B3%E3%81%8A%E8%BF%8E%E3%81%88%E5%AE%8C%E4%BA%86/</guid>
      <description>はい。
ということで大型建造で無事大鳳をお迎えすることができました。
4000&#39;3500&#39;6010&#39;6000　開発資材は20でした
Source: New feed</description>
    </item>
    
    <item>
      <title>yum updateが異常に遅い</title>
      <link>/post/2014-01-10-yum-update%E3%81%8C%E7%95%B0%E5%B8%B8%E3%81%AB%E9%81%85%E3%81%84/</link>
      <pubDate>Fri, 10 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>/post/2014-01-10-yum-update%E3%81%8C%E7%95%B0%E5%B8%B8%E3%81%AB%E9%81%85%E3%81%84/</guid>
      <description>yum updateが異常に遅い(10kbpsほどの)マシンがあり、その解決に手間取ったので解決策をここに書き記しておきます。
まず、yumでfastestmirrorプラグインが有効になっているかどうか確認します。
確認方法は、yum updateの実行の際、Loaded plugins: fastestmirrorと表示されれば有効になっています。
有効になっている場合はキャッシュファイルを削除してみます。キャッシュファイルは、/etc/yum/pluginconf.d/fastestmirror.confのhostfilepathという項目に場所が書いてあります。
私の場合は/var/cache/yum/timedhosts.txtでした。これをリネームして読み込まないようにしてみます。
これでも解決しませんでしたので、/sbin/ifconfigでインターフェースの状態を確認してみます。
すると、errorパケットがかなりあり、現在進行形で増えているようでした。
/sbin/ethtool eth0でさらに詳しく状態を見てみると、Speedが100Mb/sに設定されていました。
他のマシンは1000Mbpsで設定されていたので設定を合わせます。
/etc/sysconfig/network-scripts/ifcfg-eth0を確認してみると、ETHTOOL_OPTS=&amp;quot;autoneg off speed 100 duplex full&amp;quot;とあったので、Speedを1000に設定して/etc/init.d/network restartで再起動して有効にしようとしました。
しかし、Bringing up interface eth0: Cannot set new settings: Invalid argumentというエラーが表示されて変更できないようでした。
/sbin/ethtool -s eth0 speed 1000 duplex full autoneg offを実行しても下記のような同様の結果でした。
Cannot set new settings: Invalid argument
not setting speed
not setting duplex
not setting autoneg
おかしいなーと思いつつググると、Speedが1000の時はautonegがonになっている必要があるとの情報を発見しました。
http://www.atmarkit.co.jp/bbs/phpBB/viewtopic.php?topic=40505&amp;amp;forum=10&amp;amp;start=16
さっそく/sbin/ethtool -s eth0 speed 1000 duplex full autoneg onを実行したところうまく設定することができました。
再起動しても有効になるよう、ifcfg-eth0にもETHTOOL_OPTS=&amp;quot;autoneg on speed 1000 duplex full&amp;quot;と書いておきます。</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2013-12-12-dec-the-second/</link>
      <pubDate>Thu, 12 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-feed-0.13.0/spec/fixtures/2013-12-12-dec-the-second/</guid>
      <description>December the twelfth, actually. </description>
    </item>
    
    <item>
      <title></title>
      <link>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2013-12-12-dec-the-second/</link>
      <pubDate>Thu, 12 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/vendor/bundle/ruby/2.6.0/gems/jekyll-sitemap-1.4.0/spec/fixtures/2013-12-12-dec-the-second/</guid>
      <description>December the twelfth, actually.</description>
    </item>
    
    <item>
      <title>File &amp;#039;./mysql-bin.index&amp;#039; not found (Errcode: 13)</title>
      <link>/post/2013-12-05-file-mysql-bin-index-not-found-errcode-13/</link>
      <pubDate>Thu, 05 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-12-05-file-mysql-bin-index-not-found-errcode-13/</guid>
      <description>mysqlをソースからインストールして、mysqld_safeなどで起動しようとした時、次のエラーが発生
インストールが終わった後にmysql_install_dbでデータベースを初期化?したのだが、オプションを指定しないといけなかったらしい。多分datadirの指定が必要だったんだな。
というわけでインストール先ディレクトリのオーナーとグループを mysqlに
mysql_install_dbにオプションを付けて次のように実行
Source: New feed</description>
    </item>
    
    <item>
      <title>configure: error: Jabber library not found</title>
      <link>/post/2013-12-03-configure-error-jabber-library-not-found/</link>
      <pubDate>Tue, 03 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-12-03-configure-error-jabber-library-not-found/</guid>
      <description>Zabbix 1.8をソースからインストールした時次のエラーが発生。
iksemeはEPELリポジトリからインストールします。
AmazonAMIならば次のコマンドでiksemelインストールできるでしょう
Source: New feed</description>
    </item>
    
    <item>
      <title>熊野遂に来たる</title>
      <link>/post/2013-12-01-%E7%86%8A%E9%87%8E%E9%81%82%E3%81%AB%E6%9D%A5%E3%81%9F%E3%82%8B/</link>
      <pubDate>Sun, 01 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-12-01-%E7%86%8A%E9%87%8E%E9%81%82%E3%81%AB%E6%9D%A5%E3%81%9F%E3%82%8B/</guid>
      <description>熊野がついに実装されました
よそ見しながら建造してたら、聞きなれない声が聞こえたので、ふと画面を見たらそこに熊野がいました
Source: New feed</description>
    </item>
    
    <item>
      <title>railsのインストール中のエラー</title>
      <link>/post/2013-11-29-rails%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E4%B8%AD%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC/</link>
      <pubDate>Fri, 29 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-11-29-rails%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E4%B8%AD%E3%81%AE%E3%82%A8%E3%83%A9%E3%83%BC/</guid>
      <description>railsをgem installしようとしたら次のエラーが
rdocがないということなのでrdocをgem installしますが次のエラーが発生します。
ということでyum install ruby-irbでruby-irbをインストールしましょう。
これでエラーがでなくなるのでrdocとrailsをインストールし直しました。
Source: New feed</description>
    </item>
    
    <item>
      <title>EC2にEBSボリュームの追加する</title>
      <link>/post/2013-11-26-ec2%E3%81%ABebs%E3%83%9C%E3%83%AA%E3%83%A5%E3%83%BC%E3%83%A0%E3%81%AE%E8%BF%BD%E5%8A%A0%E3%81%99%E3%82%8B/</link>
      <pubDate>Tue, 26 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-11-26-ec2%E3%81%ABebs%E3%83%9C%E3%83%AA%E3%83%A5%E3%83%BC%E3%83%A0%E3%81%AE%E8%BF%BD%E5%8A%A0%E3%81%99%E3%82%8B/</guid>
      <description>EC2はEBSボリュームの追加を追加することができます。
ですが追加したディスクのフォーマットやマウントは自分で行う必要があります。
マウントするためにはまず、lsblkコマンドでどの名前でEBSが認識されているのかを確認します。
この場合はxvdbという名前で認識されています。xvda1はシステムが入っているRootパーティションですね。
次にファイルシステムを作成します。
ext4で作成するにはmke2fsコマンドを使います
Allocating group tables: done Writing inode tables: done Creating journal (32768 blocks): done Writing superblocks and filesystem accounting information: done これでマウントする準備が出来ました。mountコマンドでマウントしましょう。
下記の例は/dev/xvdbを/mntにマウントします。
システム起動時に自動的にマウントしたい時は/etc/fstabに必要な情報を記入します。
基本的には下記のとおりでいいかと。/dev/xvdbで始まる行が追加した行です。
Source: New feed</description>
    </item>
    
    <item>
      <title>EC2ストレージ容量が増えない</title>
      <link>/post/2013-11-26-ec2%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%E5%AE%B9%E9%87%8F%E3%81%8C%E5%A2%97%E3%81%88%E3%81%AA%E3%81%84/</link>
      <pubDate>Tue, 26 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-11-26-ec2%E3%82%B9%E3%83%88%E3%83%AC%E3%83%BC%E3%82%B8%E5%AE%B9%E9%87%8F%E3%81%8C%E5%A2%97%E3%81%88%E3%81%AA%E3%81%84/</guid>
      <description>EC2のインスタンスのEBS容量を増やして作成したのにdfコマンドで確認しても8GBしかない…
resize2fsコマンドを使うと本来のサイズに増やせる。
なら
でOK
Source: New feed</description>
    </item>
    
    <item>
      <title>衣笠さん</title>
      <link>/post/2013-11-26-%E8%A1%A3%E7%AC%A0%E3%81%95%E3%82%93/</link>
      <pubDate>Tue, 26 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-11-26-%E8%A1%A3%E7%AC%A0%E3%81%95%E3%82%93/</guid>
      <description>ついに衣笠さんが実装されました。
改二(だっけ？)にするぜー
Source: New feed</description>
    </item>
    
    <item>
      <title>長門</title>
      <link>/post/2013-11-25-%E9%95%B7%E9%96%80/</link>
      <pubDate>Mon, 25 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-11-25-%E9%95%B7%E9%96%80/</guid>
      <description>念願の長門を手に入れたぞ！
秘書加賀400 30 600 30にて
Source: New feed</description>
    </item>
    
    <item>
      <title>mod_pythonをインストールしようとした時checking for Py_NewInterpreter in -lpython2.6&amp;#8230; no configure: error: Can not link to pythonとエラーが出る</title>
      <link>/post/2013-09-06-mod_python%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E6%99%82checking-for-py_newinterpreter-in-lpython2-6-no-configure-e/</link>
      <pubDate>Fri, 06 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-09-06-mod_python%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E6%99%82checking-for-py_newinterpreter-in-lpython2-6-no-configure-e/</guid>
      <description>mod_pythonを入れようとして、
と表示された場合。
で解決
Source: New feed</description>
    </item>
    
    <item>
      <title>passenger-install-apache2-moduleが失敗する件について</title>
      <link>/post/2013-09-06-passenger-install-apache2-module%E3%81%8C%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E4%BB%B6%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/</link>
      <pubDate>Fri, 06 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-09-06-passenger-install-apache2-module%E3%81%8C%E5%A4%B1%E6%95%97%E3%81%99%E3%82%8B%E4%BB%B6%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/</guid>
      <description>Passengerをインストールするとき、passenger-install-apache2-moduleを実行しますが、Apacheをソースインストールしていたりすると、次のようなエラーが出てうまくインストールできません。
 GNU C++ compiler&amp;hellip; found at /usr/bin/g++ Curl development headers with SSL support&amp;hellip; not found OpenSSL development headers&amp;hellip; found Zlib development headers&amp;hellip; found Ruby development headers&amp;hellip; found OpenSSL support for Ruby&amp;hellip; found RubyGems&amp;hellip; found Rake&amp;hellip; found at /usr/bin/rake rack&amp;hellip; found Apache 2&amp;hellip; not found Apache 2 development headers&amp;hellip; not found Apache Portable Runtime (APR) development headers&amp;hellip; not found Apache Portable Runtime Utility (APU) development headers&amp;hellip; not found   上記例では</description>
    </item>
    
    <item>
      <title>s3cmdのデフォルトリージョンを東京にする</title>
      <link>/post/2013-08-30-s3cmd%E3%81%AE%E3%83%87%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%E3%83%AA%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E6%9D%B1%E4%BA%AC%E3%81%AB%E3%81%99%E3%82%8B/</link>
      <pubDate>Fri, 30 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-08-30-s3cmd%E3%81%AE%E3%83%87%E3%83%95%E3%82%A9%E3%83%AB%E3%83%88%E3%83%AA%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E3%82%92%E6%9D%B1%E4%BA%AC%E3%81%AB%E3%81%99%E3%82%8B/</guid>
      <description>s3cmdではデフォルトでUSリージョンが設定されます。
これを東京リージョンで設定するには、ホームディレクトリの.s3cfgを編集します
以下の4つのオプションをそれぞれ書き換えれば大丈夫です
Source: New feed</description>
    </item>
    
    <item>
      <title>SSH fingerprintの確認方法</title>
      <link>/post/2013-07-30-ssh-fingerprint%E3%81%AE%E7%A2%BA%E8%AA%8D%E6%96%B9%E6%B3%95/</link>
      <pubDate>Tue, 30 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-07-30-ssh-fingerprint%E3%81%AE%E7%A2%BA%E8%AA%8D%E6%96%B9%E6%B3%95/</guid>
      <description>OS再インストールした時、remote host identification has changedとか言われるのはこの公開鍵が変わるからなのね。
参考
http://d.hatena.ne.jp/Artisan/20130325/1364222117
Source: New feed</description>
    </item>
    
    <item>
      <title>ERROR: While executing gem &amp;#8230; (NoMethodError) undefined method `map&amp;#039; for Gem::Specification:Class</title>
      <link>/post/2013-07-03-error-while-executing-gem-nomethoderror-undefined-method-map-for-gemspecificationclass/</link>
      <pubDate>Wed, 03 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-07-03-error-while-executing-gem-nomethoderror-undefined-method-map-for-gemspecificationclass/</guid>
      <description>とか表示されるとき
~/.gemrcに
gem: --no-rdoc --no-ri
を追加すればよろし。
sudo gem install hogehoge_gem --no-rdoc --no-ri
でも同じことだと思う(未確認)
参考
http://stackoverflow.com/questions/7535737/using-no-rdoc-and-no-ri-with-bundler
Source: New feed</description>
    </item>
    
    <item>
      <title>gemでpgをインストールしようとするとNo pg_config&amp;#8230; trying anyway. If building fails, please try again withとエラーが表示される</title>
      <link>/post/2013-07-01-gem%E3%81%A7pg%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%99%E3%82%8B%E3%81%A8no-pg_config-trying-anyway-if-building-fails-please-try/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-07-01-gem%E3%81%A7pg%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E3%81%97%E3%82%88%E3%81%86%E3%81%A8%E3%81%99%E3%82%8B%E3%81%A8no-pg_config-trying-anyway-if-building-fails-please-try/</guid>
      <description>gemでpgをインストールしようとするとNo pg_config… trying anyway. If building fails, please try again withとエラーが表示される
ERROR: Error installing pg: ERROR: Failed to build gem native extension.
/usr/local/bin/ruby extconf.rb checking for pg_config&amp;hellip; no No pg_config&amp;hellip; trying anyway. If building fails, please try again with &amp;ndash;with-pg-config=/path/to/pg_config checking for libpq-fe.h&amp;hellip; no Can&#39;t find the &amp;lsquo;libpq-fe.h header *** extconf.rb failed *** Could not create Makefile due to some reason, probably lack of necessary libraries and/or headers. Check the mkmf.</description>
    </item>
    
    <item>
      <title>pg gemインストール時にPlease install the postgresql adapterとエラーが出る</title>
      <link>/post/2013-07-01-pg-gem%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%99%82%E3%81%ABplease-install-the-postgresql-adapter%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%82%8B/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>/post/2013-07-01-pg-gem%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%99%82%E3%81%ABplease-install-the-postgresql-adapter%E3%81%A8%E3%82%A8%E3%83%A9%E3%83%BC%E3%81%8C%E5%87%BA%E3%82%8B/</guid>
      <description>このlibpq.so.5は/usr/local/pgsql/libに入っているので
/usr/lib/にシンボリックリンクを貼ってみる
sudo ln -s /usr/local/pgsql/lib/libpq.so.5 /usr/lib
これでおｋ Source: New feed</description>
    </item>
    
  </channel>
</rss>